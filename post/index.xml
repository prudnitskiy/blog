<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on SRE Blog</title><link>https://prudnitskiy.pro/post/</link><description>SRE Blog (Posts)</description><generator>Hugo -- gohugo.io</generator><language>ru-ru</language><lastBuildDate>Sat, 04 Mar 2023 11:00:00 +0000</lastBuildDate><atom:link href="https://prudnitskiy.pro/post/index.xml" rel="self" type="application/rss+xml"/><item><title>Книги для инфраструктурного инженера, часть 1 - hard skills</title><link>https://prudnitskiy.pro/post/2023-01-24-books/</link><pubDate>Sat, 04 Mar 2023 11:00:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2023-01-24-books/</guid><description>&lt;p>Должен признаться &amp;ndash; я люблю книги. Сейчас это не модно, потому, что книги отнимают очень много времени для прочтения, а результативность под вопросом. Ту же самую информацию можно получить в Google за 5 минут поиска. Тем не менее я считаю пользу книг сильно недооцененной. Поиск в Google дает ответ на очень узкий конкретный вопрос (и ответ, часто, не оптимальный, а может и вовсе неверный). Хорошая, качественная книга дает обзор проблемы с разных точек зрения и показывает, как части связываются в единое целое.&lt;/p>
&lt;p>В этой статье я собрал лучшие (на мой взгляд) книги для хорошего инфраструктурного инженера (cloud engineer, system administrator, devops, site reliability engineer, как вам больше нравится). Топ получился больше, чем я планировал, потому он разделен на 2 части. В первой части будут книги по техническим знаниям, во второй - по нетехническим, но все равно важным. Я специально отсортировал книги по алфавиту по имени автора, чтобы снизить предвзятость своей оценки.&lt;/p>
&lt;p>Должен добавить, что я верю в &lt;a href="https://en.wikipedia.org/wiki/Lindy_effect">эффект Линди&lt;/a> и потому не удивляйтесь, что здесь есть сравнительно не новые книги. Шанс того, что не прошедшая испытание временем книга окажется хорошей, по моему мнению - невысок.&lt;/p>
&lt;p>Итак, топ-10 книг для инфраструктурного инженера, hard skills:&lt;/p>
&lt;h3 id="beyer-jones-petoff-murphy---site-reliability-engineeringhttpssregooglesre-booktable-of-contents" >Beyer, Jones, Petoff, Murphy - &lt;a href="https://sre.google/sre-book/table-of-contents/">Site reliability engineering&lt;/a>
&lt;span>
&lt;a href="#beyer-jones-petoff-murphy---site-reliability-engineeringhttpssregooglesre-booktable-of-contents">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Прекрасный экскурс в то, как работает инфраструктура в действительно больших проектах (на примере Google). Именно с этой книги началось понятие SRE за пределами Google. Авторы рассказывают, как в Google принимаются те или иные решения (на основе метрик), почему нельзя сделать 100% надежную систему (это слишком дорого), как решить, когда остановится (посчитать деньги), как проектировать систему с заданным уровнем надежности&amp;hellip; Даже, если ваша инфраструктура намного меньше, чем у Google - вы найдете что-то полезное для себя. Принципы построения инфраструктур, описанных в этой книге - универсальны.&lt;/p>
&lt;h3 id="bovet---understanding-linux-kernelhttpswwwamazoncomunderstanding-linux-kernel-third-danieldp0596005652" >Bovet - &lt;a href="https://www.amazon.com/Understanding-Linux-Kernel-Third-Daniel/dp/0596005652">Understanding linux kernel&lt;/a>
&lt;span>
&lt;a href="#bovet---understanding-linux-kernelhttpswwwamazoncomunderstanding-linux-kernel-third-danieldp0596005652">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Подавляющее большинство систем, с которыми работает операционный инженер базируется на Linux. Эта книга &amp;ndash; наверное, самый полный и подробный справочник по устройству ядра и взаимодействию kernel space - user space. Книга очень большая, но на удивление легко читается. Не менее классический &lt;a href="https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468">труд Роберта Лава&lt;/a> больше ориентирован на разработку и читается не в пример тяжлее. Понимание того, как в целом работает ядро &amp;ndash; критически важно для решения проблем с производительностью. Без знания того, как (и что) там тикает внутри &amp;ndash; проблемы производительности придется решать или &amp;ldquo;заливкой деньгами&amp;rdquo; (классический шаблон стартапов, за который они теперь вынуждены платить) или магическими рецептами, которые могут и не помочь. А могут даже повредить.&lt;/p>
&lt;h3 id="felleisen-findler-flatt-krishnamurthi---how-to-design-programshttpshtdporg2022-8-7bookindexhtml" >Felleisen, Findler, Flatt, Krishnamurthi - &lt;a href="https://htdp.org/2022-8-7/Book/index.html">How to design programs&lt;/a>
&lt;span>
&lt;a href="#felleisen-findler-flatt-krishnamurthi---how-to-design-programshttpshtdporg2022-8-7bookindexhtml">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Нравится нам это или нет - но современному инфраструктурному инженеру приходится писать код. В основном - инструменты для автоматизации своего труда. Подавляющее большинство из нас пишет код отвратительно, потому, что мы не были профессиональными программистами и просто не знаем, как правильно писать надежный и поддерживаемый код. Эта книга - классический учебник от MIT по проектированию программ. Книга весьма не новая и в качестве иллюстрации использует экзотический язык Racket (это такой Lisp, который хорошо кушал), однако важно не это. Книга очень подробно проводит по всем этапам проектирования программы, начиная от сбора требований и выбора алгоритмов до написания кода и подходов к его поддержки. В отличие от не менее известного SICP (Abelson et al) - эта книга старается использовать максимально инженерный подход с минимумом эзотерики и &amp;ldquo;просто поверьте на слово&amp;rdquo;. Из всего списка выше она выглядит самой бесполезной (и, наверное, самой сложной), но это книга, которая стоит прочтения.&lt;/p>
&lt;h3 id="gregg---system-performancehttpswwwbrendangreggcomsystems-performance-2nd-edition-bookhtml" >Gregg - &lt;a href="https://www.brendangregg.com/systems-performance-2nd-edition-book.html">System performance&lt;/a>
&lt;span>
&lt;a href="#gregg---system-performancehttpswwwbrendangreggcomsystems-performance-2nd-edition-bookhtml">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Безусловно лучшая книга по производительности UNIX-систем с точки зрения системы. Эта книга рассматривает производительность программы как данность и помогает понять, как измерить и &amp;ldquo;изогнуть&amp;rdquo; систему под конкретные задачи. Написана человеком, который занимается производительностью в Linux уже лет 20 и был ведущим инженером в Netflix. Абсолютно точно стоит прочитать после SRE Book, чтобы понять - как измерять производительность и что может на нее повлиять (а повлиять может многое и подчас довольно неожиданное).&lt;/p>
&lt;h3 id="goralski---the-illustrated-networkhttpswwwamazoncomillustrated-network-modern-kaufmann-networkingdp0123745411" >Goralski - &lt;a href="https://www.amazon.com/Illustrated-Network-Modern-Kaufmann-Networking/dp/0123745411">The illustrated network&lt;/a>
&lt;span>
&lt;a href="#goralski---the-illustrated-networkhttpswwwamazoncomillustrated-network-modern-kaufmann-networkingdp0123745411">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Солидный 800-страничный кирпич про устройство сети. Сети рассматриваются с точки зрения стека TCP/IP, ибо победил он с разгромным счетом и не-IP сети сейчас очень большая редкость. Это очень подробное описание принципов, алгоритмов и протоколов сети, начиная с L2 и заканчивая QoS и высокоуровневой маршрутизаций. Обязательна для прочтения сетевыми инженерам (начиная от претендующих на сертификаты с буквой P в названии), но обычному инфраструктурному инженеру тоже вреда не принесет. Как минимум - это поможет в выборе между TCP и UDP и отучит защищаться от DDoS, блокируя адреса на iptables по одному&lt;/p>
&lt;h3 id="humble---continuous-deliveryhttpswwwamazoncomdp0321601912tagcontindelive-20" >Humble - &lt;a href="https://www.amazon.com/dp/0321601912?tag=contindelive-20">Continuous delivery&lt;/a>
&lt;span>
&lt;a href="#humble---continuous-deliveryhttpswwwamazoncomdp0321601912tagcontindelive-20">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Полный, подробный справочник по DevOps. В отличие от попсового &amp;ldquo;проекта Феникс&amp;rdquo; и &amp;ldquo;руководства по DevOps&amp;rdquo; Кима - эта книга написана не для стратегов-менеджеров, а для тех инженеров, которым все это реализовывать &amp;ldquo;на земле&amp;rdquo;. Книга подробно описывает, откуда взялась идея DevOps, какую проблему она решает (нет, не любую) и какие там есть ограничения. Не смотря на то, что книга весьма немолода - концепции в ней описаны универсальные. Абсолютно точно необходима DevOps-ам, остальным - для расширения кругозора.&lt;/p>
&lt;h3 id="kleppman---design-of-data-intensive-appshttpswwworeillycomlibraryviewdesigning-data-intensive-applications9781491903063" >Kleppman - &lt;a href="https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/">Design of data-intensive apps&lt;/a>
&lt;span>
&lt;a href="#kleppman---design-of-data-intensive-appshttpswwworeillycomlibraryviewdesigning-data-intensive-applications9781491903063">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Книга &amp;ldquo;с кабанчиком&amp;rdquo; известна, наверное, всем. Мало кто ее читал, но все про нее слышали. Это книга из той редкой породы, что выходят раз в десятилетие. Контент - плотное погружение во все основные технологии, что лежат в основе современного высокопроизводительного ПО для обработки данных. Алгоритмы хранения информации (сжатие с потерями и без), поиска (поисковые деревья разных видов), записи данных, поиска консенсуса в гетерогенных системах, защиты от сбоя. Почти тысяча страниц концентрированной информации. Проглотить этот кирпич одним махом невозможно, но это без шуток - настольная книга для любого, кто работает с большими объемами данных. Инфраструктурный инженер должен понимать, какие примитивы лежат в основе систем, с которыми он работает&lt;/p>
&lt;h3 id="schneier---applied-cryptographyhttpswwwamazoncomapplied-cryptography-protocols-algorithms-source-ebookdpb072k4xbjj" >Schneier - &lt;a href="https://www.amazon.com/Applied-Cryptography-Protocols-Algorithms-Source-ebook/dp/B072K4XBJJ">Applied cryptography&lt;/a>
&lt;span>
&lt;a href="#schneier---applied-cryptographyhttpswwwamazoncomapplied-cryptography-protocols-algorithms-source-ebookdpb072k4xbjj">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Сравнительно короткий и сравнительно простой обзор криптографии. Криптография очень сложная область сама по себе, так что не стоит ждать экспертности после прочтения. Эта книга кратко описывает понятия, которые там вообще есть - виды шифрования (блочное, поточное), виды ключей (симметричные и ассиметричные). Главная мысль книги - никогда не изобретать крипто примитивы самому. Есть миллион способов сделать маленькую сложно уловимую ошибку, которая сделает шифр легковскрываемым, а значит - бессмысленным. Бонусом книга поможет выбрать криптографическое решение для конкретной ситуации и научит оценивать риски. Книга прекрасно подходит для понимания границ незнания в вопросах защиты информации, а заодно приоткрывает процесс дизайна криптографических решений.&lt;/p>
&lt;h3 id="tannenbaum---structured-computer-organizationhttpswwwamazoncomstructured-computer-organization-andrew-tanenbaum-ebookdpb0093k4p9uref_ast_author_dp" >Tannenbaum - &lt;a href="https://www.amazon.com/Structured-Computer-Organization-Andrew-Tanenbaum-ebook/dp/B0093K4P9U?ref_=ast_author_dp">Structured computer organization&lt;/a>
&lt;span>
&lt;a href="#tannenbaum---structured-computer-organizationhttpswwwamazoncomstructured-computer-organization-andrew-tanenbaum-ebookdpb0093k4p9uref_ast_author_dp">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>В русском переводе эта книга известна как &amp;ldquo;Архитектура компьютера&amp;rdquo; и издавали ее в издательстве Питер, серия Classic computer science. Если Клеппман - это экскурс в алгоритмы и технологии обработки данных, то Танненбаум - это экскурс в устройство компьютеров в целом - микроархитектуры, их виды и влияние на производительность, устройство памяти разных видов, шины и подключение устройств&amp;hellip; Фактически эта книга - конспект лекций, которые профессор Таненбаум читает в университете Амстердама (до сих пор, кстати, читает). Книга имеет какой-то сумасшедший для столь узкой сферы тираж и пережила уже 6 переизданий (первая редакция вышла аж 1976 году). Не смотря на то, что считается слегка устаревшей (самое свежее издание - 2012 года) - принципы и концепции остались те же. Книгу точно стоит прочитать - как минимум для общего понимания ландшафта.&lt;/p>
&lt;h3 id="tsoukalos---mastering-gohttpswwwamazoncommastering-go-professional-utilities-concurrentdp1801079315" >Tsoukalos - &lt;a href="https://www.amazon.com/Mastering-Go-professional-utilities-concurrent/dp/1801079315">Mastering go&lt;/a>
&lt;span>
&lt;a href="#tsoukalos---mastering-gohttpswwwamazoncommastering-go-professional-utilities-concurrentdp1801079315">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Golang считается одним из самых популярных языков программирования в среде инфраструктурных инженеров (второе место - Python, Ruby и Perl влачат маргинальное существование). Компактная грамматика (2 страницы текста!), богатейший тулинг и стандартная библиотека, предельно удобная дистрибьюция сделали язык сверх-популярным в среде админов-автоматизаторов. Если How to design programs учит &lt;em>что&lt;/em> писать, то эта книга на конкретных примерах показывает &lt;em>как&lt;/em>. Она совсем не такая всеобъемлющая, как книга Кернигана, зато практически ориентирована. Книгу можно просто прочитать, как отдельный труд, а можно использовать как справочник при написании кода для конкретных задач&lt;/p>
&lt;h2 id="заключение" >Заключение
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Хорошая книга описывает базовые концепции, которые мало меняются со временем. Польза понимания базовых идей еще и в том, что их сравнительно мало, но конкретные реализации (коих много) - строятся на базовых концепциях. Понимание базы даст возможность не только понять, как конкретные кирпичики укладываются в общую картину, но и поможет в изучении новых идей и концепций - базовые принципы универсальны. Читайте книги.&lt;/p></description></item><item><title>Как сдать экзамен Cerified Kubernetes Administrator: личный опыт</title><link>https://prudnitskiy.pro/post/2022-02-16-CKA/</link><pubDate>Wed, 16 Feb 2022 20:00:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2022-02-16-CKA/</guid><description>&lt;p>Экзамен Kubernetes Certified Administrator (CKA) по праву считается самым сложным из &amp;ldquo;базовых&amp;rdquo;. Интернет буквально заполнен жалобами людей, которые заплатили 400$ за попытку и не смогли его сдать. Linux Foundation предлагает одну дополнительную попытку и тестовый вариант экзамена (аж 3 тестовых сессии). Это не помогает все равно - LFS сначала сделали упрощенный вариант CKAD (Certified Kubernetes Application Developer), а потом - еще более упрощенный CKAN. Я этот экзамен сдал. С первой попытки и на 86% (то есть я сделал одну ошибку в одном сложном вопросе). Вся подготовка заняла пол-года (на момент старта знания у меня были только теоретические). В этой статье я расскажу, как я готовился, зачем это вообще надо и на что обращать внимание.&lt;/p>
&lt;h2 id="мотивация" >Мотивация
&lt;span>
&lt;a href="#%d0%bc%d0%be%d1%82%d0%b8%d0%b2%d0%b0%d1%86%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Kubernetes переживает сейчас бурный рост и его используют очень многие компании. Его ближайший конкурент mesos прекратил свою разработку (потому, что превосходство k8s - подавляющее). Другой конкурент - Hashicorp Nomad - на самом деле не совсем конкурент, так как решает несколько иные вопросы. Состояние Docker Swarm настолько ужасно, что Mirantis не убивает его, по-моему, из чистой жалости &amp;ndash; я ни разу не видел сколько-то работающих конфигураций Swarm, а в тестах он ведет себя настолько нестабильно, что непонятно, зачем он в принципе нужен. Linux Foundation придумали 3 программы сертификации для тех, кто работает с K8s:&lt;/p>
&lt;ul>
&lt;li>Certified Kubernetes Administrator (CKA). Экзамен для тех, кто строит и поддерживает инфраструктуры на базе K8s (operations engineering team)&lt;/li>
&lt;li>Certified Kubernetes Application Developer (CKAD). Экзамен для разработчиков, который проверяет знание best practices по написанию и развертыванию приложений внутри K8s. Этакий CKA на минималках с упором именно на deploy.&lt;/li>
&lt;li>Certified Kubernetes Security (CKS). Частично повторяет CKA, но с упором на безопасность. Для сдачи этого экзамена нужно иметь активный CKA - экзамен частично строится на его программе.&lt;/li>
&lt;li>Certified Kubernetes Associate (CKAN). CKAD на минималках, совсем-совсем базовые вопросы для тех, кому и CKAD слишком сложно (все равно не сдают).&lt;/li>
&lt;/ul>
&lt;p>Все экзамены из &amp;ldquo;проф-линейки&amp;rdquo; (то есть исключая CKAN) стоят по 400$ за попытку, сдать их надо за год с момента оплаты. Каждый экзамен дает право на одну бесплатную пересдачу (в течении того же самого года). Приятная особенность - сдавать экзамены можно дома. За экзамен выдают электронный именной сертификат, который действует три года и очень нравится рекрутерам :)&lt;/p>
&lt;h2 id="процесс-сдачи" >Процесс сдачи
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%be%d1%86%d0%b5%d1%81%d1%81-%d1%81%d0%b4%d0%b0%d1%87%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Процесс в целом похож на классический экзамен для получения сертификата. Проводится он на английском языке (для ценителей есть японский и китайский варианты). Экзамен сдается дома с помощью прокторинга - нужно предоставить специальной программе доступ к рабочему столу компьютера и камере, специальный человек по ту сторону экрана (проктор) будет следить, чтобы экзаменуемый не списывал и ему не подсказывали. В целом условия довольно типичные:&lt;/p>
&lt;ul>
&lt;li>Нельзя иметь при себе какие-либо смарт-устройства (телефон, смарт-часы, ноутбук)&lt;/li>
&lt;li>На столе не может быть ничего, кроме, собственно, компа для сдачи&lt;/li>
&lt;li>Напитки разрешены только прозрачные и в прозрачной же таре&lt;/li>
&lt;li>На старте экзамена проктор просит показать два разных ID, одно из которых должно иметь ФИО латиницей (именно так, как оно записано в заявке на экзамен) и фото.&lt;/li>
&lt;li>Комната должна быть пуста и в ней не должно быть других людей&lt;/li>
&lt;li>Запрещены наушники&lt;/li>
&lt;/ul>
&lt;p>Экзамен идет 2 часа (раньше было 3, поменяли в прошлом году) и времени, на самом деле, довольно мало. Многие из сдающих не успевают ответить на все вопросы, я слышал это много раз. Все вопросы (это важная часть) - практические, в экзамене вообще нет теоретических вопросов. Это, на самом деле, один из основных секретов сложности экзамена &amp;ndash; так, как нет теоретических вопросов &amp;ndash; их невозможно списать и заучить. Вместо этого в рамках экзамена выдается тестовое окружение (SSH консоль прямо в окне браузера) и практические задачи что-то сделать: создать/удалить deployment, привязать secret и так далее. Вопросы можно условно поделить на &amp;ldquo;простые&amp;rdquo; и &amp;ldquo;сложные&amp;rdquo;, за &amp;ldquo;сложные&amp;rdquo; дают больше баллов. Именно по этому имеет смысл сначала просмотреть все вопросы. Если на вопрос можно сразу ответить (меньше, чем за минуту) - отвечаем, нет &amp;ndash; идем дальше. После этого имеет смысл уделить время сложным вопросам, чтобы заработать больше баллов. На 2 часа выдается порядка 20 вопросов, то есть это 6 минут на вопрос в среднем. Быстрее ответите на простые вопросы &amp;ndash; больше времени будет на сложные. В процессе экзамена никаких подсказок не будет, балл сразу тоже не покажут &amp;ndash; письмо с оценкой приходит через сутки-двое. На экзамене разрешено использовать официальную документацию kubernetes (с оффсайта), включая справочник по API. Так же можно использовать github проекта (там есть референсные конфигурации, например - готовые конфиги PV/PVC). В принципе можно использовать и встроенные механизмы помощи (&lt;code>kubectl explain&lt;/code>, &lt;code>kubectl api-resources&lt;/code>). Ничего другого (google, kubernetes discussion forum, SO) - использовать нельзя, это кончается дисквалификацией. Официальное руководство разрешает сделать необходимые закладки заранее &amp;ndash; этим обязательно надо пользоваться.&lt;/p>
&lt;h2 id="подготовка" >Подготовка
&lt;span>
&lt;a href="#%d0%bf%d0%be%d0%b4%d0%b3%d0%be%d1%82%d0%be%d0%b2%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Сдать CKA без подготовки невозможно. Нет, возможно, конечно, если вас зовут Келси Хайтауэр, Андрей Квапил или Бильям Ибрагим (вот насчет последнего не уверен). Так, как экзамен практический &amp;ndash; нужно тренировать именно практические вопросы и тренировать их на скорость:&lt;/p>
&lt;ul>
&lt;li>создание-изменение-скейлинг deployment-ов.&lt;/li>
&lt;li>редактура разных компонентов (apply/inline edit/patch). Нужно держать в памяти иммутабельные поля, чтобы не споткнуться на экзамене.&lt;/li>
&lt;li>создание-редактирование сервисов.&lt;/li>
&lt;li>создание-редактирование pod-ов. Последнее может пригодиться для отладки, когда нужно посмотреть на кластер &amp;ldquo;изнутри&amp;rdquo; и проще поднять busybox или netshot.&lt;/li>
&lt;li>создание configmap-ов и secret-ов, они очень часто попадаются.&lt;/li>
&lt;/ul>
&lt;p>Очень рекомендую запомнить и потренировать императивный подходы к вышеперечисленному, чтобы не писать длинный yaml с нуля. Это еще помогает быстро создать &amp;ldquo;скелет&amp;rdquo; конфигурации примерно таким образом: &lt;code>kubectl create deploy nginx --replicas=2 --image=nginx:stable -o yaml --dry-run=client &amp;gt; nginx-deploy.yaml&lt;/code>&lt;/p>
&lt;p>Я очень рекомендую пройтись по списку всех основных примитивов (по документации или книге) и понять, чем, к примеру, отличается service от ingress а daemonset от statefulset. Так же очень советую сделать лабораторную работу &lt;a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">Kubernetes hard way&lt;/a>. Вам абсолютно точно не придется делать этого на экзамене - это слишком долго. Но эта задача позволит понять, из каких компонент K8s состоит, как они взаимодействуют друг с другом и что происходит, когда они ломаются. Для прогона практики можно арендовать сервер в Linode (новоприбывшим дают 100$ кредита на 2 месяца) или в больших облаках (там тоже есть бонус для новичков, главное &amp;ndash; следить за балансом). Машины с 4Gb RAM хватит для большинства лабораторных (исключая те, что про CNI - там нужно две машины в одной сети). Практика - 70% успеха на этом экзамене.&lt;/p>
&lt;p>Если душа лежит к видеокурсам &amp;ndash; обязательно берите те, где есть практические задачи (hands-on labs). Мне в свое время помог &lt;a href="https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests">курс&lt;/a> от Мумшада Манамбета (но один курс вас не спасет, практика обязательна и тут она важнее теории).&lt;/p>
&lt;p>Условия экзамена разрешают использовать закладки - и их нужно обязательно подготовить. Я готовил закладки сам и поделил их на 3 группы:&lt;/p>
&lt;ul>
&lt;li>справочники и прочая теория (API, описание certifications API, CNI, CRI).&lt;/li>
&lt;li>практические задачи из официальной документации. В стиле &amp;ldquo;как обновить k8s через kubeadm на специфичную версию&amp;rdquo;, &amp;ldquo;как создать и затем использовать секрет&amp;rdquo;&lt;/li>
&lt;li>готовые референсные конфиги (yaml с готовым рабочим примитивом).&lt;/li>
&lt;/ul>
&lt;p>В сети есть некоторое количество уже готовых подборок закладок, вот &lt;a href="https://gist.github.com/prudnitskiy/e71c819743aaea142b1ae58bd4d862b3">эта&lt;/a> подборка от ITNext мне показалась лучшей.&lt;/p>
&lt;p>В рамках подготовки к экзамену, если он уже оплачен &amp;ndash; появляется возможность взять тестовые сессии на [killer.sh]. Бесплатно доступно 3 сессии, каждая такая сессия доступна сутки с момента запроса. По моим ощущениям - эти сессии слегка сложнее реального экзамена, но не радикально. Эти сессии помогут понять, как идет реальный экзамен (там даже интерфейс такой же, только проктора нет).&lt;/p>
&lt;h2 id="чего-я-делать-не-советую" >Чего я делать не советую
&lt;span>
&lt;a href="#%d1%87%d0%b5%d0%b3%d0%be-%d1%8f-%d0%b4%d0%b5%d0%bb%d0%b0%d1%82%d1%8c-%d0%bd%d0%b5-%d1%81%d0%be%d0%b2%d0%b5%d1%82%d1%83%d1%8e">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Первое и самое главное &amp;ndash; сильно не советую жульничать. Экзамен сдается через Pearson Vue, в наихудшем случае это кончится баном в PV и аннуляцией уже выданных сертификатов (да, их EULA такое позволяет). Экзамен непростой, но если озаботиться подготовкой &amp;ndash; сдать его вполне реально. Многие статьи рекомендуют выучить hotkey-и для tmux и идеально владеть vim. ИМХО, если вы не умеете &amp;ndash; тратить время не стоит. Если vim вам прямо совсем не дается &amp;ndash; на тестовой машине есть nano, нужно просто знать, как переключить редактор (через переменную &lt;code>EDITOR&lt;/code>). Tmux вообще не нужен на экзамене. Так же не советую пытаться что-то запмнить наизусть &amp;ndash; официальная документация и подсказки из API всегда доступны. Тратить силы и время на именно запоминание каких-то цифр или команд &amp;ndash; просто расточительство и никак не поможет.&lt;/p>
&lt;p>Не советую назначать экзамен после окончания рабочего дня или в сильно неудобное время &amp;ndash; экзамен требует полной сосредоточенности, отвлечение может стоить вам баллов, и, как следствие, сертификата.&lt;/p>
&lt;h2 id="на-что-обращать-внимание-на-экзамене" >На что обращать внимание на экзамене
&lt;span>
&lt;a href="#%d0%bd%d0%b0-%d1%87%d1%82%d0%be-%d0%be%d0%b1%d1%80%d0%b0%d1%89%d0%b0%d1%82%d1%8c-%d0%b2%d0%bd%d0%b8%d0%bc%d0%b0%d0%bd%d0%b8%d0%b5-%d0%bd%d0%b0-%d1%8d%d0%ba%d0%b7%d0%b0%d0%bc%d0%b5%d0%bd%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Главное &amp;ndash; на &lt;em>время&lt;/em>. Его &lt;em>очень мало&lt;/em> и важность времени трудно переоценить. Если вы чувствуете, что застряли в задаче &amp;ndash; поставьте флажок и двигайтесь дальше. Если будет время &amp;ndash; потом вернетесь. Следующее, на что я советую обращать внимание &amp;ndash; на формулировку задачи. В формулировке есть все необходимое, но там может скрываться важная подсказка, которую легко упустить: указание на определенный namespace, label, граничное условие. Авторы тестов такие вопросы очень любят, проколоться элементарно. Результат? Незачет вопроса.&lt;/p>
&lt;p>Если вы ответили на все вопросы, а время еще осталось (хотя бы минут 5-10) &amp;ndash; пройдитесь по вопросам еще раз, прочитайте формулировки и проверьте решение. Одну свою задачу я переделывал, ибо поторопился. Простые задачи в целом довольно прямолинейные и если вы уделили время практике &amp;ndash; проблем быть не должно - развернуть сервис, написать политику безопасности, дать пользователю права, привязать-отвязать диск, организовать двум сервисам общение друг с другом, разобраться, почему сервис не стартует&amp;hellip; Нормальные задачи нормального админа. Сложность у задач, как я уже говорил, разная. Сложная задача видна сразу, уже по формулировкам понятно, что она даст много баллов. Если задачу можно решить несколькими способами &amp;ndash; они все идут в зачет (проверяется результат, а не способ). Но опять же, проверяйте условия задачи!&lt;/p>
&lt;h2 id="заключение" >Заключение
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Не смотря на страшный имидж - экзамен совсем не такой сложный, каким хочет казаться. Низкий процент успеха продиктован, думаю, физическим отсутствием дампов (теоретических вопросов-то нет!). При наличии времени на подготовку и некоторых теоретических знаний о том, как работает Linux сдать его будет не смертельно сложно. Главное - следить за временем, быть внимательным и потратить время на подготовку. Экзамен покрывает разные топики и человек, который его сдал - скорее всего знает k8s на приличном уровне. Даже сама подготовка - хорошая ревизия знаний и умений в этой области.&lt;/p>
&lt;p>Удачи на экзамене!&lt;/p></description></item><item><title>Распределяем pod-ы по машинам в kubernetes</title><link>https://prudnitskiy.pro/post/2021-01-15-k8s-pod-distribution/</link><pubDate>Fri, 15 Jan 2021 08:16:22 +0000</pubDate><guid>https://prudnitskiy.pro/post/2021-01-15-k8s-pod-distribution/</guid><description>&lt;p>Kubernetes иногда называют &amp;ldquo;операционной системой для дата-центров&amp;rdquo; &amp;ndash; и в этом есть логика. K8s позволяет представить группу серверов (условный ЦОД) как единое вычислительное пространство. Оператор просто бросает задания в K8s, а тот сам выбирает, где тот или иной контейнер лучше разместить. Чаще всего делает это он хорошо. Но иногда появляется необходимость как-то управлять этим процессом. Об этом я и расскажу.&lt;/p>
&lt;h2 id="зачем-управлять-распределением-pod-ов" >Зачем управлять распределением POD-ов?
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d1%87%d0%b5%d0%bc-%d1%83%d0%bf%d1%80%d0%b0%d0%b2%d0%bb%d1%8f%d1%82%d1%8c-%d1%80%d0%b0%d1%81%d0%bf%d1%80%d0%b5%d0%b4%d0%b5%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5%d0%bc-pod-%d0%be%d0%b2">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Зачем вообще нужно привязывать поды к определенным узлам? Это может быть связано с производительностью, безопасностью или надежность. Например &amp;ndash; pod может требовать доступ к специфическому железу (видеокарты и ML-ускорители для задач машинного обучения, аппаратные криптоускорители). Это может быть продиктовано безопасностью: критические части проекта будут размещаться на машинах, где физически не может быть ничего, кроме них. Это снижает шансы на то, что удачный взлом, скажем, сервиса регистраций раскроет данные о платежах. Некоторые стандарты безопасности (включая PCI DSS) имеют даже требования к физической безопасности серверов &amp;ndash; датчики вскрытия, пломбы на корпусках, запрет на доступ. Отдельная удобная особенность &amp;ndash; tier-инг. Нагрузку в кластере можно разделить на &amp;ldquo;важную&amp;rdquo; и &amp;ldquo;не очень&amp;rdquo;. Под важную выделять мощные современные машины с резервированием PSU, горячей замены дисков и памяти, под &amp;ldquo;не очень&amp;rdquo; &amp;ndash; соскрести какой-нибудь хлам. В облаках это делается даже проще за счет spot instances. Такие инстансы дешевле (порой радикально), но их работу никто не гарантирует &amp;ndash; инстанс может отключится в любой момент (вместо него появится новый). Это вызовет пересоздание POD-ов, но для чего-то маловажного это, может &amp;ndash; и не страшно совсем.&lt;/p>
&lt;h2 id="способы-управления" >Способы управления
&lt;span>
&lt;a href="#%d1%81%d0%bf%d0%be%d1%81%d0%be%d0%b1%d1%8b-%d1%83%d0%bf%d1%80%d0%b0%d0%b2%d0%bb%d0%b5%d0%bd%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;h3 id="nodeselector" >NodeSelector
&lt;span>
&lt;a href="#nodeselector">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Это самый простой способ управления аллокацией. Он предельно прямолинеен &amp;ndash; запутаться в нем невозможно. Выполняется в 2 этапа. Сначала надо поставить метки на node командой label:&lt;/p>
&lt;pre>&lt;code>kubectl label nodes snowflake3 disk=hdd
&lt;/code>&lt;/pre>
&lt;p>Проверить, какие метки уже есть можно через &lt;code>kubectl describe nodes&lt;/code>&lt;/p>
&lt;p>Теперь можно указать pod-у требование на привязку к конкретной метке. Для аллокации пода будут использоваться только помеченые узлы, то есть при включении nodeSelector для пода ноды без меток будут игнорироваться:&lt;/p>
&lt;pre>&lt;code>apiVersion: v1
kind: Pod
metadata:
name: nginx
labels:
env: test
spec:
containers:
- name: nginx
image: nginx
nodeSelector:
disk: hdd
&lt;/code>&lt;/pre>
&lt;p>Для deployment nodeSelector передается в шаблон pod-а, как обычно. Не смотря на удобство и прямолинейность подхода &amp;ndash; nodeSelector имеет три минуса:&lt;/p>
&lt;ul>
&lt;li>nodeSelector применяется в момент аллокации пода и бесполезен, если под уже аллоцирован. Если вам нужно &amp;ldquo;освободить&amp;rdquo; ноду &amp;ndash; придется поставить на нее метку и затем выкинуть оттуда поды командой &lt;code>drain&lt;/code>&lt;/li>
&lt;li>nodeSelector не особенно гибкий и работает по принципу &amp;ldquo;один к одному&amp;rdquo;. К примеру, можно сделать метки для машин &lt;code>small&lt;/code>, &lt;code>medium&lt;/code> и &lt;code>large&lt;/code> и указать поду, что он должен развернуться на машине класса &lt;code>small&lt;/code>. Но нельзя &amp;ndash; на машине класса &lt;code>medium&lt;/code> или &lt;code>large&lt;/code> &amp;ndash; возможен только один вариант.&lt;/li>
&lt;li>nodeSelector не запрещает аллокаций. То есть на машине с меткой могут размещаться поды без nodeAffinity. Для решения этой проблемы придуман иной подход.&lt;/li>
&lt;/ul>
&lt;h3 id="taints-and-tolerations" >Taints and Tolerations
&lt;span>
&lt;a href="#taints-and-tolerations">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Taints &amp;ndash; это NodeAffinity наоборот. Если nodeAffinity говорит scheduler-у, где он должен размещать pod-ы, то taint говорит, где pod-ы размещать &lt;em>нельзя&lt;/em>. Любой taint запрещает размещение на машине любых подов (есть одно исключение, про него дальше). Однако можно создать под, который будет игнорировать (&lt;code>tolerate&lt;/code>) этот запрет &amp;ndash; и данный pod запустится на данной машине. Даже если у вас есть совершенно пустой нормальный кластер kubernetes &amp;ndash; у вас уже есть taint. По умолчанию kubernetes запрещает размещать обычные поды на master nodes &amp;ndash; это taint &lt;code>node-role.kubernetes.io/master&lt;/code>&lt;/p>
&lt;p>taint создается с помощью команды &lt;code>kubectl taint&lt;/code>. Общий вид:&lt;/p>
&lt;pre>&lt;code>kubectl taint nodes nodeName taintKey=taintValue:taintEffect
&lt;/code>&lt;/pre>
&lt;p>taintKey и taintValue &amp;ndash; это просто метки, они могут быть произвольными. У taintEffect есть 3 возможных значения:&lt;/p>
&lt;ul>
&lt;li>NoSchedule &amp;ndash; новые поды не будут аллоцироваться, однако существующие продолжат свою работу&lt;/li>
&lt;li>PreferNoSchedule &amp;ndash; новые поды не будут аллоцироваться, если в кластере есть свободное место&lt;/li>
&lt;li>NoExecute &amp;ndash; все запущенные поды без tolerations должны быть убраны&lt;/li>
&lt;/ul>
&lt;p>Теперь о том, как прописываются tolerations. Язык tolerations слегка сложнее прямолинейного подхода nodeAffinity:&lt;/p>
&lt;pre>&lt;code>apiVersion: v1
kind: Pod
metadata:
name: nginx
labels:
env: test
spec:
containers:
- name: nginx
image: nginx
tolerations:
- key: &amp;quot;pft-env&amp;quot;
operator: &amp;quot;Exists&amp;quot;
effect: &amp;quot;NoSchedule&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>в данном примере мы создадим под, который будет игнорировать taint, созданный вот такой командой:&lt;/p>
&lt;pre>&lt;code>kubectl taint nodes pft-node-1 pft-env=true:NoSchedule
&lt;/code>&lt;/pre>
&lt;p>Есть более сложный вариант &amp;ndash; можно учитывать не только факт наличия метки, но и ее значение. Создадим пару taint-ов:&lt;/p>
&lt;pre>&lt;code>kubectl taint nodes secure-1 secGroup=secure:NoSchedule
kubectl taint nodes insecure-2 secGroup=unsafe:NoSchedule
apiVersion: v1
kind: Pod
metadata:
name: vault
labels:
env: test
spec:
containers:
- name: vault
image: vault
tolerations:
- key: &amp;quot;secGroup&amp;quot;
operator: &amp;quot;Equals&amp;quot;
value: &amp;quot;secure&amp;quot;
effect: &amp;quot;NoSchedule&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>В данном примере pod vault будет создан только на ноде secure-1, потому что только на ней &lt;code>secGroup&lt;/code> равен &lt;code>secure&lt;/code>.&lt;/p>
&lt;p>Taint-ов можно создать сколь угодно много и условия проверки можно сочетать, как в примере ниже:&lt;/p>
&lt;pre>&lt;code>apiVersion: v1
kind: Pod
metadata:
name: processing
labels:
env: test
spec:
containers:
- name: processing
image: processing
tolerations:
- key: &amp;quot;dedicatedNode&amp;quot;
operator: &amp;quot;Exists&amp;quot;
effect: &amp;quot;NoSchedule&amp;quot;
- key: &amp;quot;secGroup&amp;quot;
operator: &amp;quot;Equals&amp;quot;
value: &amp;quot;secure&amp;quot;
effect: &amp;quot;NoExecute&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>В данном примере мы выделяем пул выделенных машин taint-ом &amp;ldquo;dedicatedNode&amp;rdquo; и отдельно помечаем группу максимальной безопасности значением secure для группы secGroup.&lt;/p>
&lt;p>Удалить taint можно, добавив в конец знак минуса:&lt;/p>
&lt;pre>&lt;code>kubectl taint nodes secure-1 secGroup=secure:NoSchedule-
&lt;/code>&lt;/pre>
&lt;h3 id="nodeaffinity" >nodeAffinity
&lt;span>
&lt;a href="#nodeaffinity">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Не смотря на простоту и эффективность механизма nodeSelector &amp;ndash; механизм это прямолинейный и не особенно гибкий. Авторы kubernetes предлагают более мощный, гибкий (а так же &amp;ndash; сложный и неудобный) механизм &amp;ndash; nodeAffinity. Язык описания nodeAffinity предлагает несколько мощных возомжностей:&lt;/p>
&lt;ul>
&lt;li>логические операторы для выбора условия размещения &amp;ndash; IN (размещать на одной из нод с разными метками) или AND (размещать на нодах, имеющих обе метки сразу)&lt;/li>
&lt;li>можно выбраить политики размещения pod-ов относительно друг друга: например &amp;ndash; запретить экземплярам кэша оказываться на одной физической машине или требовать размещение приложения вместе с экземпляром кеша на одном физическом узле&lt;/li>
&lt;/ul>
&lt;p>Минус nodeAffinity в том, что язык очень многословный и читается тяжело. Общая спецификация выглядит так:&lt;/p>
&lt;pre>&lt;code>spec:
affinity:
nodeAffinity:
{affinityClass}:
nodeSelectorTerms:
- matchExpressions:
- key: {affinityKey}
operator: {affinityOperator}
values:
- {affinityValues}
&lt;/code>&lt;/pre>
&lt;p>affinityClass влияет на строгость выбора узла:&lt;/p>
&lt;ul>
&lt;li>requiredDuringSchedulingIgnoredDuringExecution: обязательно размещать pod-ы по требованию nodeAffinity. Если разместить не получится &amp;ndash; pod застрянет в статусе Pending&lt;/li>
&lt;li>preferredDuringSchedulingIgnoredDuringExecution: по возможности размещать pod-ы по требованиям affinity. Если поды не влезли &amp;ndash; scheduler разместит их &amp;ldquo;как получится&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;p>affinityKey &amp;ndash; это метка (ключ), по которой мы будем искать ноды для размещения pod-ов.
affinityValues &amp;ndash; это значения метки, которые нам подойдут
affinityOperator &amp;ndash; это тот логический оператор, по которому будет производится выбор метки. Варианты:&lt;/p>
&lt;ul>
&lt;li>In &amp;ndash; подойдет любое из перечисленных значений&lt;/li>
&lt;li>NotIn &amp;ndash; противоположно In&lt;/li>
&lt;li>Exists &amp;ndash; метка просто есть (values игнорируется)&lt;/li>
&lt;li>DoesNotExists &amp;ndash; противоположно Exists&lt;/li>
&lt;li>Gt &amp;ndash; Greater than &amp;ndash; значение метки больше указанного в политике числа. Сработает только для чисел&lt;/li>
&lt;li>Lt &amp;ndash; Less than &amp;ndash; противоположно Gt&lt;/li>
&lt;/ul>
&lt;p>affinityClass preferredDuringSchedulingIgnoredDuringExecution слегка отличается &amp;ndash; вместо nodeSelectorTerms используется поле preference (синтаксис такой же), плюс есть обязательное поле weight &amp;ndash; оно отвечает за приоритет при выборе node.&lt;/p>
&lt;p>Пример:&lt;/p>
&lt;pre>&lt;code>apiVersion: v1
kind: Pod
metadata:
name: nginx-with-node-affinity
spec:
affinity:
nodeAffinity:
requiredDuringSchedulingIgnoredDuringExecution:
nodeSelectorTerms:
- matchExpressions:
- key: kubernetes.io/e2e-az-name
operator: In
values:
- e2e-az1
- e2e-az2
preferredDuringSchedulingIgnoredDuringExecution:
- weight: 1
preference:
matchExpressions:
- key: kubernetes.io/node-tier
operator: In
values:
- silver
- bronze
containers:
- name: with-node-affinity
image: k8s.gcr.io/nginx
&lt;/code>&lt;/pre>
&lt;p>affinity не учитывается для уже аллоцированных nodes, так что если нужно освободить node-у от всех подов которые там уже есть &amp;ndash; поможет команда &lt;code>kubectl node drain&lt;/code>&lt;/p>
&lt;h4 id="лирическое-отступление----podaffinitty-и-podantiaffinitty" >Лирическое отступление &amp;ndash; PodAffinitty и PodAntiAffinitty
&lt;span>
&lt;a href="#%d0%bb%d0%b8%d1%80%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%be%d0%b5-%d0%be%d1%82%d1%81%d1%82%d1%83%d0%bf%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5----podaffinitty-%d0%b8-podantiaffinitty">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h4>&lt;p>Механизм, который помогает размещать pod-ы относительно нод &amp;ndash; может так же помочь и разместить pod-ы относительно друг друга &amp;ndash; за это отвечают классы PodAffinity и PodAntiAffinity. Все три класса можно сочетать друг с другом, синтаксис внутри одинаковый, по этому просто покажу пример:&lt;/p>
&lt;pre>&lt;code>apiVersion: apps/v1
kind: Deployment
metadata:
name: redis-cache
spec:
selector:
matchLabels:
app: store
replicas: 3
template:
metadata:
labels:
app: store
spec:
affinity:
podAntiAffinity:
requiredDuringSchedulingIgnoredDuringExecution:
- labelSelector:
matchExpressions:
- key: app
operator: In
values:
- store
topologyKey: &amp;quot;kubernetes.io/hostname&amp;quot;
containers:
- name: redis-server
image: redis:3.2-alpine
&lt;/code>&lt;/pre>
&lt;p>В этом примере мы запрещаем экземплярам redis размещаться на одном узле. Каждый pod в этом deployment получит метку &lt;code>app:store&lt;/code>, политика podAntiAffinity запрещает размещать второй под с меткой app=store на ноде с таким же hostname. Важный параметр тут &amp;ndash; topologyKey. Именно по нему scheduler понимает, какие node-ы считаются одной зоной размещения,а какие &amp;ndash; нет. Усложним пример, добавив web worker:&lt;/p>
&lt;pre>&lt;code>apiVersion: apps/v1
kind: Deployment
metadata:
name: web-server
spec:
selector:
matchLabels:
app: web-store
replicas: 3
template:
metadata:
labels:
app: web-store
spec:
affinity:
podAntiAffinity:
requiredDuringSchedulingIgnoredDuringExecution:
- labelSelector:
matchExpressions:
- key: app
operator: In
values:
- web-store
topologyKey: &amp;quot;kubernetes.io/hostname&amp;quot;
podAffinity:
requiredDuringSchedulingIgnoredDuringExecution:
- labelSelector:
matchExpressions:
- key: app
operator: In
values:
- store
topologyKey: &amp;quot;kubernetes.io/hostname&amp;quot;
containers:
- name: web-app
image: nginx:1.16-alpine
&lt;/code>&lt;/pre>
&lt;p>В этом примере мы размещаем nginx на разных node (как мы сделали с redis), но при этом требуем, чтобы nginx размещался вместе с redis. Это может быть удобно для кешей. Проверим, что получилось:&lt;/p>
&lt;pre>&lt;code>&amp;gt; kubectl get pods -o wide
NAME READY STATUS RESTARTS AGE IP NODE
redis-cache-1450370735-6dzlj 1/1 Running 0 8m 10.192.4.2 kube-node-3
redis-cache-1450370735-j2j96 1/1 Running 0 8m 10.192.2.2 kube-node-1
redis-cache-1450370735-z73mh 1/1 Running 0 8m 10.192.3.1 kube-node-2
web-server-1287567482-5d4dz 1/1 Running 0 7m 10.192.2.3 kube-node-1
web-server-1287567482-6f7v5 1/1 Running 0 7m 10.192.4.3 kube-node-3
web-server-1287567482-s330j 1/1 Running 0 7m 10.192.3.2 kube-node-2
&lt;/code>&lt;/pre>
&lt;h3 id="static-pod-allocations" >Static pod allocations
&lt;span>
&lt;a href="#static-pod-allocations">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Это очень редкий случай, но не упомянуть его было бы нечестно. Pod-ы можно аллоцировать полностью статически, вручную привязав к конкретной node. В этом случае scheduler никак на них не влияет. На них не действуют taints, nodeSelector и podAffinity. Даже node drain ничего не сможет с такими подами сделать. Зачем это может потребоваться? Ну, во-первых для запуска таких pod-ов не нужен работающий scheduler или apiserver. Это делает размещение таких подов сверхнадежным &amp;ndash; они будут работать всегда. Именно так kubeadm устанавливает свои компоненты &amp;ndash; это не полноценные демоны, а контейнеры, которые вручную привязаны к master node.&lt;/p>
&lt;p>Во-вторых такой подход может потребоваться в случае, если какой-то контейнер надо привязать к конкретной, строго определенной node вручную и ни при каких условиях не давать ему оттуда уезжать. Скажем, у вас какое-то особое шифрование и оно зависит от HSM, который физически подключен к определенной, особо защищенной машине. Вообще &amp;ndash; это порочная практика и такой сценарий лучше решается через nodeSelector + taint, но мало ли?&lt;/p>
&lt;p>Выполнить статическую аллоакцию очень просто &amp;ndash; нужно положить манифесты pod-ов в папку со статическими подами. Этот путь можно задать двумя путями:&lt;/p>
&lt;ul>
&lt;li>через аргумент командной строки kubelet: &lt;code>--pod-manifest-path&lt;/code>&lt;/li>
&lt;li>через параметр конфига &lt;code>staticPodPath&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Если у вас kubernetes установлен через kubeadm &amp;ndash; этот параметр там уже есть, kubelet будет искать статические манифесты по адресу &lt;code>/etc/kubernetes/manifests&lt;/code>. Kubelet перечитывает папку с манифестами каждые 10 секунд. Если удалить манифест &amp;ndash; kubernetes удалит pod.&lt;/p>
&lt;p>Просто создадим манифест статического пода&lt;/p>
&lt;pre>&lt;code>cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/kubernetes/manifests/static-web.yaml
apiVersion: v1
kind: Pod
metadata:
name: static-web
labels:
role: static
spec:
containers:
- name: web
image: nginx
ports:
- name: web
containerPort: 80
protocol: TCP
EOF
&lt;/code>&lt;/pre>
&lt;p>И проверим, что получилось:&lt;/p>
&lt;pre>&lt;code>&amp;gt; kubectl get pods -l role=static
NAME READY STATUS RESTARTS AGE
static-web-my-node1 1/1 Running 0 2m
&lt;/code>&lt;/pre>
&lt;h2 id="порядок-применения" >Порядок применения
&lt;span>
&lt;a href="#%d0%bf%d0%be%d1%80%d1%8f%d0%b4%d0%be%d0%ba-%d0%bf%d1%80%d0%b8%d0%bc%d0%b5%d0%bd%d0%b5%d0%bd%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Первым всегда применяется static pod. Он игнорирует все (taints, affinities, node selectors).&lt;/p>
&lt;p>Вторым по списку применяется taint. Если у pod нет toleration &amp;ndash; он не будет размещен, по этому taint &amp;ndash; это очень эффективный способ &amp;ldquo;разогнать&amp;rdquo; pod-ы с определенного узла (или группы узлов).&lt;/p>
&lt;p>В случае, если есть nodeAffinity и nodeSelector &amp;ndash; должны сработать оба условия сразу (то есть &amp;ndash; и метка селектора и условия affinity).&lt;/p>
&lt;h2 id="заключение" >Заключение
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Kubernetes &amp;ndash; мощный, богатый на возможности инструмент. Он кажется слегка неудобным, но ровно до момента понимания логики его работы. Scheduler у kubernetes практически ключевой компонент, и он достаточно гибок, пусть и не самым лучшим образом описан. Надеюсь &amp;ndash; эта статья кому-то поможет. Высокого вам аптайма!&lt;/p></description></item><item><title>Restic: backup для современного мира</title><link>https://prudnitskiy.pro/post/2020-06-23-restic-quickstart/</link><pubDate>Tue, 23 Jun 2020 23:00:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2020-06-23-restic-quickstart/</guid><description>&lt;p>Restic - это простой, надежный, быстрый и эффективный способ резервного копирования. Простой в установке и настройке, с поддержкой большого количества бэкендов хранения, надежным шифрованием и дедупликацией. Это прекрасный инструмент для резервного копирования в современном ИТ-ландшафте. Тут я расскажу, зачем он нужен, как его поставить и начать им пользоваться.&lt;/p>
&lt;h1 id="теоретическая-часть" >Теоретическая часть
&lt;span>
&lt;a href="#%d1%82%d0%b5%d0%be%d1%80%d0%b5%d1%82%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%b0%d1%8f-%d1%87%d0%b0%d1%81%d1%82%d1%8c">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h1>&lt;h2 id="предыстория" >Предыстория
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%b5%d0%b4%d1%8b%d1%81%d1%82%d0%be%d1%80%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Исторически сложилось, что системы резервного копирования устроены очень сложно. Их сложно устанавливать, настраивать и сопровождать. Руководство к Veritas NetBackup (в дальнейшем - Symantec) имеет размеры приличной книги, по этой системе можно сдать экзамен и получить сертификат. Конфиг Amanda или Bacula весит под сотню килобайт, а официальное руководство занимает больше 500 страниц. Разумеется - у этой поражающей сложности есть простая, понятная, логичная причина, даже две:&lt;/p>
&lt;ul>
&lt;li>ненадежность медиа&lt;/li>
&lt;li>сложность процедуры бэкапа&lt;/li>
&lt;/ul>
&lt;h3 id="ненадежные-медиа" >Ненадежные медиа
&lt;span>
&lt;a href="#%d0%bd%d0%b5%d0%bd%d0%b0%d0%b4%d0%b5%d0%b6%d0%bd%d1%8b%d0%b5-%d0%bc%d0%b5%d0%b4%d0%b8%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Резервные копии надо где-то хранить. Традиционно используются цифровые кассеты (DAT/DLT), CD (в дальнейшем - DVD и BD) ROM/RW и жесткие диски. Проблема физических медиа в их не абсолютной надежности: кассеты размагничиваются и осыпаются, диски - царапаются и страдают от деградаций красочного слоя, про жесткие диски и говорить нечего. Из-за этого &amp;ldquo;классические&amp;rdquo; системы резервного копирования имеют сложные структуры расписаний и управление медиа-пулом. Медианосители надо постоянно перетасовывать, чтобы нагрузка на чтение и запись была равномерной и чтобы не оказалось, что весь огромный многотеррабайтный бэкап зависит от одного-единственного диска, который только что рассыпался в дисководе. Сложное расписание умножается на сложную структуру бэкапов (полный, инкрементальный, дифференциальный) где каждый слой зависит от другого. Это делается для экономия места и времени бэкапа. Кроме этого медиа ограничены в размере, а потому - нужно иметь возможность точно отфильтровать файлы и писать только то, что реально необходимо.&lt;/p>
&lt;h3 id="сложная-процедура-бэкапа" >Сложная процедура бэкапа
&lt;span>
&lt;a href="#%d1%81%d0%bb%d0%be%d0%b6%d0%bd%d0%b0%d1%8f-%d0%bf%d1%80%d0%be%d1%86%d0%b5%d0%b4%d1%83%d1%80%d0%b0-%d0%b1%d1%8d%d0%ba%d0%b0%d0%bf%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>В классическом традиционном ИТ-подходе бэкап - это очень сложная процедура. Бэкапим мы файлы, но данные нельзя воспринимать как файлы - они меняются. Бэкап файлов &amp;ldquo;в лоб&amp;rdquo; провоцирует инконсистентные данные, когда что-то поменялось на ходу и часть файлов находится в состоянии &amp;ldquo;до&amp;rdquo;, а часть - уже &amp;ldquo;после&amp;rdquo;. В том же Veritas NetBackup львиную долю цены лицензий состовляла цена агентов - сущностей, которые помогали бэкапить конкретные базы (Oracle, MSSQL) или состояния конкретных продуктов (SAP, BAAN). Агент знал, как &amp;ldquo;заморозить&amp;rdquo; состояние системы и получить консистентный бэкап, без него резервное копирование превращалось в лотерею. В opensource решениях агентов обычно нет, но родовые травмы в виде PreTask/PostTask остались - нужно подготовить данные к резервному копированию, а потом - вывести систему из этого состояния.&lt;/p>
&lt;h2 id="restic-новый-подход" >Restic: новый подход
&lt;span>
&lt;a href="#restic-%d0%bd%d0%be%d0%b2%d1%8b%d0%b9-%d0%bf%d0%be%d0%b4%d1%85%d0%be%d0%b4">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Restic задуман как резервное копирование для современного ИТ-мира. Он имеет простой (предельно простой) интерфейс и минимум настроек. Одно из главных нововведений Restic - отказ от сложных медиа-операций. В современном ИТ в качестве системы хранения используется внешний сервис хранения, доступный обычно по S3 (Amazon S3, Azure BlobStorage, DigitalOcean Spaces, Minio на собственном оборудовании) или через прослойку в виде rclone (dropbox, Yandex.Disk). Restic предполагает такой бэкенд &lt;em>небезопасным, но надежным&lt;/em>. Разумеется, данные внутри Amazon S3 хранятся на медиа, и медиа эти ненадежны. Однако между пользователем и медиа - несколько слоев абстракции, которые защищают данные, следят за их целостностью и верификацией. RAID-контроллеры, Erasure Codes, репликация между серверами-стойками-датацентрами, media scrubbing, check-суммы блоков - технологий десятки, если не сотни. По словам Dropbox - 80% трафика внутри их датацентров составляет служебный трафик, верификация, репликация и проверки данных, и только 20% - это собственно пользовательские данные. Restic исходит из идеи, что данные во внешнем хранилище содержатся вполне надежно и шансы получить битый или потеряный блок - минимальны. Именно по этому в Restic &lt;strong>нет разделения на типы бэкапов - полные, инкрементальные и дифференциальные&lt;/strong>. Вместо этого предложен механизм snapshot-тов. Это просто снимок состояния системы в момент времени.&lt;/p>
&lt;h3 id="как-хранятся-данные" >Как хранятся данные
&lt;span>
&lt;a href="#%d0%ba%d0%b0%d0%ba-%d1%85%d1%80%d0%b0%d0%bd%d1%8f%d1%82%d1%81%d1%8f-%d0%b4%d0%b0%d0%bd%d0%bd%d1%8b%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Так как restic предполагает, что медиа - небезопасно - все данные шифруются AES256-CTR. Ключ AES шифруется паролем. Содержимое файлов нарезается на блоки (blobs) переменной длины (от 512кб до 8Мб), при этом каждый blob имеет контрольную сумму (CDC). Блоки упаковываются в пачки (pack). Пачка хранит в себе содержимое файла с метаданными или дерево (то есть - хранит в себе ссылки на другие пачки - файлы). Разные пачки могут ссылаться на один и тот же blob, что позволяет значительно экономить место. На самом верху этой пирамиды восседает snapshot, который хранит метаданные о, собственно, бэкапе (кто, когда, где) и ссылку на пачку с деревом верхнего уровня. При этом разные snapshot-ы могут ссылаться на одни и те же пачки деревьев, а пачки деревьев - на одни и те же пачки файлов (если файлы не менялись). Restic имеет удобную команду &lt;code>restic cat blob &amp;lt;blobId&amp;gt;&lt;/code>, которая позволяет посмотреть в содержимое конкретного блоба и выяснить, что там лежит.&lt;/p>
&lt;h1 id="практическая-часть" >Практическая часть
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%b0%d0%ba%d1%82%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%b0%d1%8f-%d1%87%d0%b0%d1%81%d1%82%d1%8c">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h1>&lt;h2 id="установка-и-инициализация-repository" >Установка и инициализация repository
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d0%b8-%d0%b8%d0%bd%d0%b8%d1%86%d0%b8%d0%b0%d0%bb%d0%b8%d0%b7%d0%b0%d1%86%d0%b8%d1%8f-repository">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Restic написан на go и потому распространяется в виде единственно бинарного файла, который содержит все необходимое. В Debian и Ubuntu он есть в виде пакета, так что поставить можно традиционно:&lt;/p>
&lt;pre>&lt;code>apt-get install -y restic
&lt;/code>&lt;/pre>
&lt;p>Ну или просто скачать готовый binary &lt;a href="https://github.com/home/projects/restic/releases/">отсюда&lt;/a>.&lt;/p>
&lt;p>После установки нужно инициализировать repo. При этом restic сгенерирует ключ для шифрования и создаст структуру каталогов для хранения blob-ов, паков и snapshot-ов. Тут нужно сделать небольшое отступление: в рамках одного repo можно хранить бэкапы разных каталогов и даже разных хостов. Структура repo restic-а позволяет это делать и бэкапы не будут пересекаться друг с другом (hostname и path бэкапа - обязательный атрибут snapshot-а, так что можно легко отфильтровать нужный). Блобы общие в рамках repo, по этому если три разных хоста хранят одинаковый файл - в repo он будет хранится в одном блобе, что позволит сэкономить место.&lt;/p>
&lt;p>Инициализация выполняется командой &lt;code>init&lt;/code>&lt;/p>
&lt;pre>&lt;code># для локальной файловой системы:
restic init --repo /mnt/disk0/backup-repo
# для S3-совместимых серверов (Minio, CEPH ObjGateway)
export AWS_ACCESS_KEY_ID=&amp;lt;MY_ACCESS_KEY&amp;gt;
export AWS_SECRET_ACCESS_KEY=&amp;lt;MY_SECRET_ACCESS_KEY&amp;gt;
restic init --repo s3:https://my.local.server/backup-repo
# для Amazon S3 (European bucket)
export AWS_ACCESS_KEY_ID=&amp;lt;MY_ACCESS_KEY&amp;gt;
export AWS_SECRET_ACCESS_KEY=&amp;lt;MY_SECRET_ACCESS_KEY&amp;gt;
restic init -o s3.region=&amp;quot;eu-west-1&amp;quot; --repo s3://s3.eu-west-1.amazonaws.com/bucketName/backupRepo
&lt;/code>&lt;/pre>
&lt;p>Главное - не забыть пароль, про который спросит restic. Именно этим паролем шифруется ключ и если пароль посеять - шансов на распаковку будет примерно ноль.&lt;/p>
&lt;h2 id="типовые-операции" >Типовые операции
&lt;span>
&lt;a href="#%d1%82%d0%b8%d0%bf%d0%be%d0%b2%d1%8b%d0%b5-%d0%be%d0%bf%d0%b5%d1%80%d0%b0%d1%86%d0%b8%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;h3 id="бэкап" >Бэкап
&lt;span>
&lt;a href="#%d0%b1%d1%8d%d0%ba%d0%b0%d0%bf">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Бэкап - основная операция, которая выполняется (по-хорошему), чаще всего:&lt;/p>
&lt;pre>&lt;code>restic -r /mnt/disk0/backup-repo backup /home/projects
&lt;/code>&lt;/pre>
&lt;p>Не всегда нужны все файлы. Для таких случаев есть ключ &lt;code>--exclude-file&lt;/code>. В этот можно добавить как конкретные файлы и папки (путь должен быть относительным, от корня бэкапа), так и regexp. Для парсинга файла используется filepath.Glob, так что синтаксис в деталях можно посмотреть &lt;a href="https://golang.org/pkg/path/filepath/#Match">тут&lt;/a>.&lt;/p>
&lt;p>Пример файла:&lt;/p>
&lt;pre>&lt;code># просто папки
tmp
out
# файлы по расширению
*.deb
*.rpm
*.pyc
*.pyo
# файлы по пути. К примеру /home/projects/a/b/c/temp /home/projects/a/temp /home/projects/temp
/home/projects/**/temp
&lt;/code>&lt;/pre>
&lt;h3 id="получение-списка-snapshot-ов-из-которых-можно-восстанавливать" >Получение списка snapshot-ов (из которых можно восстанавливать):
&lt;span>
&lt;a href="#%d0%bf%d0%be%d0%bb%d1%83%d1%87%d0%b5%d0%bd%d0%b8%d0%b5-%d1%81%d0%bf%d0%b8%d1%81%d0%ba%d0%b0-snapshot-%d0%be%d0%b2-%d0%b8%d0%b7-%d0%ba%d0%be%d1%82%d0%be%d1%80%d1%8b%d1%85-%d0%bc%d0%be%d0%b6%d0%bd%d0%be-%d0%b2%d0%be%d1%81%d1%81%d1%82%d0%b0%d0%bd%d0%b0%d0%b2%d0%bb%d0%b8%d0%b2%d0%b0%d1%82%d1%8c">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;pre>&lt;code>restic -r /mnt/disk0/backup-repo snaphots
repository 365c035e opened successfully, password is correct
ID Time Host Tags Paths
----------------------------------------------------------------------
119a1eb2 2020-04-30 15:48:20 mynote mynote,work /home/projects
ee597f8e 2020-05-31 00:30:01 mynote mynote,work /home/projects
a43ffe6a 2020-06-07 22:12:33 mynote mynote,work /home/projects
1d70de01 2020-06-10 00:32:43 mynote mynote,work /home/projects
0c236089 2020-06-12 18:44:56 mynote mynote,work /home/projects
e557bc74 2020-06-15 23:53:01 mynote mynote,work /home/projects
b39cf3de 2020-06-17 23:07:33 mynote mynote,work /home/projects
677b00d2 2020-06-19 11:40:50 mynote mynote,work /home/projects
8b781249 2020-06-20 00:07:52 mynote mynote,work /home/projects
d7c588a3 2020-06-23 10:15:06 mynote mynote,work /home/projects
----------------------------------------------------------------------
&lt;/code>&lt;/pre>
&lt;h3 id="сравнение-двух-snapshot-ов-дельта" >Сравнение двух snapshot-ов (дельта):
&lt;span>
&lt;a href="#%d1%81%d1%80%d0%b0%d0%b2%d0%bd%d0%b5%d0%bd%d0%b8%d0%b5-%d0%b4%d0%b2%d1%83%d1%85-snapshot-%d0%be%d0%b2-%d0%b4%d0%b5%d0%bb%d1%8c%d1%82%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;pre>&lt;code>restic -r /mnt/disk0/backup-repo diff 119a1eb2 ee597f8e
password is correct
comparing snapshot 119a1eb2 to ee597f8e:
C /home/projects/cmd_diff.go
+ /home/projects/foo
C /home/projects/restic
Files: 0 new, 0 removed, 2 changed
Dirs: 1 new, 0 removed
Others: 0 new, 0 removed
Data Blobs: 14 new, 15 removed
Tree Blobs: 2 new, 1 removed
Added: 16.403 MiB
Removed: 16.402 MiB
&lt;/code>&lt;/pre>
&lt;h3 id="просмотр-списка-файлов-в-snapshot-е" >Просмотр списка файлов в snapshot-е
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%be%d1%81%d0%bc%d0%be%d1%82%d1%80-%d1%81%d0%bf%d0%b8%d1%81%d0%ba%d0%b0-%d1%84%d0%b0%d0%b9%d0%bb%d0%be%d0%b2-%d0%b2-snapshot-%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Так можно посмотреть все файлы, которые можно найти в snapshot-е&lt;/p>
&lt;pre>&lt;code>restic -r /mnt/disk0/backup-repo ls -l latest
snapshot d7c588a3 of [/home/projects] filtered by [] at 2020-06-23 10:15:06.972887989 +0300 MSK):
/home
/home/projects
/home/projects/.ICEauthority
/home/projects/.PyCharmCE2019.3
/home/projects/.PyCharmCE2019.3/config
/home/projects/.PyCharmCE2019.3/config/codestyles
/home/projects/.PyCharmCE2019.3/config/codestyles/Default.xml
/home/projects/.PyCharmCE2019.3/config/inspection
/home/projects/.PyCharmCE2019.3/config/inspection/Default.xml
/home/projects/.PyCharmCE2019.3/config/options
/home/projects/.PyCharmCE2019.3/config/options/colors.scheme.xml
/home/projects/.PyCharmCE2019.3/config/options/debugger.xml
[...]
&lt;/code>&lt;/pre>
&lt;p>А так можно найти определенный (если восстановить хочется не все, а только определенные файлы):&lt;/p>
&lt;pre>&lt;code>restic find &amp;quot;**/blog/**/*.md&amp;quot; --snapshot latest
repository 365c035e opened successfully, password is correct
Found matching entries in snapshot d7c588a3
/home/projects/blog/_drafts/2017-11-06-deadend.md
/home/projects/blog/_drafts/2018-02-06-newway.md
/home/projects/blog/_posts/2005-01-14-openssh-key-auth.md
[...]
&lt;/code>&lt;/pre>
&lt;h3 id="восстановление-из-бэкапа" >Восстановление из бэкапа
&lt;span>
&lt;a href="#%d0%b2%d0%be%d1%81%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5-%d0%b8%d0%b7-%d0%b1%d1%8d%d0%ba%d0%b0%d0%bf%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Самый простой вариант - восстановить все файлы из определенного snapshot-а. Latest как ID snapshot-а автоматически преобразуется в последний доступный snapshot&lt;/p>
&lt;pre>&lt;code>restic -r /mnt/disk0/backup-repo restore latest --target=tmptest/
repository 365c035e opened successfully, password is correct
restoring &amp;lt;Snapshot d7c588a3 of [/home/projects] at 2020-06-23 10:15:06.972887989 +0300 MSK by logan@mynote&amp;gt; to tmptest/
&lt;/code>&lt;/pre>
&lt;p>Если восстанавливать хочется не все - есть ключ &lt;code>--include&lt;/code>:&lt;/p>
&lt;pre>&lt;code>restic -r /mnt/disk0/backup-repo restore latest --target=tmptest/ --include &amp;quot;.PyCharmCE2019.3&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>В этом случае будет восстановлена только папка &lt;code>.PyCharmCE2019.3&lt;/code> со всем ее содержимым. Обратный фокус с ключом &lt;code>--exclude&lt;/code> сработает тоже.&lt;/p>
&lt;h3 id="проверки-snapshot-ов" >Проверки snapshot-ов
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%be%d0%b2%d0%b5%d1%80%d0%ba%d0%b8-snapshot-%d0%be%d0%b2">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Целосность данных критически важна. Если будет потерян blob - все snapshot-ы, которые ссылаются на него - станут невалидными и не смогут восстановится. Для этой цели есть команда &lt;code>check&lt;/code>:&lt;/p>
&lt;pre>&lt;code>restic -r /mnt/disk0/backup-repo check
using temporary cache in /tmp/restic-check-cache-830311414
repository 365c035e opened successfully, password is correct
created new cache in /tmp/restic-check-cache-830311414
create exclusive lock for repository
load indexes
check all packs
check snapshots, trees and blobs
no errors were found
&lt;/code>&lt;/pre>
&lt;h2 id="уборка-в-репозитории" >Уборка в репозитории
&lt;span>
&lt;a href="#%d1%83%d0%b1%d0%be%d1%80%d0%ba%d0%b0-%d0%b2-%d1%80%d0%b5%d0%bf%d0%be%d0%b7%d0%b8%d1%82%d0%be%d1%80%d0%b8%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Restic по умолчанию не имеет политик очистки (retention policy), а значит - репозиторий будет расти вечно, с каждым изменением файла. Чтобы этого избежать - репозиторий надо чистить. Это делается в два шага:&lt;/p>
&lt;ul>
&lt;li>команда &lt;code>forget&lt;/code> удаляет ненужные snapshot-ы из репозитория. Однако она не трогает сами блобы, на которые ссылаются эти snapshot-ы&lt;/li>
&lt;li>команда &lt;code>prune&lt;/code> удаляет блобы, на которые никто не ссылается. Именно в этот момент происходит реальная чистка репозитория.&lt;/li>
&lt;/ul>
&lt;p>Пример использования:&lt;/p>
&lt;pre>&lt;code>restic -r /mnt/disk0/backup-repo forget --keep-daily 7 --keep-weekly 5 --keep-monthly 12
restic -r /mnt/disk0/backup-repo prune
&lt;/code>&lt;/pre>
&lt;p>В этом примере мы храним 7 последних ежедневных snapshot-ов, 4 snapshot-а недельных (что покрывает месяц) и 12 месячных. Это позволит нам вытащить бэкап за весь последний год, причем за последнюю неделю он ежедневный, за месяц - еженедельный а дальше - помесячный. Почему keep-weekly в этом примере равен 5? Потому что последний из 7 keep-daily попадает на недельный (это первый по-недельный snapshot). Чтобы проверить, какие snapshot-ы будут удалены - можно вызвать &lt;code>forget&lt;/code> с ключом &lt;code>--dry-run&lt;/code>. Никакого удаления при этом не производится и можно по выводу команды понять, отрабатывает ли политика так, как задумано.&lt;/p>
&lt;p>Авторы restic рекомендуют запускать check после prune, чтобы убедится, что не произошло повреждения данных.&lt;/p>
&lt;h2 id="использование-в-скриптах" >Использование в скриптах
&lt;span>
&lt;a href="#%d0%b8%d1%81%d0%bf%d0%be%d0%bb%d1%8c%d0%b7%d0%be%d0%b2%d0%b0%d0%bd%d0%b8%d0%b5-%d0%b2-%d1%81%d0%ba%d1%80%d0%b8%d0%bf%d1%82%d0%b0%d1%85">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Restic прекрасно работает в скриптах, в нем нет интерактивных элементов. Пароль можно задать с помощью переменных окружающей среды:&lt;/p>
&lt;ul>
&lt;li>RESTIC_PASSWORD - пароль repo &amp;ldquo;как есть&amp;rdquo;, открытым текстом без шифрования&lt;/li>
&lt;li>RESTIC_PASSWORD_FILE - файл с паролем repo. Без шифрования. Учитывается только первая строка. Имеет более высокий приоритет, чем RESTIC_PASSWORD (если задан RESTIC_PASSWORD_FILE, RESTIC_PASSWORD не учитывается)&lt;/li>
&lt;li>RESTIC_PASSWORD_COMMAND - команда, выполнение которой вернет пароль. Задавать ее в виде субпроцесса &lt;code>$(command)&lt;/code> не нужно. Хороший вариант, если вы используете для шифрования PGP или менеджер паролей (pass, gopass, 1password-cli). Наивысший приоритет&lt;/li>
&lt;/ul>
&lt;h2 id="заключение" >Заключение
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Restic - простой, быстрый и при правильном применении - вполне надежный инструмент. Простота настройки снижает риск ошибок, а скорость работы - повышает шансы, что все будет забэкаплено вовремя и как надо. Я очень рекомендую этот инструмент, он показал себя простым, гибким, удобным и надежным. И помните - системные администраторы делятся на две группы: те, кто не делают бэкапы и те, кто &lt;strong>уже делают бэкапы&lt;/strong> :)&lt;/p></description></item><item><title>WireGuard: перспективный VPN</title><link>https://prudnitskiy.pro/post/2019-07-24-wireguard/</link><pubDate>Wed, 24 Jul 2019 12:00:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2019-07-24-wireguard/</guid><description>&lt;p>VPN придуман давно (IPSec - в 1998 году, например) и имеет множество областей применения - безопасный доступ для удаленных сотрудников, прозрачное объединение корпоративных сетей, безопасный доступ в интернет поверх небезопасных каналов, даже - уклонение от корпоративной и государственной цензуры. Протоколов VPN - целый выводок, а реализации (программы, ПАК, даже чистые аппаратные решения без ПО есть) - еще больше. При этом каждый каждый стандарт имеет свои недостатки. WireGuard - это очередной протокол VPN, попытка эти проблемы решить. При всех плюсах WG (про них - ниже) - он мало известен и на удивление плохо документирован. Эта статья - попытка устранить эти недостатки.&lt;/p>
&lt;p>WireGuard - это протокол VPN, который был придуман и реализован полностью с нуля - с применением последних, самых свежих концепций в программировании и криптографии. Главная задача, которую ставил перед собой автор (Джейсон Доненфелд) - простота протокола и реализации и высокая скорость работы. Протокол предельно простой, по-моему даже PPP сложнее. Очень простое взаимодействие операционной системы с VPN - WireGuard добавляет в систему сетевой интерфейс типа wireguard (по умолчанию - wgX), маршрутизация трафика идет через него. VPN полностью реализован на уровне ядра (для Linux, для других операционных систем поддерживается работа в виде обычной программы) - он очень быстро работает. Трафик упаковывается в совершенно типовой UDP, не нужны специфичные IP-протоколы (как это сделано в PPP/IPSec). Автор решил не использовать классические legacy-протоколы шифрования и взял самые свежие, но доказанно безопасные протоколы:&lt;/p>
&lt;ul>
&lt;li>ChaCha20 (salsa) - симметричное потоковое шифрование данных&lt;/li>
&lt;li>Curve25519 ECDH - ассиметричное шифрование для авторизации и аутентификации&lt;/li>
&lt;li>Blake2s - для хеширования&lt;/li>
&lt;/ul>
&lt;p>По скорости работы WireGuard обгоняет IPSec, даже с учетом того, что IPSec жульничает - современные CPU часть криптопримитивов могут выполнять в одну инструкцию.&lt;/p>
&lt;p>При этом по простоте и удобству настройки WireGuard проще OpenVPN.&lt;/p>
&lt;p>В качестве бонуса - Торвальдс очень хвалил код WireGuard (а Торвальдс известен нетерпимостью к плохому коду и не станет раздавать незаслуженные комплименты) и обещал, что код войдет в базовое ядро в ближайшем будущем. Звучит очень интересно, не так ли?&lt;/p>
&lt;p>Разумеется, минусы у него тоже есть, и не упомянуть их было неправильно:&lt;/p>
&lt;ul>
&lt;li>wireguard формально находится в стадии активной разработки. До сих пор не вышло ни одной формальной версии, то есть даже wireguard 0.0.0.1 - нет в природе. Авторы не обещают и не гарантируют обратной совместимости протокола, то есть при одном удачном обновлении у вас легко может рассыпаться сеть. За пол-года, что я использовал WG - у меня такого не было ни разу, но в теории такая возможность сохраняется до выхода стабильной версии.&lt;/li>
&lt;li>wireguard не является стандартным и стабильным решением, не существует физического устройства, которое его поддерживает официально (как IPSec, например). Частично можно компенсировать тем, что все современные linux-based прошивки для маршрутизаторов (dd-wrt, OpenWRT, tomato) - поддерживают его с минимальным набором телодвижений. OpenVPN это обстоятельство, кстати, никак не мешает - из железяк его поддерживает разве что mikrotik и делает это настолько отвратительно, что лучше бы не поддерживал вовсе.&lt;/li>
&lt;li>wireguard не проходил формального аудита безопасности. Протоколы, которые он используют - аудит проходили, реализация - нет. Прохождение аудита у авторов запланировано после стабилизации кодовой базы. Как следствие - сертифицировать решение на базе wireguard невозможно. Если вы работаете в банке - пожалуйста, не используйте wireguard.&lt;/li>
&lt;li>криптопримитивы в wireguard прибиты гвоздиками и поменять их невозможно. Только ECDH для авторизации, только salsa20 для потоковых шифров, только UDP в качестве транспорта. С одной стороны - это здорово упрощает жизнь &amp;ndash; невозможно перепутать настройки протоколов и провести пару вечеров за отладкой. С другой - если в каком-то из этих примитивов найдут серьезную дыру - придется переписать пол-протокола или вообще все выкинуть. Частично компенсируется тем, что весь Bitcoin (и не только он) построен вокруг ECDH, так что если там найдут дыру - проблемы wiregaurd будут мелочью.&lt;/li>
&lt;/ul>
&lt;p>В целом я могу уверенно рекомендовать wireguard для личного использования или как VPN-протокол в малокритичных сетях (без SLA и с командой, которая готова с ним разбираться). В общем случае, если у вас есть OpenVPN на linux - WireGuard идеально может его заменить. WireGuard напоминает мне OpenVPN в те времена, когда тот еще только появился и не успел стать legacy - простой, удобный, быстрый в настройке VPN.&lt;/p>
&lt;h2 id="установка" >Установка
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;h3 id="debianubuntu" >Debian/Ubuntu
&lt;span>
&lt;a href="#debianubuntu">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Так, как стабильных релизов wireguard нет - нам потребуется DKMS для сборки модулей ядра. Пакеты для WireGuard для debian stretch/buster не выпускались, но они есть для debian sid. Добавим репозиторий unstable и создадим pin. Если добавить репозиторий и не создавать пин - все пакеты из sid приедут в ваш сервер. Удачно запущенный apt-get install превратит систему в кашу:&lt;/p>
&lt;pre>&lt;code># echo &amp;quot;deb http://deb.debian.org/debian/ sid main&amp;quot; &amp;gt; /etc/apt/sources.list.d/unstable.list
# printf 'Package: *\nPin: release a=unstable\nPin-Priority: 90\n' &amp;gt; /etc/apt/preferences.d/limit-unstable.pref
&lt;/code>&lt;/pre>
&lt;p>К счастью, в ubuntu все необходимые пакеты уже есть и дополнительные телодвижения не нужны. Ставим модуль:&lt;/p>
&lt;pre>&lt;code># apt-get update
# apt-get install wireguard wireguard-dkms wireguard-tools
&lt;/code>&lt;/pre>
&lt;p>Проверим, что все установилось:&lt;/p>
&lt;pre>&lt;code># ip link add dev wg0 type wireguard
# ip link print
1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1
link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
[...]
25: wg0: &amp;lt;POINTOPOINT,NOARP&amp;gt; mtu 1420 qdisc noop state DOWN mode DEFAULT group default qlen 1
link/none
&lt;/code>&lt;/pre>
&lt;h3 id="centosrheloracleubl" >CentOS/RHEL/OracleUBL
&lt;span>
&lt;a href="#centosrheloracleubl">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Владельцам rpm-based дистрибутивов повезло больше - есть готовый отдельный репозиторий, так что достаточно поставить его и EPEL (хотя мне сложно представить rpm-based дистрибутив без EPEL):&lt;/p>
&lt;pre>&lt;code># curl -Lo /etc/yum.repos.d/wireguard.repo https://copr.fedorainfracloud.org/coprs/jdoss/wireguard/repo/epel-7/jdoss-wireguard-epel-7.repo
# yum makecache
# yum install epel-release
# yum install wireguard-dkms wireguard-tools
&lt;/code>&lt;/pre>
&lt;h2 id="настройка" >Настройка
&lt;span>
&lt;a href="#%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;h3 id="сервер" >Сервер
&lt;span>
&lt;a href="#%d1%81%d0%b5%d1%80%d0%b2%d0%b5%d1%80">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Wireguard использует авторизацию только по ключам (keypair). Ключи генерирует сам. Авторизация клиента производится по его публичному ключу, то есть на сервере должны быть публичные ключи всех клиентов, а на клиентах - публичный ключ сервера. Создадим такой ключ:&lt;/p>
&lt;pre>&lt;code>server# umask 077
server# wg genkey &amp;gt; server.priv
server# wg pubkey &amp;lt; server.priv &amp;gt; server.pub
&lt;/code>&lt;/pre>
&lt;p>На выходе получим два ключа, приватный и публичный. В принципе wireguard можно полностью управлять через команду ip, но это не сказать, чтобы сильно удобно. Для того, чтобы упростить настройку, авторы wireguard написали утилиту &lt;code>wg-quick&lt;/code>. Она читает конфиг из &lt;code>/etc/wireguard/wgX.conf&lt;/code> и создает соответствующий интерфейс. Пример конфига &lt;code>/etc/wireguard/wg0.conf&lt;/code>:&lt;/p>
&lt;pre>&lt;code>[Interface]
Address = 192.168.254.1/24
SaveConfig = false
ListenPort = 25968
PrivateKey = [...]
PostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE
PostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE
&lt;/code>&lt;/pre>
&lt;p>Что тут написано:&lt;/p>
&lt;ul>
&lt;li>&lt;code>address&lt;/code> - адресное пространство VPN-сети. Этот адрес будет присвоен интерфейсу wg0. Все клиенты, которые подключены к одному интерфейсу - должны иметь адреса в одной подсети, иначе они не смогут общаться.&lt;/li>
&lt;li>&lt;code>saveconfig = false&lt;/code> - если что-то было изменено после wg-quick вручную (командой ip link) - по умолчанию изменения запишутся в конфиг. Побочный эффект - если во время работы wireguard вы что-то в конфиге поменяете и перезапустите wireguard - все изменения будут стерты.&lt;/li>
&lt;li>&lt;code>ListenPort&lt;/code> - на какой порт должны приходить UDP-датаграммы, предназначенные для этого конкретного интерфейса wireguard. Никто не запрещает создать несколько интерфейсов wireguard - каждый с отдельным ключом, адресным пространством и списком клиентов. Этот порт должен быть открыт снаружи для UDP&lt;/li>
&lt;li>&lt;code>PrivateKey&lt;/code> - ключ из server.priv (из шага выше).&lt;/li>
&lt;li>&lt;code>PostUp&lt;/code> - добавляет правила в фаерволл - разрешает форвардинг для интерфейса и включает nat. Эта строка вам не нужна, если правила добавлены вручную. В данном примере считается, что внешний интерфейс сервера - eth0.&lt;/li>
&lt;li>&lt;code>PostDown&lt;/code> - удаляет правила, который добавил &lt;code>PostUp&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>На всякий случай включим форвардинг пакетов:&lt;/p>
&lt;pre>&lt;code>server# sysctl -w net.ipv4.ip_forward=1
server# echo &amp;quot;net.ipv4.ip_forward=1&amp;quot; &amp;gt;&amp;gt; /etc/sysctl.conf
&lt;/code>&lt;/pre>
&lt;h3 id="клиент" >Клиент
&lt;span>
&lt;a href="#%d0%ba%d0%bb%d0%b8%d0%b5%d0%bd%d1%82">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Точно так же ставим wireguard и генерируем ключи, как в примере выше:&lt;/p>
&lt;pre>&lt;code>client# umask 077
client# wg genkey &amp;gt; client.priv
client# wg pubkey &amp;lt; client.priv &amp;gt; client.pub
&lt;/code>&lt;/pre>
&lt;p>А вот содержимое конфига будет слегка иным:&lt;/p>
&lt;pre>&lt;code>[Interface]
PrivateKey = &amp;lt;from client.priv&amp;gt;
Address = 192.168.254.2/24
ListenPort = 25967
Table=wire
[Peer]
PublicKey = &amp;lt;from server.pub&amp;gt;
Endpoint = &amp;lt;server ip&amp;gt;:25968
AllowedIPs = 0.0.0.0/0
PersistentKeepalive = 30
&lt;/code>&lt;/pre>
&lt;p>Что появилось в конфиге нового. Секция Interface как и раньше - отвечает за настройку самого сервиса wiregurad:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Address&lt;/code> - из той же подсети, что и адрес сервера, но уникальный.&lt;/li>
&lt;li>&lt;code>Table = wire&lt;/code> - нужно, чтобы wireguard знал, в какую таблицу записывать маршруты. Они описаны в разделе peer (о нем ниже) и в момент, когда связь с peer-ом (сервером) будет установлена - маршруты будут добавлены. Если таблицу не указывать - будет использована системная. Это может вызвать проблему, если VPN выдает маршрут по умолчанию (как здесь). Чуть ниже я покажу, как с этим жить.&lt;/li>
&lt;/ul>
&lt;p>Секция peer настраивает параметры подключения к другой стороне:&lt;/p>
&lt;ul>
&lt;li>&lt;code>PublicKey&lt;/code> - публичный ключ сервера. Именно по нему клиент авторизует сервер.&lt;/li>
&lt;li>&lt;code>Endpoint&lt;/code> - внешний адрес и порт сервера.&lt;/li>
&lt;li>&lt;code>AllowedIPs&lt;/code> - обращения к каким адресам можно отправлять в этот туннель. При поднятии туннеля маршрут ко всем адресам (сетям), перечисленным тут - будет добавлен в таблицу маршрутизации из секции Interface. Если какой-то сети или адреса тут нет - ручное добавление маршрута не поможет, wireguard отклонит такой маршрут. В данном примере я использую wireguard-сервер как шлюз по умолчанию, то есть хожу в интернет через него. Если сетей нужно добавить несколько - их можно перечислить через запятую.&lt;/li>
&lt;li>&lt;code>PersistentKeepalive&lt;/code> - интервал keepalive в секундах. По умолчанию данные в туннеле есть только тогда, когда кто-то что-то через него передает. KeepAlive периодически пингует удаленную сторону и поддерживает соединение. Это важно в тех случаях, если вы сидите за nat - сервер не может поддерживать соединение с клиентом, nat gateway разорвет неактивное соединение. Если после этого сервер захочет передать пакет клиенту - он не сможет этого сделать.&lt;/li>
&lt;/ul>
&lt;p>Включаем wiregurad на клиенте и идем настраивать на сервер:&lt;/p>
&lt;pre>&lt;code>client# wg-quick up wg0
&lt;/code>&lt;/pre>
&lt;p>Чтобы клиент запускал wireguard автоматически - добавим его в автозагрузку:&lt;/p>
&lt;pre>&lt;code>client# systemctl enable wg-quick@wg0
&lt;/code>&lt;/pre>
&lt;h3 id="снова-сервер" >Снова сервер
&lt;span>
&lt;a href="#%d1%81%d0%bd%d0%be%d0%b2%d0%b0-%d1%81%d0%b5%d1%80%d0%b2%d0%b5%d1%80">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>В &lt;code>/etc/wireguard/wg0.conf&lt;/code> нужно вписать клиента, которого мы только что создали выше. Добавим секцию:&lt;/p>
&lt;pre>&lt;code>[Peer]
PublicKey = &amp;lt;from client.pub&amp;gt;
AllowedIPs = 192.168.254.2/32, 192.168.1.1/24
Endpoint = &amp;lt;client public IP&amp;gt;:25967
&lt;/code>&lt;/pre>
&lt;p>Обратите внимание на то, что в AllowedIPs указан, в том числе, адрес интерфейса wireguard &lt;em>на клиенте&lt;/em>. Это очень важно, без этого трафик ходить не будет. Про него часто забывают. В примере выше через VPN маршрутизируется сеть &lt;code>192.168.1.0/24&lt;/code>, потому она указана тоже.&lt;/p>
&lt;p>Поднимем VPN на сервере тоже и проверим:&lt;/p>
&lt;pre>&lt;code>server# wg-quick up wg0
server# wg show
interface: wg0
public key: [...]
private key: (hidden)
listening port: 25968
peer: [...]
endpoint: 1.2.3.4:25967
allowed ips: 192.168.254.2/32, 192.168.1.0/24
latest handshake: 1 minute, 35 seconds ago
transfer: 1.84 KiB received, 2.84 KiB sent
&lt;/code>&lt;/pre>
&lt;p>Настройка VPN, в общем-то, закончена. Как я и говорил выше - восхитительно просто.&lt;/p>
&lt;h4 id="лирическое-отступление-маршрутизация-через-таблицы-и-маркировка-трафика" >Лирическое отступление: маршрутизация через таблицы и маркировка трафика
&lt;span>
&lt;a href="#%d0%bb%d0%b8%d1%80%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%be%d0%b5-%d0%be%d1%82%d1%81%d1%82%d1%83%d0%bf%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5-%d0%bc%d0%b0%d1%80%d1%88%d1%80%d1%83%d1%82%d0%b8%d0%b7%d0%b0%d1%86%d0%b8%d1%8f-%d1%87%d0%b5%d1%80%d0%b5%d0%b7-%d1%82%d0%b0%d0%b1%d0%bb%d0%b8%d1%86%d1%8b-%d0%b8-%d0%bc%d0%b0%d1%80%d0%ba%d0%b8%d1%80%d0%be%d0%b2%d0%ba%d0%b0-%d1%82%d1%80%d0%b0%d1%84%d0%b8%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h4>&lt;p>Как я уже упоминал выше - по умолчанию wireguard добавляет все маршруты, указанные в AllowedIPs в основную таблицу маршрутизации. Linux не поддерживает policy based routing, соответственно там нельзя создать &amp;ldquo;условные маршруты&amp;rdquo; вида &amp;ldquo;если клиент из офисной сети - маршрут в google пустить через VPN&amp;rdquo;. Default gateway через VPN вообще кончится потерей связи, так как сервер потеряет маршрут до VPN-сервера. Выход есть - и называется он &amp;ldquo;таблицы маршрутизации&amp;rdquo;. Linux поддерживает 255 таблиц маршрутизации (точнее - 251, так как есть зарезервированные таблицы, которые нельзя удалить). Для решения перечисленных выше проблем мы просто создадим отдельную таблицу маршрутизации, а потом с помощью iptables будем ловить трафик, предназначенный для VPN и отправлять его в нужную нам таблицу. При этом клиентская сеть сохранит доступ к серверу и мы сможем гибко настраивать потоки трафика. К примеру - пустить через VPN только трафик для google/youtube, а трафик в Яндекс пустить по старому маршруту по умолчанию. Создадим таблицу:&lt;/p>
&lt;pre>&lt;code>client# echo &amp;quot;200 wire&amp;quot; &amp;gt;&amp;gt; /etc/iproute2/rt_tables
Теперь создадим правило iptables, которое будет помечать нужный нам трафик. Этот трафик должен быть отправлен в VPN:
client# iptables -I PREROUTING -t mangle -i eth0 -j MARK --set-mark 1
&lt;/code>&lt;/pre>
&lt;p>В данном примере я отправляю в VPN весь трафик, который приходит на интерфейс eth0 (в моем случае это внутренний интерфейс)&lt;/p>
&lt;p>Теперь нам нужно правило (ip rule), которое перенаправит трафик с меткой 0х1 в таблицу wire:&lt;/p>
&lt;pre>&lt;code>ip rule add fwmark 0x1 lookup wire
&lt;/code>&lt;/pre>
&lt;p>Чтобы правило не потерялось при перезагрузке сервера или пересоздании интерфейса - я набросал простейший скрипт и положил его в &lt;code>/etc/network/if-up.d&lt;/code> (это пример для debian). Таким образом правило будет добавляться каждый раз, когда интерфейс переходит в активное состояние (UP):&lt;/p>
&lt;pre>&lt;code>#!/bin/bash
if [[ ! $(ip rule list | grep &amp;quot;fwmark 0x1 lookup wire&amp;quot;) ]]; then
/bin/ip rule add fwmark 0x1 lookup wire
fi
&lt;/code>&lt;/pre>
&lt;p>Этому скрипту нужно обязательно дать права на выполнение (chmod +x). Название скрипта не важно совершенно, главное - место, где файл лежит и права.&lt;/p>
&lt;p>Еще одну проблему подарит rpfilter. В нормальной ситуации это полезная настройка - она позволяет отсекать фальшивые (forged) пакеты, которые пришли не на тот интефейс, с которого уходили. К примеру, у нас есть eth0 (192.168.1.1) и eth1 (172.16.1.1). Пакет отправляется с source address 192.168.1.2 (интерфейс eth0) а ответ приходит на eth1. Это или что-то странное (что редкость) или попытка взлома (что более вероятно). RPFilter отсекает такие пакеты. Проблема в том, что с точки зрения rpfilter пакеты, уходящие в другую таблицу - будут &amp;ldquo;проваливаться в никуда&amp;rdquo;, а ответные - &amp;ldquo;возникать из ниоткуда&amp;rdquo;. Чудеса телепортации rpfilter не любит, так что его придется отключить, иначе не видать вам трафика через vpn:&lt;/p>
&lt;pre>&lt;code>client# sysctl -w net.ipv4.conf.eth0.rp_filter=2
client# sysctl -w net.ipv4.conf.wg0.rp_filter=2
&lt;/code>&lt;/pre>
&lt;p>Чтобы эти изменения не пропали при перезагрузке - добавим их в &lt;code>/etc/sysctl.conf&lt;/code>:&lt;/p>
&lt;pre>&lt;code>client# printf &amp;quot;net.ipv4.conf.eth0.rp_filter=2\nnet.ipv4.conf.wg0.rp_filter=2&amp;quot; &amp;gt;&amp;gt; /etc/sysctl.conf
&lt;/code>&lt;/pre>
&lt;h4 id="лирическое-отступление-номер-два-добавляем-исключения-ipset" >Лирическое отступление номер два: добавляем исключения. IPSET.
&lt;span>
&lt;a href="#%d0%bb%d0%b8%d1%80%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%be%d0%b5-%d0%be%d1%82%d1%81%d1%82%d1%83%d0%bf%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5-%d0%bd%d0%be%d0%bc%d0%b5%d1%80-%d0%b4%d0%b2%d0%b0-%d0%b4%d0%be%d0%b1%d0%b0%d0%b2%d0%bb%d1%8f%d0%b5%d0%bc-%d0%b8%d1%81%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d1%8f-ipset">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h4>&lt;p>Иногда хочется пустить через VPN только часть трафика или наоборот - исключить часть трафика из прохождения через VPN. В принципе все это можно сделать исключительно правилами чистого iptables. Например, VPN для нескольких серверов будет выглядеть примерно так:&lt;/p>
&lt;pre>&lt;code>iptables -I PREROUTING -t mangle -i eth0 -d 1.2.3.4 -j MARK --set-mark 1
iptables -I PREROUTING -t mangle -i eth0 -d 1.2.5.5 -j MARK --set-mark 1
iptables -I PREROUTING -t mangle -i eth0 -d 1.2.5.6 -j MARK --set-mark 1
iptables -I PREROUTING -t mangle -i eth0 -d 1.2.6.7 -j MARK --set-mark 1
iptables -I PREROUTING -t mangle -i eth0 -d 1.2.7.8 -j MARK --set-mark 1
&lt;/code>&lt;/pre>
&lt;p>Выглядит, честно говоря, ужасно. Что намного хуже - работать будет довольно медленно, поскольку &lt;em>каждый пакет проходит все правила iptables по очереди - пока не наткнется на правило, которое его обработает&lt;/em>. Пара тысяч правил застави задуматься даже весьма приличный сервер. Пара миллионов - уложит машину на лопатки, пакеты будут путешествовать по недрам netfilter минутами - это вечность. Для решения этой проблемы был придуман ipset. IPSet - это простой и очень эффективный способ хранить множество адресов в памяти компактно, а искать в этом списке - быстро. Память выделяется для ipset в момент создания set (даже, если set пуст). IPSet в кратчайшие сроки ответит на вопрос - есть ли в нем тот или иной адрес - время ответа приближено к O(1), то есть скорость проверки наличия адреса в ipset в общем-то не зависит от размера. В штатную поставку операционной системы ipset не входит, но ставится очень легко:&lt;/p>
&lt;pre>&lt;code>client# apt-get install ipset
&lt;/code>&lt;/pre>
&lt;p>IPSet предоставляет разные варианты sets - они позволяют хранить разные вещи, но требуют разного количества памяти на одну запись. Для примера создадим set, который хранит подсети (адрес + маску):&lt;/p>
&lt;pre>&lt;code>client# ipset create novpn hash:net hashsize 65535
&lt;/code>&lt;/pre>
&lt;p>это создаст set novpn емкостью 65535 записей. Изменить размер или тип сета после создания будет нельзя, так что выбирать придется с умом.&lt;/p>
&lt;p>Удалим старое правило (которое отправляет в VPN весь трафик из внутренней сети) и добавим новое - оно будет отправлять трафик в VPN, если адреса нет в set-е novpn:&lt;/p>
&lt;pre>&lt;code>client# iptables -t mangle -D PREROUTING 1
client# iptables -I PREROUTING -t mangle -i eth0 -m set ! --match-set novpn dst -j MARK --set-mark 1
&lt;/code>&lt;/pre>
&lt;p>Теперь добавим какое-нибудь исключение. Например, avito.ru очень не любит дешевые VPS, на которых часто делают VPN-сервера - мошенники активно используют такие же сервера, чтобы воровать с авито данные, а потому большинство сетей крупнейших облачных провайдеров на авито просто забанены.&lt;/p>
&lt;pre>&lt;code>client# ipset add novpn 185.89.12.0/24
&lt;/code>&lt;/pre>
&lt;p>Проверим:&lt;/p>
&lt;pre>&lt;code>client# ipset list
Name: novpn
Type: hash:net
Revision: 6
Header: family inet hashsize 65536 maxelem 65536
Size in memory: 1376
References: 1
Members:
185.89.12.0/24
&lt;/code>&lt;/pre>
&lt;p>Теперь трафик к avito (185.89.12.0/24) пойдет напрямую, а весь остальной - через VPN.&lt;/p>
&lt;p>К слову - можно сделать и наоборот, то есть пустить через VPN трафик, который попадает в ipset. Правило будет выглядеть чуть-чуть иначе:&lt;/p>
&lt;pre>&lt;code>client# iptables -I PREROUTING -t mangle -i eth0 -m set --match-set tovpn dst -j MARK --set-mark 1
&lt;/code>&lt;/pre>
&lt;p>Все остальные принципы работы с ipset сохраняются. Рекомендую.&lt;/p>
&lt;h3 id="клиент-отдельный-ноутбук-на-linux-roadwarrior" >Клиент: отдельный ноутбук на linux (roadwarrior)
&lt;span>
&lt;a href="#%d0%ba%d0%bb%d0%b8%d0%b5%d0%bd%d1%82-%d0%be%d1%82%d0%b4%d0%b5%d0%bb%d1%8c%d0%bd%d1%8b%d0%b9-%d0%bd%d0%be%d1%83%d1%82%d0%b1%d1%83%d0%ba-%d0%bd%d0%b0-linux-roadwarrior">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Wireguard ставится ровно так же, как в примере выше:&lt;/p>
&lt;pre>&lt;code>notebook# apt-get install wireguard wireguard-dkms wireguard-tools
&lt;/code>&lt;/pre>
&lt;p>С ключами тоже никаких сюрпризов:&lt;/p>
&lt;pre>&lt;code>notebook# umask 077
notebook# wg genkey &amp;gt; notebook.priv
notebook# wg pubkey &amp;lt; notebook.priv &amp;gt; notebook.pub
&lt;/code>&lt;/pre>
&lt;p>Ключи создаются точно так же. Пример конфига ноутбука (&lt;code>/etc/wireguard/wg0.conf&lt;/code>):&lt;/p>
&lt;pre>&lt;code>[Interface]
PrivateKey = &amp;lt;from notebook.priv&amp;gt;
Address = 192.168.254.2/24
[Peer]
PublicKey = &amp;lt;from server.pub&amp;gt;
Endpoint = 1.2.3.4:25967
AllowedIPs = 0.0.0.0/0
PersistentKeepalive = 21
&lt;/code>&lt;/pre>
&lt;p>Включаем командой &lt;code>wg-quick up wg0&lt;/code>. Выключаем, соответственно - &lt;code>wg-quick down wg0&lt;/code>. Интеграции с netmanager пока что нет, так что включать-выключать конфиг графической кнопкой не выйдет.&lt;/p>
&lt;p>Не забудьте добавить содержимое &lt;code>notebook.pub&lt;/code> на сервер - в секцию &lt;code>[Peer]&lt;/code>.&lt;/p>
&lt;h3 id="задача-со-звездочкой---подключаем-мобильное-устройство" >Задача со звездочкой - подключаем мобильное устройство
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d0%b4%d0%b0%d1%87%d0%b0-%d1%81%d0%be-%d0%b7%d0%b2%d0%b5%d0%b7%d0%b4%d0%be%d1%87%d0%ba%d0%be%d0%b9---%d0%bf%d0%be%d0%b4%d0%ba%d0%bb%d1%8e%d1%87%d0%b0%d0%b5%d0%bc-%d0%bc%d0%be%d0%b1%d0%b8%d0%bb%d1%8c%d0%bd%d0%be%d0%b5-%d1%83%d1%81%d1%82%d1%80%d0%be%d0%b9%d1%81%d1%82%d0%b2%d0%be">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Wireguard есть как для iOS, так и для android. В первом случае он сделан как userspace процесс, но протокол реализует тот же. Работает, конечно, медленнее, но не думаю, что это будет заметно. Ставится как любое типичное приложение, а вот настройки создаются интересно.&lt;/p>
&lt;p>Создадим на сервере ключи для мобильного:&lt;/p>
&lt;pre>&lt;code>server# wg genkey | tee mobile.priv | wg pubkey &amp;gt; mobile.pub
&lt;/code>&lt;/pre>
&lt;p>Добавим еще один peer в конфиг сервера:&lt;/p>
&lt;pre>&lt;code>[Peer]
PublicKey = &amp;lt;from mobile.pub&amp;gt;
AllowedIPs = 192.168.254.3/32
&lt;/code>&lt;/pre>
&lt;p>Перезапустим wg:&lt;/p>
&lt;pre>&lt;code>server# wg-quick down wg0
server# wg-quick up wg0
&lt;/code>&lt;/pre>
&lt;p>создадим конфиг для мобильного с примерно таким содержимым:&lt;/p>
&lt;pre>&lt;code>[Interface]
PrivateKey = &amp;lt;from mobile.priv&amp;gt;
Address = 192.168.254.3/32
DNS = 8.8.8.8
[Peer]
PublicKey = &amp;lt;from server.pub&amp;gt;
Endpoint = 1.2.3.4:25967
AllowedIPs = 0.0.0.0/0
&lt;/code>&lt;/pre>
&lt;p>В целом все выглядит знакомо. Теперь нужно передать конфиг на мобильное устройство. Проще всего это сделать, закодировав конфиг в QR-code:&lt;/p>
&lt;pre>&lt;code>server# qrencode -t ansiutf8 &amp;lt; mobile.conf
&lt;/code>&lt;/pre>
&lt;p>На выходе будет картинка - QR-код. Открываем wireguard на мобильном, жмем + -&amp;gt; from QR code -&amp;gt; показываем картинку. Готово, мобильное устройство получило конфиг и теперь VPN можно включать штатными средствами.&lt;/p>
&lt;p>Ключи mobile и конфиг рекомендуется удалить с сервера - чтобы никто их не украл.&lt;/p>
&lt;h2 id="выводы" >Выводы
&lt;span>
&lt;a href="#%d0%b2%d1%8b%d0%b2%d0%be%d0%b4%d1%8b">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>WireGuard - прекрасная альтернатива openvpn уже сейчас. Простой, легко и быстро настраиваемый сервис. Работает очень стабильно, при этом - очень быстро. Я горячо рекомендую его как замену openvpn - как в корпоративном секторе, так и для личного использования.&lt;/p>
&lt;p>Безопасного вам интернета!&lt;/p></description></item><item><title>CFSS: TLS CA со скоростью молнии</title><link>https://prudnitskiy.pro/post/2018-12-14-cfssl/</link><pubDate>Fri, 14 Dec 2018 12:00:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2018-12-14-cfssl/</guid><description>&lt;p>TLS - один из самых распространенных стандартов шифрования и аутентификации в современном интернете. Используется исключительно широко - взаимодействие с пользователем (HTTPS), межпрограммное общение (RPC over HTTPS, gRPC), даже VPN (OpenVPN) и телефония (SIPoTLS). Он обеспечивает шифрование (симметричным ключом), авторизацию (PKI), проверку целостности переданной информации (HMAC). Важная часть TLS - PKI (инфраструктура публичных ключей). Любой публичный ключ в TLS должен быть подписан (публичный ключ с подписью и набором определенных атрибутов называется сертификатом). Центр сертификации – критически важная часть работы TLS, так как он управляет доверием к приложению или сервису (цепочки доверия). В этой статье я расскажу о том, как запустить свой собственный CA на основе CFSSL. Введение получилось неожиданно большим, так что если вам нужна практика - вам сюда&lt;/p>
&lt;h2 id="цепочки-доверия" >Цепочки доверия
&lt;span>
&lt;a href="#%d1%86%d0%b5%d0%bf%d0%be%d1%87%d0%ba%d0%b8-%d0%b4%d0%be%d0%b2%d0%b5%d1%80%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>В ассиметричном шифровании каждый сервис имеет два ключа, открытый (публичный) и закрытый (приватный). Из приватного ключа можно легко получить публичный, но обратная операция практически невозможна. Из публичного ключа, добавив в него несколько текстовых полей (атрибутов) - можно создать запрос на сертификат (CSR). Центр сертификации подписывает CSR и таким образом CSR становится сертификатом. Подписью центр сертификации (CA) подтверждает, что:&lt;/p>
&lt;ul>
&lt;li>сервис, использующий этот сертификат – достоин доверия с точки зрения CA&lt;/li>
&lt;li>цифровая подпись действительна в определенный момент времени (у нее есть ограничения по сроку жизни)&lt;/li>
&lt;li>подписанный CA сертификат можно использовать определенным образом. Возможности использования описаны атрибутами в сертификате. Так, как атрибуты подписываются вместе с самим публичным ключом – их нельзя поменять, это разрушит цифровую подпись.&lt;/li>
&lt;/ul>
&lt;p>Сертификат может быть отозван по определенной причине (например, приватный ключ сервиса был украден). Для того, чтобы приложения (пользователи) узнали о факте отзыва – существует CRL (certificate revocation list). Устроен он сравнительно просто: это текстовый файл, где перечислены уникальные серийные номера сертификатов (SSN) и дата отзыва. Содержимое файла подписано цифровой подписью CA, что исключает подделку.&lt;/p>
&lt;p>Чтобы клиент (приложение) мог доверять центру сертификации – у него должен быть сертификат центра сертификации. Этому сертификату клиент (приложение) доверяет безусловно, а используя этот сертификат – может проверить цельность цифровой подписи любого сертификата, подписанного доверенным центром сертификации.&lt;/p>
&lt;p>Очевидно, что потеря (компрометация) ключа доверенного центра сертификации – это крайне плохо – нужно создать новый ключ после чего заново подписать все сертификаты. Плюс – разослать всем клиентам новый сертификат, а старый пометить, как не подлежащий доверию. Тот, кто украдет ключ центра сертификации – сможет выписывать себе произвольные сертификаты и соединение с таким сервисом будет считаться совершенно безопасным.&lt;/p>
&lt;p>Чтобы избежать этого – IEEE придумали цепочки сертификатов. Сначала создается “корневая пара” из приватного ключа и сертификата. Именно этому сертификату будут доверять клиенты безусловно. Корневой сертификат подписывает сам себе. Затем создается “промежуточная пара”. Ключ промежуточной пары подписывается корневым ключом. Теперь корневой ключ можно положить сейф, залить сейф бетоном и закопать в основании небоскреба – в обозримом будущем он нам не потребуется. Клиентские сертификаты будут подписаны промежуточной парой. Клиент, подключаясь, проверит, что сертификат подписан промежуточным центром сертификации, а сертификат промежуточного центра подписан сертификатом, которому клиент доверяет. Такая конструкция называется цепочкой доверия или цепочкой сертификатов (certificate chain), а обладатель промежуточной пары – промежуточным центром сертификации (intermediate center of authorities). Если произойдет ужасное, и ключ промежуточного центра утечет – мы просто откопаем сейф, вынем из него корневой ключ, подпишем этим ключом новую корневую пару и будем подписывать новые сертификаты уже новой корневой парой. Сертификаты, подписанные скомпрометированным ключом – придется перевыпускать (то есть – подписать заново, новым ключом), но хотя бы не придется заставлять всех клиентов менять рутовый сертификат.&lt;/p>
&lt;h2 id="что-делает-ca-и-из-чего-его-можно-собрать" >Что делает CA и из чего его можно собрать
&lt;span>
&lt;a href="#%d1%87%d1%82%d0%be-%d0%b4%d0%b5%d0%bb%d0%b0%d0%b5%d1%82-ca-%d0%b8-%d0%b8%d0%b7-%d1%87%d0%b5%d0%b3%d0%be-%d0%b5%d0%b3%d0%be-%d0%bc%d0%be%d0%b6%d0%bd%d0%be-%d1%81%d0%be%d0%b1%d1%80%d0%b0%d1%82%d1%8c">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Как я уже говорил выше – CA - это пара “приватный ключ + публичный ключ”, в котором приватный ключ создает для сертификатов цифровые подписи. Доступный всем желающим публичный ключ можно использовать для проверки цифровой подписи. При подписании СА должен внести в сертификат уникальный серийный номер подписанного сертификата, а так же – указать срок действия подписи. Хороший центр сертификации должен вести учет выданных сертификатов (то есть - хранить серийные номера всех сертификатов, которые он подписал), а так же – при необходимости создавать CRL – список отозванных сертификатов. Так как TLS сейчас буквально везде – способов создать CA существует множество:&lt;/p>
&lt;h3 id="openssl-ca" >OpenSSL ca
&lt;span>
&lt;a href="#openssl-ca">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>OpenSSL - это классика реализации SSL (TLS) в xNIX. Состоит из библиотеки (libssl) и утилиты командной строки (openssl). Штука фантастически, невероятно, исключительно сложная. Алгоритмы криптографии в принципе не подарок, а в случае openssl сложнейший С-код набит различными оптимизациями для ускорения работы (шифрование должно работать быстро!). Плюс OpenSSL поддерживается для кучи различных платформ (ОС и процессоров). Ориентация в коде OpenSSL – сложнейшее дело. В 2014 году небольшая правка в коде вызывала уязвимость, известную как “heartbleed” – отправляя специально сформированные пакеты на любой сервис, использующий TLS - можно было читать память, доступную процессу, принимающему пакеты. Чтение было медленным, но результат – сокрушительным: heartbleed позволял вытаскивать внутренние данные работающих программ, читать данные других пользователей, даже воровать приватные ключи приложения.&lt;/p>
&lt;p>Пользовательская сторона OpenSSL тоже не подарок – умеет она много, а документирована при этом просто отвратительно. Достаточно просто сказать, что список только доступных команд к утилите openssl - это 3 страницы текста. А руководства, в общем-то – нет. В случае работы с OpenSSL очень несложно сделать ошибку, из-за которой ваш CA станет небезопасным, а потому я не рекомендую использовать openssl для этого.&lt;/p>
&lt;h3 id="easyrsa--easyrsav2" >EasyRSA / EasyRSAv2
&lt;span>
&lt;a href="#easyrsa--easyrsav2">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>По сути это вообще не утилита. Это набор shell-скриптов, которые используют все тот же OpenSSL. Это резко облегчает настройку и снижает вероятность ошибки, но – уменьшает гибкость настройки. Плюс скрипты могут ломаться (у них бывает, увы), и в таком случае вам будет очень трудно понять, что именно у вас сломалось, и где. Ибо за милым и простым фасадом из easy-rsa вас ждет кровожадное лицо OpenSSL.&lt;/p>
&lt;h3 id="hasicorp-vault" >Hasicorp Vault
&lt;span>
&lt;a href="#hasicorp-vault">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Мощная, удобная утилита для создания и хранения секретов. Секретов самых разных - паролей, токенов. Умеет работать с центрами сертификации в том числе. Прекрасный выбор, если вам нужно построить большую и сложную систему централизованного управления секретами и давать в эту систему ограниченный доступ. Для новичка – очень сложно. Требует поднятия отдельного сервера (где будет работать сервис vault), поднятия отдельного хранилища данных, написания политик доступа в vault. Если вам нужно быстро запустить CA (или несколько, но работать с самим СА будет буквально пара человек) - это явный перебор&lt;/p>
&lt;h3 id="cfssl" >CFSSL
&lt;span>
&lt;a href="#cfssl">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>То, ради чего статья затевалась. Набор из простых, небольших, понятных утилит для создания и управления CA. Код написан целиком на golang – он простой и легко читается. Так как утилита сравнительно молодая - в ней минимум legacy-кода. Изначально написана и поддерживается компанией CloudFlare - огромным CDN-провайдером. Так как CF активно использует шифрование внутри своей сети – сертификатов ему нужно море, по этому они и написали собственный инструментарий для работы с ними&lt;/p>
&lt;h2 id="самый-простой-случай-bare-ca" >Самый простой случай: Bare CA
&lt;span>
&lt;a href="#%d1%81%d0%b0%d0%bc%d1%8b%d0%b9-%d0%bf%d1%80%d0%be%d1%81%d1%82%d0%be%d0%b9-%d1%81%d0%bb%d1%83%d1%87%d0%b0%d0%b9-bare-ca">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Чтобы установить свежую версию cfssl (если у вас нет ее в пакетах) – потребуется go версии 1.10 или выше. Ставим:&lt;/p>
&lt;pre>&lt;code>go get -u github.com/cloudflare/cfssl/cmd/cfssl
&lt;/code>&lt;/pre>
&lt;p>Проверяем установку:&lt;/p>
&lt;pre>&lt;code>&amp;gt; cfssl version
Version: 1.3.2
Revision: dev
Runtime: go1.10.2
&lt;/code>&lt;/pre>
&lt;p>Все ок, можно делать CA. Создаем папку для CA, переходим туда и создаем конфиг для создания ключа самого CA:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;CN&amp;quot;: &amp;quot;Test Root CA&amp;quot;,
&amp;quot;key&amp;quot;: {
&amp;quot;algo&amp;quot;: &amp;quot;rsa&amp;quot;,
&amp;quot;size&amp;quot;: 2048
},
&amp;quot;ca&amp;quot;: {
&amp;quot;expiry&amp;quot;: &amp;quot;87600h&amp;quot;
},
&amp;quot;names&amp;quot;: [
{
&amp;quot;C&amp;quot;: &amp;quot;RU&amp;quot;,
&amp;quot;L&amp;quot;: &amp;quot;Saint Petersburg&amp;quot;,
&amp;quot;O&amp;quot;: &amp;quot;Test Company&amp;quot;,
&amp;quot;OU&amp;quot;: &amp;quot;Internal systems unit&amp;quot;,
&amp;quot;ST&amp;quot;: &amp;quot;Saint Petersburg&amp;quot;
}
]
}
&lt;/code>&lt;/pre>
&lt;p>В данном примере мы используем ключ RSA в 2048 бит размером. CFSSL поддерживает как RSA таки ECDSA ключи. Назовем файлик csr.json. Поле expiry задает срок жизни CA. CA не может подписывать ключ на срок больший его собственной жизни. Точнее – может, но смысла в этом нет – когда срок существования цифровой подписи самого CA закончится – все созданные им цифровые подписи не будут считаться легитимными.&lt;/p>
&lt;p>Сгенерируем ключ:&lt;/p>
&lt;pre>&lt;code>&amp;gt; cfssl gencert -initca csr.json | cfssljson -bare ca
2018/12/14 19:56:56 [INFO] generating a new CA key and certificate from CSR
2018/12/14 19:56:56 [INFO] generate received request
2018/12/14 19:56:56 [INFO] received CSR
2018/12/14 19:56:56 [INFO] generating key: rsa-2048
2018/12/14 19:56:57 [INFO] encoded CSR
2018/12/14 19:56:57 [INFO] signed certificate with serial number 594378542753634129370457275219291351654652931156
&lt;/code>&lt;/pre>
&lt;p>Посмотрим в папку:&lt;/p>
&lt;pre>&lt;code>&amp;gt; tree
.
├── csr.json
├── ca-key.pem
├── ca.csr
└── ca.pem
0 directories, 4 files
&lt;/code>&lt;/pre>
&lt;p>Где:&lt;/p>
&lt;ul>
&lt;li>ca-key.pem - приватный ключ, которым подписываются сертификаты&lt;/li>
&lt;li>ca.pem - сам сертификат&lt;/li>
&lt;li>ca.csr - запрос на сертификат (публичный ключ без подписи).&lt;/li>
&lt;/ul>
&lt;p>Лично я рекомендую для общего удобства работы ключи класть в отдельную папку, ее можно, к примеру, назвать keys:&lt;/p>
&lt;pre>&lt;code>mkdir keys
mv ca-key.pem ca.csr ca.pem keys/
&lt;/code>&lt;/pre>
&lt;p>Чтобы в Теперь создадим конфиг для создания клиентских ключей и сертификатов. Назовем его, например, ca.json:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;signing&amp;quot;: {
&amp;quot;profiles&amp;quot;: {
&amp;quot;server&amp;quot;: {
&amp;quot;expiry&amp;quot;: &amp;quot;17520h&amp;quot;,
&amp;quot;usages&amp;quot;: [
&amp;quot;digital signature&amp;quot;,
&amp;quot;key encipherment&amp;quot;,
&amp;quot;server auth&amp;quot;
]
},
&amp;quot;client&amp;quot;: {
&amp;quot;expiry&amp;quot;: &amp;quot;8760h&amp;quot;,
&amp;quot;usages&amp;quot;: [
&amp;quot;signing&amp;quot;,
&amp;quot;client auth&amp;quot;
]
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>В этом примере у нас два профиля – сертификаты для сервера (со сроком жизни в 2 года) и для клиента (на год). Сертификат клиента может использоваться для авторизации клиентского подключения (например, в OpenVPN), но такой сертификат нельзя выдать серверу.&lt;/p>
&lt;p>Чтобы мочь использовать конфиг для CSR (и не вводить заново страну, регион и прочее) – его нужно подправить, убрав из него секцию CA:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;CN&amp;quot;: &amp;quot;Test Root CA&amp;quot;,
&amp;quot;key&amp;quot;: {
&amp;quot;algo&amp;quot;: &amp;quot;rsa&amp;quot;,
&amp;quot;size&amp;quot;: 2048
},
&amp;quot;names&amp;quot;: [
{
&amp;quot;C&amp;quot;: &amp;quot;RU&amp;quot;,
&amp;quot;L&amp;quot;: &amp;quot;Saint Petersburg&amp;quot;,
&amp;quot;O&amp;quot;: &amp;quot;Test Company&amp;quot;,
&amp;quot;OU&amp;quot;: &amp;quot;Internal systems unit&amp;quot;,
&amp;quot;ST&amp;quot;: &amp;quot;Saint Petersburg&amp;quot;
}
]
}
&lt;/code>&lt;/pre>
&lt;p>Теперь сгенерируем серверный ключ:&lt;/p>
&lt;pre>&lt;code>&amp;gt; cfssl gencert -ca=keys/ca.pem \
-ca-key=keys/ca-key.pem \
-config=ca.json \
-profile=&amp;quot;server&amp;quot; \
-cn=&amp;quot;test.server.local&amp;quot; \
-hostname=&amp;quot;test.server.local,test,192.168.1.1&amp;quot; \
csr.json | cfssljson -bare keys/server
2018/12/14 20:28:47 [INFO] generate received request
2018/12/14 20:28:47 [INFO] received CSR
2018/12/14 20:28:47 [INFO] generating key: rsa-2048
2018/12/14 20:28:48 [INFO] encoded CSR
2018/12/14 20:28:48 [INFO] signed certificate with serial number 53158698715503305792227475745544378560981646495
&lt;/code>&lt;/pre>
&lt;p>Аргумент cfssljson -bare keys/server позволяет положить ключ в папку keys, и называться файлы будут с server&lt;/p>
&lt;p>Посмотрим, что получилось:&lt;/p>
&lt;pre>&lt;code>&amp;gt; tree
.
├── ca.json
├── csr.json
└── keys
├── ca-key.pem
├── ca.csr
├── ca.pem
├── server-key.pem
├── server.csr
└── server.pem
&lt;/code>&lt;/pre>
&lt;p>Проверим ключ сервера:&lt;/p>
&lt;pre>&lt;code>&amp;gt; openssl x509 -text -noout -in keys/server.pem
Certificate:
Data:
Version: 3 (0x2)
Serial Number:
09:4f:b7:ef:17:c4:b5:f5:06:f6:66:bb:0f:85:de:f0:b6:8a:3c:9f
Signature Algorithm: sha256WithRSAEncryption
Issuer: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=Internal systems unit, CN=Test Root CA
Validity
Not Before: Dec 14 17:24:00 2018 GMT
Not After : Dec 13 17:24:00 2020 GMT
Subject: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=Internal systems unit, CN=test.server.local
Subject Public Key Info:
Public Key Algorithm: rsaEncryption
Public-Key: (2048 bit)
&lt;/code>&lt;/pre>
&lt;p>Теперь создадим сертификат для клиента (скажем, для OpenVPN):&lt;/p>
&lt;pre>&lt;code>&amp;gt; cfssl gencert -ca=keys/ca.pem \
-ca-key=keys/ca-key.pem \
-config=ca.json \
-profile=&amp;quot;client&amp;quot; \
-cn=&amp;quot;prudnitskiy&amp;quot; \
-hostname=&amp;quot;Paul Rudnitskiy&amp;quot; \
csr.json | cfssljson -bare &amp;quot;keys/prudnitskiy&amp;quot;
2018/12/14 20:35:56 [INFO] generate received request
2018/12/14 20:35:56 [INFO] received CSR
2018/12/14 20:35:56 [INFO] generating key: rsa-2048
2018/12/14 20:35:57 [INFO] encoded CSR
2018/12/14 20:35:57 [INFO] signed certificate with serial number 82476622684473156560886280203356252095924099426
&lt;/code>&lt;/pre>
&lt;p>Проверим сертификат клиента:&lt;/p>
&lt;pre>&lt;code>&amp;gt; openssl x509 -text -noout -in keys/prudnitskiy.pem
Certificate:
Data:
Version: 3 (0x2)
Serial Number:
0e:72:61:32:19:eb:71:30:43:ee:66:6d:8d:8c:e7:e5:bd:57:59:62
Signature Algorithm: sha256WithRSAEncryption
Issuer: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=Internal systems unit, CN=Test Root CA
Validity
Not Before: Dec 14 17:31:00 2018 GMT
Not After : Dec 14 17:31:00 2019 GMT
Subject: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=Internal systems unit, CN=prudnitskiy
Subject Public Key Info:
Public Key Algorithm: rsaEncryption
Public-Key: (2048 bit)
[.....]
X509v3 Subject Alternative Name:
DNS:Paul Rudnitskiy
&lt;/code>&lt;/pre>
&lt;p>Здесь видно, что у клиента сертификат на год, а у сервера (чуть выше) - на два года&lt;/p>
&lt;h2 id="подпись-чужого-сертификата" >Подпись чужого сертификата
&lt;span>
&lt;a href="#%d0%bf%d0%be%d0%b4%d0%bf%d0%b8%d1%81%d1%8c-%d1%87%d1%83%d0%b6%d0%be%d0%b3%d0%be-%d1%81%d0%b5%d1%80%d1%82%d0%b8%d1%84%d0%b8%d0%ba%d0%b0%d1%82%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>В примере выше мы создавали и ключ и сертификат прямо там, где работает центр сертификации. Вообще это не правильно – приватный ключ не должен покидать места своего использования. В этом примере мы создадим приватный ключ, запрос на подпись сертификата и подпишем этот запрос на другом сервере. Создаем ключ:&lt;/p>
&lt;pre>&lt;code>server$ openssl genrsa -aes256 -out client.key 4096
Generating RSA private key, 4096 bit long modulus
...................................................++
................................................................................................................................................................................++
e is 65537 (0x10001)
Enter pass phrase for client.key:
Verifying - Enter pass phrase for client.key:
&lt;/code>&lt;/pre>
&lt;p>Теперь создаем запрос на сертификат:&lt;/p>
&lt;pre>&lt;code>server$ openssl req -new -key client.key -out client.csr
Enter pass phrase for client.key:
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [AU]:RU
State or Province Name (full name) [Some-State]:Saint Petersburg
Locality Name (eg, city) []:Saint Petersburg
Organization Name (eg, company) [Internet Widgits Pty Ltd]:Test Company
Organizational Unit Name (eg, section) []:International section
Common Name (e.g. server FQDN or YOUR name) []:test2.ssign.local
Email Address []:
Please enter the following 'extra' attributes
to be sent with your certificate request
A challenge password []:
An optional company name []:
&lt;/code>&lt;/pre>
&lt;p>У нас есть приватный ключ и запрос на сертификат:&lt;/p>
&lt;pre>&lt;code>server$ tree
.
├── client.csr
└── client.key
&lt;/code>&lt;/pre>
&lt;p>Запрос отправим на сервер и подпишем:&lt;/p>
&lt;pre>&lt;code>&amp;gt; cfssl sign -ca keys/ca.pem \
-ca-key keys/ca-key.pem \
-config=ca.json \
-profile=&amp;quot;server&amp;quot; \
client.csr | cfssljson -bare &amp;quot;keys/signed&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Проверим, что получилось:&lt;/p>
&lt;pre>&lt;code>&amp;gt; openssl x509 -text -noout -in keys/signed.pem
Certificate:
Data:
Version: 3 (0x2)
Serial Number:
06:08:a0:e6:77:a0:a3:f2:15:82:6c:8a:da:9c:9a:73:df:a4:aa:5c
Signature Algorithm: sha256WithRSAEncryption
Issuer: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=Internal systems unit, CN=Test Root CA
Validity
Not Before: Dec 14 17:45:00 2018 GMT
Not After : Dec 13 17:45:00 2020 GMT
Subject: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=International section, CN=test2.ssign.local
Subject Public Key Info:
Public Key Algorithm: rsaEncryption
Public-Key: (4096 bit)
&lt;/code>&lt;/pre>
&lt;p>keys/signed.pem – это и есть наш подписанный сертификат – его можно возвращать на сервер и использовать.&lt;/p>
&lt;h2 id="intermediate-center-of-authorities" >Intermediate center of authorities
&lt;span>
&lt;a href="#intermediate-center-of-authorities">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>InterimCA - это центр сертификации, подписанный другим центром сертификации. Его можно использовать для большей безопасности или разграничения возможности подписывать разные сертификаты для разных ситуаций (например, сделать CA, который подписывает только соединение с базами данных и ничего более). Сделаем для его отдельную папку и положим туда два конфига:&lt;/p>
&lt;p>l2init.json:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;signing&amp;quot;: {
&amp;quot;default&amp;quot;: {
&amp;quot;usages&amp;quot;: [
&amp;quot;cert sign&amp;quot;,
&amp;quot;crl sign&amp;quot;
],
&amp;quot;expiry&amp;quot;: &amp;quot;43800h&amp;quot;,
&amp;quot;ca_constraint&amp;quot;: {
&amp;quot;is_ca&amp;quot;: true,
&amp;quot;max_path_len&amp;quot;: 0,
&amp;quot;max_path_len_zero&amp;quot;: true
},
&amp;quot;crl_url&amp;quot;: &amp;quot;https://server.com/pki/crl&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>В этом примере CA будет действовать 5 лет (root CA действует 10)&lt;/p>
&lt;p>l2csr.json:&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;CN&amp;quot;: &amp;quot;Level2 CA&amp;quot;,
&amp;quot;key&amp;quot;: {
&amp;quot;algo&amp;quot;: &amp;quot;ecdsa&amp;quot;,
&amp;quot;size&amp;quot;: 384
},
&amp;quot;names&amp;quot;: [
{
&amp;quot;C&amp;quot;: &amp;quot;RU&amp;quot;,
&amp;quot;L&amp;quot;: &amp;quot;Saint Petersburg&amp;quot;,
&amp;quot;O&amp;quot;: &amp;quot;Test Company&amp;quot;,
&amp;quot;OU&amp;quot;: &amp;quot;Internal systems unit&amp;quot;,
&amp;quot;ST&amp;quot;: &amp;quot;Saint Petersburg&amp;quot;
}
]
}
&lt;/code>&lt;/pre>
&lt;p>В этом примере мы используем ключ на эллиптических кривых, 384 бита&lt;/p>
&lt;p>Сгенерируем ключ для L2CA:&lt;/p>
&lt;pre>&lt;code>&amp;gt; cfssl gencert -initca l2/l2csr.json | cfssljson -bare &amp;quot;l2/l2ca&amp;quot;
2018/12/14 21:09:11 [INFO] generating a new CA key and certificate from CSR
2018/12/14 21:09:11 [INFO] generate received request
2018/12/14 21:09:11 [INFO] received CSR
2018/12/14 21:09:11 [INFO] generating key: ecdsa-384
2018/12/14 21:09:11 [INFO] encoded CSR
2018/12/14 21:09:11 [INFO] signed certificate with serial number 113401202328445156746253039479389987233218778440
&lt;/code>&lt;/pre>
&lt;p>Теперь подпишем его ключом Root CA:&lt;/p>
&lt;pre>&lt;code>&amp;gt; cfssl sign -ca keys/ca.pem \
-ca-key keys/ca-key.pem \
-config=l2/l2init.json l2/l2ca.csr | cfssljson -bare &amp;quot;l2/l2ca&amp;quot;
2018/12/14 21:09:21 [INFO] signed certificate with serial number 716266849684210842961608276575977912635137621329
&lt;/code>&lt;/pre>
&lt;p>Проверим:&lt;/p>
&lt;pre>&lt;code>&amp;gt; openssl x509 -text -noout -in l2/l2ca.pem
Certificate:
Data:
Version: 3 (0x2)
Serial Number:
7d:76:84:30:b6:71:47:f6:51:0a:f1:40:4d:26:86:21:0c:da:7d:51
Signature Algorithm: sha256WithRSAEncryption
Issuer: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=Internal systems unit, CN=Test Root CA
Validity
Not Before: Dec 14 18:04:00 2018 GMT
Not After : Dec 13 18:04:00 2023 GMT
Subject: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=Internal systems unit, CN=Level2 CA
&lt;/code>&lt;/pre>
&lt;p>Здесь хорошо видно, что ключ подписан Test Root CA (Issuer)&lt;/p>
&lt;p>Теперь можно создавать ключи, подписаные L2CA - как в прошлом примере:&lt;/p>
&lt;pre>&lt;code>&amp;gt; cfssl gencert -ca=l2/l2ca.pem \
-ca-key=l2/l2ca-key.pem \
-config=ca.json \
-profile=&amp;quot;server&amp;quot; \
-cn=&amp;quot;test.l2.server.local&amp;quot; \
-hostname=&amp;quot;test.l2.server.localtest,172.16.0.1&amp;quot; \
l2/l2csr.json | cfssljson -bare l2/server
&lt;/code>&lt;/pre>
&lt;p>Здесь мы используем ca.json из root ca (там хранятся профили подписи - время жизни и key usage), а конфигурацию CSR - уже из L2 (тип ключа, секция names).&lt;/p>
&lt;p>Проверим сгенерированый сертификат:&lt;/p>
&lt;pre>&lt;code>&amp;gt; openssl x509 -text -noout -in l2/server.pem
Certificate:
Data:
Version: 3 (0x2)
Serial Number:
30:a0:58:e2:3c:0e:f3:ec:73:64:b0:e1:25:0a:86:26:46:43:21:e2
Signature Algorithm: ecdsa-with-SHA384
Issuer: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=Internal systems unit, CN=Level2 CA
Validity
Not Before: Dec 14 18:11:00 2018 GMT
Not After : Dec 13 18:11:00 2020 GMT
Subject: C=RU, ST=Saint Petersburg, L=Saint Petersburg, O=Test Company, OU=Internal systems unit, CN=test.l2.server.local
&lt;/code>&lt;/pre>
&lt;p>Подписант – Level2CA&lt;/p>
&lt;p>Создадим цепочку доверенных сертификатов. Цепочка читается “снизу вверх”, то есть в самом низу цепочки у нас находится root CA:&lt;/p>
&lt;pre>&lt;code>&amp;gt; cat l2/l2ca.pem keys/ca.pem &amp;gt; chain.pem
&lt;/code>&lt;/pre>
&lt;p>Проверим, что сертификат сервера - действительный:&lt;/p>
&lt;pre>&lt;code>&amp;gt; openssl verify -CAfile chain.pem l2/server.pem
l2/server.pem: OK
&lt;/code>&lt;/pre>
&lt;h2 id="выводы" >Выводы
&lt;span>
&lt;a href="#%d0%b2%d1%8b%d0%b2%d0%be%d0%b4%d1%8b">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>TLS - основа современной сети. При правильной настройке TLS обеспечивает надежную и безопасное шифрование с проверкой всех участников процесса. CFSSL – простой, быстрый и удобный инструмент для запуска SSL CA. Он позволяет избежать само-подписанных сертификатов и помогает построить инфраструктуру обмена ключами для шифрованных соединений. Так, как большинство серверов работает в сети, которой по определению нельзя доверять – использовать шифрование необходимо, а благодаря CFSSL – это несложно.&lt;/p></description></item><item><title>Repmgr: управление репликацией postgresql</title><link>https://prudnitskiy.pro/post/2018-08-22-repmgr/</link><pubDate>Wed, 22 Aug 2018 12:00:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2018-08-22-repmgr/</guid><description>&lt;p>PostgreSQL - это мощная и очень развитая база данных, функциональная и дружелюбная. В комплект входит надежный и очень удобный механизм потоковой репликации (я писал о нем &lt;a href="https://prudnitskiy.pro/2018-01-05-pgsql-replica">здесь&lt;/a>). Не смотря на мощь и удобство – этот инструмент сложен в настройке и не всегда понятен, особенно, если серверов баз много. Все становится еще хуже, если у вас сложная схема репликации с каскадами (master &amp;gt; slave &amp;gt; slave of slave). Чтобы облегчить жизнь DBA в таких ситуациях – известные специалисты по консалтингу Postgres, компания 2ndQuadrant придумали repmgr – специальный инструмент для управления настройками репликации для PostgreSQL.&lt;/p>
&lt;p>Repmgr может:&lt;/p>
&lt;ul>
&lt;li>облегчить создание новых серверов&lt;/li>
&lt;li>облегчить переключение на другой сервер (promote)&lt;/li>
&lt;li>автоматизировать переключение на новый сервер при отказе старого (failover)&lt;/li>
&lt;li>вести аудит событий репликации в кластере (event flow)&lt;/li>
&lt;li>официально repmgr поддерживает мультимастер с помощью механизма bidirectional replication. Это жуткий грязный хак, и я очень не рекомендую его использовать&lt;/li>
&lt;/ul>
&lt;p>Repmgr требует (ограничения):&lt;/p>
&lt;ul>
&lt;li>postgresql 9 или 10 (так как только в 9 версии появилась потоковая репликаця)&lt;/li>
&lt;li>доступ с каждого узла кластера на каждый узел кластера по протоколам SSH (непривелигированый) и postgresql (5432)&lt;/li>
&lt;li>одинаковую версию Postgres (только major)&lt;/li>
&lt;li>одинаковую архитектуру сервера (вы не сможете реплицировать данные с ARM на AMD64)&lt;/li>
&lt;li>одинаковую версию repmgr на всех узлах кластера (одинаковость должна быть &lt;em>полной&lt;/em>)&lt;/li>
&lt;li>пользователя с правами SUPERUSER, от имени которого repmgr будет проводить операции. Пароль от этого пользователя хранится в файловой системе кластера в открытом виде.&lt;/li>
&lt;/ul>
&lt;h2 id="установка" >Установка
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Repmgr поставляется в виде пакета и входит в стандартный для всех пользователей postgresql репозиторий PGDG. В данной статье я продемонстрирую настройку для debian, но для centos он настраивается практически так же – меняются только пути доступа к файлам. Добавим репозиторий:&lt;/p>
&lt;pre>&lt;code>sh -c 'echo &amp;quot;deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main&amp;quot; &amp;gt; /etc/apt/sources.list.d/pgdg.list'
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | apt-key add -
apt-get update
&lt;/code>&lt;/pre>
&lt;p>Теперь можно установить необходимые для работы пакеты:&lt;/p>
&lt;pre>&lt;code>apt-get install postgresql-10 postgresql-10-repmgr -y
&lt;/code>&lt;/pre>
&lt;p>Для repmgr важно, чтобы все хосты видели друг друга по hostname. Я рекомендую иметь внутренний DNS для решения этой задачи, но если у вас по какой-то причине его нет – придется добавить имена и адреса серверов кластера в &lt;code>/etc/hosts&lt;/code>. Например:&lt;/p>
&lt;pre>&lt;code>192.168.0.17 pg1.lab.office pg1
192.168.0.18 pg2.lab.office pg2
192.168.0.19 pg3.lab.office pg3
&lt;/code>&lt;/pre>
&lt;p>Для того, что бы repmgr мог копировать базу с одного сервера на другой – пользователю repmgrd нужен доступ по ssh без ввода пароля. Для этого на каждом из серверов нужно сгенерировать ssh public key. Этот public key нужно положить на все остальные сервера кластера в файл &lt;code>~/.ssh/authorized_keys&lt;/code>. Это нужно сделать для пользователя, от которого будет запущен repmgr. Обычно это тот же пользователь, от имени которого запущен postgres. Создадим ключи на каждом сервере:&lt;/p>
&lt;pre>&lt;code>sudo -u postgres ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/var/lib/postgresql/.ssh/id_rsa):
Created directory '/var/lib/postgresql/.ssh'.
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /var/lib/postgresql/.ssh/id_rsa.
Your public key has been saved in /var/lib/postgresql/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:oqFJ3/Gr8oeBgQpAsKSlImbUOLroa/YaFbJ8AxlsBng postgresql@pg1
&lt;/code>&lt;/pre>
&lt;p>Публичный ключ из файла &lt;code>/var/lib/postgresql/.ssh/id_rsa.pub&lt;/code> надо добавить на все остальные сервера кластера, в файл &lt;code>~/.ssh/authorized_keys&lt;/code>. Заодно поправим права:&lt;/p>
&lt;pre>&lt;code>#на сервере pg1
echo &amp;quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCoavDuAETBMZBD0NwRvSEDYL1avCIkSLzxMG50L6b7nIeasrfv90AGjARxID9THkUXDNkdKhfRIu+WGFYxlgZ6zqPQCyZyQvKjcJr325pbo9it474LpLpeHuPrXdeMSzSilxvAKvYX/ml7L9KtOnYMDusFK1XdGeV25qcj2OSLWBY168riW5vvGWFYTCdU6q9eQ+JN2zCpoZzXKNqhh+dpItt1QiKRw84u7EtUW6U02tw1V5nmO+HGyG2A50S5/JNS7lbj/7IYAXwIgtlBrf3mzCPCIoHbjlSny/V6sp3S7QWNrxynpkI7o+oMvJq5frAEpn0syiUmtOz56Qnw67GP postgres@pg2&amp;quot; &amp;gt;&amp;gt; /var/lib/postgresql/.ssh/authorized_keys
echo &amp;quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDfl8Rg47u97kGUPf7OwF4jeGhcIxVtWEVDk1AKJt5o3Y65v5jzrjoI5F0YrboEzr+oPu5BV24M6dOI5u3ysRBX/osQI2fBlt+hotAIWXPiP8UUy9CgIdQH59h/MJcp3jPH0KYQTwF8WJDr1skUcUzKGswuofBaElm5TpME+Oz2vygXEl2vL9Pfo5kfdsk9ov58cUJNlDGtxTo/Rzw9XFRnkBimzwvem/gmdpYBFb45ulsbLVmdBcv+QTU7PQ+knqIyERboTecS8wBYoKnlCTA0LZscvyeHjKwILSl9ZFfir3CRdYtxNqx4Zk/hMphx4Bt7hn96KUXRiMf3ODpd2yp1 postgres@pg3&amp;quot; &amp;gt;&amp;gt; /var/lib/postgresql/.ssh/authorized_keys
chown postgres /var/lib/postgresql/.ssh/authorized_keys
chmod 600 /var/lib/postgresql/.ssh/authorized_keys
&lt;/code>&lt;/pre>
&lt;p>Убедимся, что доступ есть:&lt;/p>
&lt;pre>&lt;code>root@pg1:~# sudo -u postgres ssh pg2.lab.office -x 'w'
09:04:07 up 3 days, 23:48, 1 user, load average: 0.00, 0.00, 0.00
USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT
logan pts/0 192.168.0.70 14:28 1:19 0.22s 0.02s sshd: logan [priv]
&lt;/code>&lt;/pre>
&lt;p>Для остальных серверов делаем по аналогии.&lt;/p>
&lt;p>Для того, чтобы процесс repmgr мог сам перезапускать постгрес - ему нужны соответствующие права. Чтобы их дать - создадим файл &lt;code>/etc/sudoers.d/repmgr&lt;/code> и впишем туда:&lt;/p>
&lt;pre>&lt;code>Cmnd_Alias PGRE = /bin/systemctl status postgresql, \
/bin/systemctl start postgresql, \
/bin/systemctl stop postgresql, \
/bin/systemctl restart postgresql, \
/bin/systemctl reload postgresql
postgres ALL=(ALL) NOPASSWD: PGRE
&lt;/code>&lt;/pre>
&lt;p>Это позволит пользователю postgres перезапускать процесс сервера postgres.&lt;/p>
&lt;p>Теперь нам надо настроить сам postgresql. Обязательный минимум:&lt;/p>
&lt;ul>
&lt;li>доступность из сети (директива &lt;code>listen_addresses&lt;/code>)&lt;/li>
&lt;li>репликация (&lt;code>wal_level&lt;/code>, &lt;code>archive_mode&lt;/code>)&lt;/li>
&lt;li>лимит &lt;code>max_wal_senders&lt;/code> - как минимум на 1 больше количества серверов в кластере&lt;/li>
&lt;li>&lt;code>hot_standby&lt;/code> - для серверов в режиме slave.&lt;/li>
&lt;li>права на репликацию в hba&lt;/li>
&lt;/ul>
&lt;p>Если вы строите кластер на debian - настройки надо скопировать на все сервера кластера. Для centos это не обязательно, так как файл настроек лежит прямо в data directory и при клонировании repmgr вытащит файлы.&lt;/p>
&lt;p>Пример настроек - &lt;code>/etc/postgresql/10/main/postgresql.conf&lt;/code>:&lt;/p>
&lt;pre>&lt;code># тут приведены не все настройки, а только то, что я поменял
# часть настроек в файле закомментирована, а в части указаны другие значения.
# Пользуйтесь поиском.
listen_addresses = '*'
wal_level = replica
archive_mode = on
archive_command = 'cp %p /var/lib/pg-arch/%f'
max_wal_senders = 4
hot_standby = on
&lt;/code>&lt;/pre>
&lt;p>В данном примере мы не удаляем архивированные сегменты, а перемещаем их папку &lt;code>/var/lib/pg-arch/&lt;/code>. Это позволит восстановить &amp;ldquo;отставший&amp;rdquo; slave. Подробнее я писал &lt;a href="https://prudnitskiy.pro/2018-01-05-pgsql-replica">здесь&lt;/a>. Эту папку нужно создать (владелец - postgres, права доступа - 700). Папку нужно периодически чистить – postgres сам не очищает архивы. В упомянутой выше статье вы найдете детальное описание.&lt;/p>
&lt;p>Пример настроек hba. В данном примере пользователь БД называется &lt;code>repmgr&lt;/code>. Служебная база repmgr - &lt;code>repmgrdb&lt;/code>:&lt;/p>
&lt;pre>&lt;code># Не менять! сломаются локальные операции!
local all postgres peer
# TYPE DATABASE USER ADDRESS METHOD
local all all md5
host all all 127.0.0.1/32 md5
host all all ::1/128 md5
# replication settings
local replication all peer
host replication all 127.0.0.1/32 md5
host replication all ::1/128 md5
host repmgrdb repmgr 192.168.0.0/24 md5
host replication repmgr 192.168.0.0/24 md5
#remote access to server cluster. any DB, any user, any host, password required
host all all 0.0.0.0/0 md5
&lt;/code>&lt;/pre>
&lt;p>С настройкой postgres закончили, перезапускаем сервер и создаем служебную базу и пользователя. Пароль для пользователя лучше сделать посложнее:&lt;/p>
&lt;pre>&lt;code>service postgresql status
sudo -u postgres psql
psql (10.4 (Debian 10.4-2.pgdg90+1))
Type &amp;quot;help&amp;quot; for help.
postgres=# create user repmgr with superuser;
postgres=# alter role repmgr with password 'Ahn7yaechie6hoe0av8eF0ei';
postgres=# create database repmgrdb owner repmgr;
postgres=# \q
&lt;/code>&lt;/pre>
&lt;p>Чтобы repmgr мог обращаться к серверу БД и ему не требовалось вводить пароль – нужно создать файл &lt;code>/var/lib/postgresql/.pgpass&lt;/code>. Владельцем файла должен быть пользователь postgres, права - 0600 (иначе он игнорируется). Структура файла - &lt;code>IP:port:DB:user:password&lt;/code>. &lt;code>*&lt;/code> означает &amp;ldquo;любое&amp;rdquo;. К сожалению pgpass не в состоянии работать с CIDR, то есть задать адрес как &lt;code>192.168.0.*&lt;/code> можно, а &lt;code>192.168.0.0/24&lt;/code> – нельзя. Пример файла:&lt;/p>
&lt;pre>&lt;code>*:5432:repmgrdb:repmgr:Ahn7yaechie6hoe0av8eF0ei
*:5432:replication:repmgr:Ahn7yaechie6hoe0av8eF0ei
&lt;/code>&lt;/pre>
&lt;p>Вторая запись нужна для самого процесса репликации.&lt;/p>
&lt;p>Теперь настроим repmgr. Его настройки в debian лежат в файле &lt;code>/etc/repmgr.conf&lt;/code>. Пример с комментариями:&lt;/p>
&lt;pre>&lt;code># ID узла (сервера). В рамках кластера обязательно уникальный
node_id=1
# hostname. Остальные узлы должны иметь возможность найти этот именно по этому имени.
node_name='pg1.lab.office'
# строка подключения к БД
conninfo='host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2'
# директория с данными postgres.
data_directory='/var/lib/postgresql/10/main/'
# режим репликации. Пока что поддерживается только этот
replication_type=physical
# log file. Не забудьте создать папку для него.
log_file='/var/log/repmgr/repmgr.log'
# записывать статус каждые 5 минут (300 секунд)
log_status_interval=300
# где находятся bin-файлы postgres.
pg_bindir='/usr/lib/postgresql/10/bin/'
# не использовать password из conninfo (строки выше)
# мы храним пароль в .pgpass, это безопаснее. Потому - false
use_primary_conninfo_password=false
ssh_options='-q -o ConnectTimeout=10'
# режим failover
failover=manual
# очередность выборов мастера в случае отказа
# эта настройка и последующие применимы только если failover - auto
priority=100
reconnect_attempts=3
reconnect_interval=5
promote_command='/usr/bin/repmgr -f /etc/repmgr.conf standby promote --log-to-file'
follow_command='/usr/bin/repmgr standby follow -f /etc/repmgr.conf --log-to-file --upstream-node-id=%n'
# команды запуска, остановки и перезапуска сервиса. Должны соответствовать тому, что мы вписали в sudo.
service_start_command = 'sudo -n /bin/systemctl start postgresql'
service_stop_command = 'sudo -n /bin/systemctl stop postgresql'
service_restart_command = 'sudo -n /bin/systemctl restart postgresql'
service_reload_command = 'sudo -n /bin/systemctl reload postgresql'
&lt;/code>&lt;/pre>
&lt;p>Теперь можно зарегистрировать первый сервер в кластере:&lt;/p>
&lt;pre>&lt;code>sudo -u postgres repmgr -f /etc/repmgr.conf primary register
&lt;/code>&lt;/pre>
&lt;p>Проверим, что он там появился:&lt;/p>
&lt;pre>&lt;code>root@pg1:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | * running | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
&lt;/code>&lt;/pre>
&lt;p>Все ок. Теперь настроим остальные два сервера. Они настраиваются по аналогии с первым сервером. Только в конфиге repmgr.conf нужно поменять node_id, node_name и conninfo. На 2 и 3 серверах запускать postgres не нужно.&lt;/p>
&lt;p>Удалим существующий data-dir и склонируем базу с мастера:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# service postgresql stop
root@pg2:~# rm -rf /var/lib/postgresql/10/main/*
root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf -h pg1.lab.office -U repmgr -d repmgrdb standby clone
NOTICE: destination directory &amp;quot;/var/lib/postgresql/10/main/&amp;quot; provided
NOTICE: starting backup (using pg_basebackup)...
HINT: this may take some time; consider using the -c/--fast-checkpoint option
NOTICE: standby clone (using pg_basebackup) complete
NOTICE: you can now start your PostgreSQL server
HINT: for example: sudo -n /bin/systemctl start postgresql
HINT: after starting the server, you need to register this standby with &amp;quot;repmgr standby register&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Запускаем сервер, регистрируемся:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# service postgresql start
root@pg2:~# sudo -u postgres /usr/bin/repmgr standby register
NOTICE: standby node &amp;quot;pg2.lab.office&amp;quot; (id: 2) successfully registered
&lt;/code>&lt;/pre>
&lt;p>Проверяем, что изменилось:&lt;/p>
&lt;pre>&lt;code>root@pg1:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | * running | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
2 | pg2.lab.office | standby | running | pg1.lab.office | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
&lt;/code>&lt;/pre>
&lt;p>Третий сервер запускаем по аналогии со вторым.&lt;/p>
&lt;h2 id="failover" >Failover
&lt;span>
&lt;a href="#failover">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Итак, мастер сломался и надо переключится на slave:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+---------------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | ? unreachable | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
2 | pg2.lab.office | standby | running | pg1.lab.office | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
3 | pg3.lab.office | standby | running | pg1.lab.office | default | host=pg3.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
WARNING: following issues were detected
- when attempting to connect to node &amp;quot;pg1.lab.office&amp;quot; (ID: 1), following error encountered :
&amp;quot;could not connect to server: Connection refused
Is the server running on host &amp;quot;pg1.lab.office&amp;quot; (192.168.0.17) and accepting
TCP/IP connections on port 5432?&amp;quot;
- node &amp;quot;pg1.lab.office&amp;quot; (ID: 1) is registered as an active primary but is unreachable
&lt;/code>&lt;/pre>
&lt;p>Прежде чем продолжить – обязательно убедитесь, что старый мастер (pg1) отключен и не &amp;ldquo;оживет&amp;rdquo; в самый неподходящий момент. Repmgr не умеет работать с fencing-ом и вы можете потерять часть данных.&lt;/p>
&lt;p>Повышаем pg2 до мастера:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf standby promote
NOTICE: promoting standby to primary
DETAIL: promoting server &amp;quot;pg2.lab.office&amp;quot; (ID: 2) using &amp;quot;/usr/lib/postgresql/10/bin/pg_ctl -w -D '/var/lib/postgresql/10/main/' promote&amp;quot;
waiting for server to promote.... done
server promoted
NOTICE: STANDBY PROMOTE successful
DETAIL: server &amp;quot;pg2.lab.office&amp;quot; (ID: 2) was successfully promoted to primary
&lt;/code>&lt;/pre>
&lt;p>Проверяем статус:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | - failed | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
2 | pg2.lab.office | primary | * running | | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
3 | pg3.lab.office | standby | running | pg1.lab.office | default | host=pg3.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
&lt;/code>&lt;/pre>
&lt;p>pg3 по-прежнему ждет данных от pg1. Его нужно переключить на новый мастер:&lt;/p>
&lt;pre>&lt;code>root@pg3:~# sudo -u postgres /usr/bin/repmgr standby follow -f /etc/repmgr.conf --upstream-node-id=2
NOTICE: setting node 3's primary to node 2
NOTICE: restarting server using &amp;quot;sudo -n /bin/systemctl restart postgresql&amp;quot;
NOTICE: STANDBY FOLLOW successful
DETAIL: node 3 is now attached to node 2
&lt;/code>&lt;/pre>
&lt;p>Проверим состояние кластера:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | - failed | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
2 | pg2.lab.office | primary | * running | | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
3 | pg3.lab.office | standby | running | pg2.lab.office | default | host=pg3.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
WARNING: following issues were detected
- when attempting to connect to node &amp;quot;pg1.lab.office&amp;quot; (ID: 1), following error encountered :
&amp;quot;could not connect to server: Connection refused
Is the server running on host &amp;quot;pg1.lab.office&amp;quot; (192.168.0.17) and accepting
TCP/IP connections on port 5432?&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Теперь мы можем убрать старый сервер из конфигурации:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf primary unregister --node-id=1
&lt;/code>&lt;/pre>
&lt;p>Проверяем еще раз:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
2 | pg2.lab.office | primary | * running | | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
3 | pg3.lab.office | standby | running | pg2.lab.office | default | host=pg3.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
&lt;/code>&lt;/pre>
&lt;p>Теперь можно спокойно чинить pg1, без риска что он внезапно вернется в сеть и будет конфликт записи в slave.&lt;/p>
&lt;h2 id="возврат-мастера" >Возврат мастера
&lt;span>
&lt;a href="#%d0%b2%d0%be%d0%b7%d0%b2%d1%80%d0%b0%d1%82-%d0%bc%d0%b0%d1%81%d1%82%d0%b5%d1%80%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Самый простой способ вернуть старый сервер - удалить его datadir и зарегистрировать заново как slave:&lt;/p>
&lt;pre>&lt;code>root@pg1:~# rm -rf /var/lib/postgresql/10/main/*
root@pg1:~# sudo -u postgres repmgr -f /etc/repmgr.conf -h pg2.lab.office -U repmgr -d repmgrdb standby clone
NOTICE: destination directory &amp;quot;/var/lib/postgresql/10/main/&amp;quot; provided
NOTICE: starting backup (using pg_basebackup)...
HINT: this may take some time; consider using the -c/--fast-checkpoint option
NOTICE: standby clone (using pg_basebackup) complete
NOTICE: you can now start your PostgreSQL server
HINT: for example: sudo -n /bin/systemctl start postgresql
HINT: after starting the server, you need to register this standby with &amp;quot;repmgr standby register&amp;quot;
root@pg1:~# service postgresql start
root@pg1:~# sudo -u postgres /usr/bin/repmgr standby register
WARNING: --upstream-node-id not supplied, assuming upstream node is primary (node ID 2)
NOTICE: standby node &amp;quot;pg1.lab.office&amp;quot; (id: 1) successfully registered
&lt;/code>&lt;/pre>
&lt;h2 id="заключение" >Заключение
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Repmgr - простой, понятный инструмент, который сильно облегчает операции в master-slave конфигурациях. Он не позволит полностью автоматизировать защиту от отказов (для этого нужны другие инструменты), но поможет в простых конфигурациях. Я очень рекомендую использовать его – самостоятельно или в сочетании с pgpool-II. В таком варианте pgpool отвечает за балансировку запросов, фенсинг и инициирует failover, когда это необходимо. Repmgr отвечает за сам низкоуровневый процесс failover (и это намного лучше, чем рекомендуемый pgpool набор жутковатых скриптов!).&lt;/p>
&lt;p>При этом я очень не рекомендую:&lt;/p>
&lt;ul>
&lt;li>использовать автоматический failover средствами repmgr. Строго говоря – он не работает. Для работы repmgr нужен работающий сервер postgresql, и если postgresql master упал – repmgr не в состоянии самостоятельно переключится (из-за упавшего мастера)&lt;/li>
&lt;li>использовать bidirectional multimaster. Эта функция заявлена в описании, но работает крайне плохо - сервера теряют связь друг с другом и часто трут конфликтующие данные. Проверено до версии &lt;strong>4.0.5&lt;/strong>&lt;/li>
&lt;/ul></description></item><item><title>Yubikey + GPG – быстрый старт</title><link>https://prudnitskiy.pro/post/2018-08-02-yubikey-gpg/</link><pubDate>Thu, 02 Aug 2018 09:00:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2018-08-02-yubikey-gpg/</guid><description>&lt;p>Требования к безопасности непрерывно растут, так как взломщики постоянно эволюционируют и все лучше умеют красть данные. Доступ к данным становится все более ценным - это могут быть живые деньги, секретная информация или доступ в инфраструктуру, интеллектуальную собственность или пользовательские данные (которые эта инфраструктура обрабатывает). А это – очень большие деньги. А иногда и вовсе вопрос жизни и смерти целой структуры.&lt;/p>
&lt;p>Простой системы логин/пароль уже недостаточно, чтобы обеспечить надежную защиту, и даже система с ассиметричными ключами имеет уязвимости:&lt;/p>
&lt;ul>
&lt;li>ключ можно выкрасть. Он будет шифрован, но пароль можно подобрать. Это медленный процесс, но взломщику может повезти, особенно, если у него есть какая-то информация об особенностях пароля. Например, он знает его точную длинну.&lt;/li>
&lt;li>Для того, чтобы ключ можно было использовать - он должен быть расшифрован. Обычно расшифрованый ключ хранится в оперативной памяти, но при наличии доступа к памяти его можно украсть. Атака сложная, но если ключ по-настоящиему ценный - реальная.&lt;/li>
&lt;/ul>
&lt;p>Для того, чтобы сделать работу с шифрованием надежной и безопасной – были придуманы аппаратные носители ключей. Концепция выглядит просто – шифровальный ключ не покидает аппаратного токена (обычно это смарт-карта с чипом), и если операционной системе требуется произвести какое-то действие с шифрованием (зашифровка, расшифровка, подпись) – данные передаются в аппаратный ключ. Ключ выполняет действия (если проситель имеет право на такие действия) и выдает результат.&lt;/p>
&lt;p>В этой статье я расскажу, как настроить Yubikey 4 для работы с GPG и использовать его для стандартных действий (шифрование, расшифровка, авторизация по SSH).&lt;/p>
&lt;p>Yubikey - это именно такой ключ. Это простой, удобный и понятный для начинающего ключ-смарткарта в форм-факторе USB-флешки. Классический Yubikey 4 выпускается в двух форм-факторах – обычная &amp;ldquo;полноразмерная&amp;rdquo; флешка или &amp;ldquo;нано-ключ&amp;rdquo; - вставленный в комп наноключ практически не выступает из порта, что удобно, если ключ подключен постоянно и не должен изыматься. Yubikey 4 выпускается как под USB2 Type A, так и под USB3 Type C порт, что удобно для обладателей новых ноутбуков (macbook pro touch bar). Так же компания Yubiko выпускает Yubkey Neo - Yubkey с поддержкой NFC (для смартфонов), но со сниженным максимальным размером ключа (2048 бит вместо 4096 для Yubikey 4).&lt;/p>
&lt;p>Кроме GPG, Yubikey может работать как стандартная smart-карта и генерировать одноразовые пароли (TOTP/HOTP). В этой статье будет описана только настройка под GPG.&lt;/p>
&lt;h2 id="предварительные-настройки" >Предварительные настройки
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%b5%d0%b4%d0%b2%d0%b0%d1%80%d0%b8%d1%82%d0%b5%d0%bb%d1%8c%d0%bd%d1%8b%d0%b5-%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Для того, чтобы использовать gpg для Yubikey - потребуется сам gpg. Пользователи MacOS могут использовать &lt;a href="https://gpgtools.org/">MacGPG&lt;/a>. Пользователям Linux ничего делать не надо - gpg входит в поставку ОС. Чтобы gpg создал нужные ему папки - запускаем gpgtool. Он предложит создать новый приватный ключ - игнорируем, просто закрываем программу.&lt;/p>
&lt;p>После установки пакета надо добавить в &lt;code>~/.bashrc&lt;/code> следующие строки:&lt;/p>
&lt;pre>&lt;code>export GPG_TTY=&amp;quot;$(tty)&amp;quot;
export SSH_AUTH_SOCK=$(/usr/local/MacGPG2/bin/gpgconf --list-dirs agent-ssh-socket)
if ! pgrep gpg-agent &amp;amp;&amp;gt; /dev/null; then
echo &amp;quot;gpg-agent not running&amp;quot;
/usr/local/MacGPG2/bin/gpg-agent --homedir /Users/YOUR_LOGIN/.gnupg --daemon
fi
&lt;/code>&lt;/pre>
&lt;p>Обратите внимание, что вам нужно поменять логин на свой&lt;/p>
&lt;p>Также надо указать pinentry и включить поддежку ssh-agent в файле &lt;code>~/.gnupg/gpg-agent.conf&lt;/code>:&lt;/p>
&lt;pre>&lt;code>default-cache-ttl 600
max-cache-ttl 7200
pinentry-program /usr/local/MacGPG2/libexec/pinentry-mac.app/Contents/MacOS/pinentry-mac
enable-ssh-support
&lt;/code>&lt;/pre>
&lt;p>Теперь можно подключить yubikey. Проверим, что карта подключилась и определилась:&lt;/p>
&lt;pre>&lt;code>tungsten&amp;gt; gpg --card-edit
Reader ...........: Yubico Yubikey 4 OTP U2F CCID
Application ID ...: D2760001240102010006070171690000
Version ..........: 2.1
Manufacturer .....: Yubico
Serial number ....: 07017169
Name of cardholder: [not set]
Language prefs ...: [not set]
Sex ..............: unspecified
URL of public key : [not set]
Login data .......: [not set]
Signature PIN ....: not forced
Key attributes ...: rsa2048 rsa2048 rsa2048
Max. PIN lengths .: 127 127 127
PIN retry counter : 3 0 3
Signature counter : 0
Signature key ....: [none]
Encryption key....: [none]
Authentication key: [none]
General key info..: [none]
gpg/card&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Отлично, карта есть, можно настраивать. Первое, что нужно поменять - pin-коды карты. У карты два pin-кода:&lt;/p>
&lt;ul>
&lt;li>User PIN - отвечает за проверку авторизации самой карты. Его нужно ввести, чтобы использовать ключ (зашифровать, расшифровать данные или авторизоваться)&lt;/li>
&lt;li>Admin PIN - отвечает за настройку карты. Он позволяет управлять содержимым карты или ее настройками.&lt;/li>
&lt;/ul>
&lt;p>Не смотря на названия, PIN-коды - это полноценные пароли длинной до 127 символов включительно. Пароли имеют ограничения - там нельзя использовать символы национальных алфавитов и спецсимволы. То есть – можно только английские буквы и цифры. Кроме того, Admin PIN должен быть не менее 8 символов длинной. Yubikey никак не предупредит об этом, но pin короче 8 символов просто не запишется. При смене PIN-кода спросят старый PIN. PIN-коды по умолчанию:&lt;/p>
&lt;ul>
&lt;li>User PIN: 123456&lt;/li>
&lt;li>Admin PIN: 12345678&lt;/li>
&lt;/ul>
&lt;p>Переключимся в админ-режим и поменяем пины:&lt;/p>
&lt;pre>&lt;code>gpg/card&amp;gt; admin
Admin commands are allowed
gpg/card&amp;gt; passwd
gpg: OpenPGP card no. D2760001240102010006070171690000 detected
1 - change PIN
2 - unblock PIN
3 - change Admin PIN
4 - set the Reset Code
Q - quit
Your selection? 1
PIN changed.
1 - change PIN
2 - unblock PIN
3 - change Admin PIN
4 - set the Reset Code
Q - quit
Your selection? 3
PIN changed.
1 - change PIN
2 - unblock PIN
3 - change Admin PIN
4 - set the Reset Code
Q - quit
Your selection? q
&lt;/code>&lt;/pre>
&lt;p>Небольшая ремарка про PIN-ы. Карта считает все неуспешные попытки использования PIN-кода. Если ввести PIN-код неправильно несколько раз подряд – он блокируется. User PIN можно разблокировать с помощью Admin PIN. Заблокированный Admin PIN разблокировать нельзя никак. Карту можно полностью сбросить командой &lt;code>factory-reset&lt;/code> - при этом все ее содержимое будет безвозвратно уничтожено. Для &lt;code>factory-reset&lt;/code> никакие пин-коды не нужны. Счетчик неуспешных попыток сбрасывается, если ввести PIN правильно.&lt;/p>
&lt;p>Теперь рекомендуется персонализировать карту - внести в нее информацию о себе. Это мало на что влияет, но имя будет отображаться в диалоге ввода PIN (что облегчает идентификацию карты). Кроме того, общую информацию о карте можно прочитать без кода – это может помочь, если вы потеряете карту. Важный параметр - url, это адрес, с которого можно будет скачать ваш &lt;strong>публичный&lt;/strong> ключ:&lt;/p>
&lt;pre>&lt;code>gpg/card&amp;gt; name
Cardholder's surname: Rudnitskiy
Cardholder's given name: Paul
gpg/card&amp;gt; sex
Sex ((M)ale, (F)emale or space): M
gpg/card&amp;gt; lang
Language preferences: en
gpg/card&amp;gt; login
Login data (account name): logan
gpg/card&amp;gt; url
URL to retrieve public key: https://prudnitskiy.pro/gpg.pub
&lt;/code>&lt;/pre>
&lt;p>Карта готова и теперь можно экспортировать ключ на нее или создать ключ прямо на ней. Если у вас нет ключа - я рекомендую прямо на карте его и создавать. Если ключ уже есть – ниже есть раздел о том, как перенести ключ на карту&lt;/p>
&lt;h2 id="генерация-ключа-на-yubikey" >Генерация ключа на Yubikey
&lt;span>
&lt;a href="#%d0%b3%d0%b5%d0%bd%d0%b5%d1%80%d0%b0%d1%86%d0%b8%d1%8f-%d0%ba%d0%bb%d1%8e%d1%87%d0%b0-%d0%bd%d0%b0-yubikey">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Перед тем, как создавать ключ - я рекомендую поменять его размер. По умолчанию Yubikey создает один мастер-ключ и два сабключа:&lt;/p>
&lt;ul>
&lt;li>Master + Certify&lt;/li>
&lt;li>SUB1 - Encryption&lt;/li>
&lt;li>SUB2 – Authentication&lt;/li>
&lt;/ul>
&lt;p>Все три ключа по умолчанию - RSA2048. RSA4096 выглядит намного интереснее. Поменяем:&lt;/p>
&lt;pre>&lt;code>gpg/card&amp;gt; key-attr
Changing card key attribute for: Signature key
Please select what kind of key you want:
(1) RSA
(2) ECC
Your selection? 1
What keysize do you want? (2048) 4096
The card will now be re-configured to generate a key of 4096 bits
Changing card key attribute for: Encryption key
Please select what kind of key you want:
(1) RSA
(2) ECC
Your selection? 1
What keysize do you want? (2048) 4096
The card will now be re-configured to generate a key of 4096 bits
Changing card key attribute for: Authentication key
Please select what kind of key you want:
(1) RSA
(2) ECC
Your selection? 1
What keysize do you want? (2048) 4096
The card will now be re-configured to generate a key of 4096 bits
gpg: error changing key attribute for key 3: Bad PIN
Changing card key attribute for: Authentication key
Please select what kind of key you want:
(1) RSA
(2) ECC
Your selection? 1
What keysize do you want? (2048) 4096
The card will now be re-configured to generate a key of 4096 bits
&lt;/code>&lt;/pre>
&lt;p>Внимание! Если у вас Yubikey Neo - вы &lt;strong>не можете использовать 4096-битные ключи.&lt;/strong>&lt;/p>
&lt;p>Теперь (наконец-то!) приступим к созданию ключей. Вопрос политики устаревания ключей в целом довольно дискуссионный, и тут я не могу ничего порекомендовать. В данном примере я создам мастер-ключ с бесконечным сроком жизни, а саб-ключи мы потом отредактируем и они будут жить по 5 лет. В процессе создания ключа GPG спросит пароль для шифрования off-card резервной копии. Она вам потребуется, если вы потеряете физический ключ. Off-card экспортируется только subkey для шифрования (capability - E). Остальные sub-ключи и мастер-ключ останутся на карте и вынуть оттуда их нельзя. Процесс генерации ключа зависит от выбранного размера ключа (4096 бит будет генерироваться дольше, чем 2048):&lt;/p>
&lt;pre>&lt;code>gpg/card&amp;gt; generate
Make off-card backup of encryption key? (Y/n) y
Please specify how long the key should be valid.
0 = key does not expire
&amp;lt;n&amp;gt; = key expires in n days
&amp;lt;n&amp;gt;w = key expires in n weeks
&amp;lt;n&amp;gt;m = key expires in n months
&amp;lt;n&amp;gt;y = key expires in n years
Key is valid for? (0) 0
Key does not expire at all
Is this correct? (y/N) y
GnuPG needs to construct a user ID to identify your key.
Real name: Paul Rudnitskiy
Email address: me@prudnitskiy.pro
Comment: YBKey
You selected this USER-ID:
&amp;quot;Paul Rudnitskiy (YBKey) &amp;lt;me@prudnitskiy.pro&amp;gt;&amp;quot;
Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? O
[...]
We need to generate a lot of random bytes. It is a good idea to perform
some other action (type on the keyboard, move the mouse, utilize the
disks) during the prime generation; this gives the random number
generator a better chance to gain enough entropy.
gpg: Note: backup of card key saved to '/Users/logan/.gnupg/sk_8E0418955A55C1A8.gpg'
gpg: key 9ECF9961A551A45B marked as ultimately trusted
gpg: revocation certificate stored as '/Users/logan/.gnupg/openpgp-revocs.d/707C3210B50A430B555DD6AC9ECF9961A551A45B.rev'
public and secret key created and signed.
&lt;/code>&lt;/pre>
&lt;p>Ключ готов. Резервную копию забираем из &lt;code>/Users/logan/.gnupg/sk_8E0418955A55C1A8.gpg&lt;/code> (у вас место будет другим) и прячем в надежное место. Пароль резервной копии тоже прячем в надежное место, но &lt;em>другое&lt;/em>. Обязательно удалите резервную копию с той машины, где вы работаете с ключом.&lt;/p>
&lt;p>Проверим, что ключ сгенерировался:&lt;/p>
&lt;pre>&lt;code>gpg/card&amp;gt; list
Reader ...........: Yubico Yubikey 4 OTP U2F CCID
Application ID ...: D2760001240102010006070171690000
Version ..........: 2.1
Manufacturer .....: Yubico
Serial number ....: 07017169
Name of cardholder: Paul Rudnitskiy
Language prefs ...: en
Sex ..............: male
URL of public key : [not set]
Login data .......: logan
Signature PIN ....: not forced
Key attributes ...: rsa4096 rsa4096 rsa4096
Max. PIN lengths .: 127 127 127
PIN retry counter : 3 0 3
Signature counter : 4
Signature key ....: 707C 3210 B50A 430B 555D D6AC 9ECF 9961 A551 A45B
created ....: 2018-08-07 07:58:18
Encryption key....: 062A ABF7 6FB0 8EF4 0E97 4B47 8E04 1895 5A55 C1A8
created ....: 2018-08-07 07:58:18
Authentication key: 6A41 D75C 2B56 41FC A7F4 8DBE CC02 AF33 8EE7 E338
created ....: 2018-08-07 07:58:18
General key info..: pub rsa4096/9ECF9961A551A45B 2018-08-07 Paul Rudnitskiy (YBKey) &amp;lt;me@prudnitskiy.pro&amp;gt;
sec&amp;gt; rsa4096/9ECF9961A551A45B created: 2018-08-07 expires: never
card-no: 0006 07017169
ssb&amp;gt; rsa4096/CC02AF338EE7E338 created: 2018-08-07 expires: never
card-no: 0006 07017169
ssb&amp;gt; rsa4096/8E0418955A55C1A8 created: 2018-08-07 expires: never
card-no: 0006 07017169
&lt;/code>&lt;/pre>
&lt;p>Все в порядке, уходим:&lt;/p>
&lt;pre>&lt;code>gpg/card&amp;gt; quit
&lt;/code>&lt;/pre>
&lt;p>Теперь зададим срок жизни сабключей. Он нужен для того, чтобы если по какой-то причине вы потеряли доступ к копии ключа – им нельзя было пользовать после истечения срока жизни ключа. Для этого надо выйти из режима редактирования карты и отредактировать ключ. Редактивровать мы будем SEC-ключ, в этом примере это &lt;em>9ECF9961A551A45B&lt;/em>:&lt;/p>
&lt;pre>&lt;code>tungsten&amp;gt; gpg --edit-key 9ECF9961A551A45B
gpg (GnuPG/MacGPG2) 2.2.8; Copyright (C) 2018 Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Secret key is available.
gpg: checking the trustdb
gpg: marginals needed: 3 completes needed: 1 trust model: pgp
gpg: depth: 0 valid: 5 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 5u
gpg: next trustdb check due at 2024-05-30
sec rsa4096/9ECF9961A551A45B
created: 2018-08-07 expires: never usage: SC
card-no: 0006 07017169
trust: ultimate validity: ultimate
ssb rsa4096/CC02AF338EE7E338
created: 2018-08-07 expires: never usage: A
card-no: 0006 07017169
ssb rsa4096/8E0418955A55C1A8
created: 2018-08-07 expires: never usage: E
card-no: 0006 07017169
[ultimate] (1). Paul Rudnitskiy (YBKey) &amp;lt;me@prudnitskiy.pro&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Команда &lt;code>key NUM&lt;/code> выберет ключ для редактирования. Чтобы снять выбор - нужно ввести ее повторно:&lt;/p>
&lt;pre>&lt;code>gpg&amp;gt; key 1
sec rsa4096/9ECF9961A551A45B
created: 2018-08-07 expires: never usage: SC
card-no: 0006 07017169
trust: ultimate validity: ultimate
ssb* rsa4096/CC02AF338EE7E338
created: 2018-08-07 expires: never usage: A
card-no: 0006 07017169
ssb rsa4096/8E0418955A55C1A8
created: 2018-08-07 expires: never usage: E
card-no: 0006 07017169
[ultimate] (1). Paul Rudnitskiy (YBKey) &amp;lt;me@prudnitskiy.pro&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Меняем срок жизни:&lt;/p>
&lt;pre>&lt;code>gpg&amp;gt; expire
Changing expiration time for a subkey.
Please specify how long the key should be valid.
0 = key does not expire
&amp;lt;n&amp;gt; = key expires in n days
&amp;lt;n&amp;gt;w = key expires in n weeks
&amp;lt;n&amp;gt;m = key expires in n months
&amp;lt;n&amp;gt;y = key expires in n years
Key is valid for? (0) 5y
Key expires at Sun Aug 6 11:01:18 2023 MSK
Is this correct? (y/N) y
sec rsa4096/9ECF9961A551A45B
created: 2018-08-07 expires: never usage: SC
card-no: 0006 07017169
trust: ultimate validity: ultimate
ssb* rsa4096/CC02AF338EE7E338
created: 2018-08-07 expires: 2023-08-06 usage: A
card-no: 0006 07017169
ssb rsa4096/8E0418955A55C1A8
created: 2018-08-07 expires: never usage: E
card-no: 0006 07017169
[ultimate] (1). Paul Rudnitskiy (YBKey) &amp;lt;me@prudnitskiy.pro&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Снимаем выделение первого ключа и меняем второй по аналогии:&lt;/p>
&lt;pre>&lt;code>gpg&amp;gt; key 1
sec rsa4096/9ECF9961A551A45B
created: 2018-08-07 expires: never usage: SC
card-no: 0006 07017169
trust: ultimate validity: ultimate
ssb rsa4096/CC02AF338EE7E338
created: 2018-08-07 expires: 2023-08-06 usage: A
card-no: 0006 07017169
ssb rsa4096/8E0418955A55C1A8
created: 2018-08-07 expires: never usage: E
card-no: 0006 07017169
[ultimate] (1). Paul Rudnitskiy (YBKey) &amp;lt;me@prudnitskiy.pro&amp;gt;
gpg&amp;gt; key 2
sec rsa4096/9ECF9961A551A45B
created: 2018-08-07 expires: never usage: SC
card-no: 0006 07017169
trust: ultimate validity: ultimate
ssb rsa4096/CC02AF338EE7E338
created: 2018-08-07 expires: 2023-08-06 usage: A
card-no: 0006 07017169
ssb* rsa4096/8E0418955A55C1A8
created: 2018-08-07 expires: never usage: E
card-no: 0006 07017169
[ultimate] (1). Paul Rudnitskiy (YBKey) &amp;lt;me@prudnitskiy.pro&amp;gt;
gpg&amp;gt; expire
Changing expiration time for a subkey.
Please specify how long the key should be valid.
0 = key does not expire
&amp;lt;n&amp;gt; = key expires in n days
&amp;lt;n&amp;gt;w = key expires in n weeks
&amp;lt;n&amp;gt;m = key expires in n months
&amp;lt;n&amp;gt;y = key expires in n years
Key is valid for? (0) 5y
Key expires at Sun Aug 6 11:01:29 2023 MSK
Is this correct? (y/N) y
sec rsa4096/9ECF9961A551A45B
created: 2018-08-07 expires: never usage: SC
card-no: 0006 07017169
trust: ultimate validity: ultimate
ssb rsa4096/CC02AF338EE7E338
created: 2018-08-07 expires: 2023-08-06 usage: A
card-no: 0006 07017169
ssb* rsa4096/8E0418955A55C1A8
created: 2018-08-07 expires: 2023-08-06 usage: E
card-no: 0006 07017169
[ultimate] (1). Paul Rudnitskiy (YBKey) &amp;lt;me@prudnitskiy.pro&amp;gt;
gpg&amp;gt; save
&lt;/code>&lt;/pre>
&lt;p>Ключ на карте готов к использованию&lt;/p>
&lt;h2 id="перенос-существующего-ключа-на-yubikey" >Перенос существующего ключа на Yubikey
&lt;span>
&lt;a href="#%d0%bf%d0%b5%d1%80%d0%b5%d0%bd%d0%be%d1%81-%d1%81%d1%83%d1%89%d0%b5%d1%81%d1%82%d0%b2%d1%83%d1%8e%d1%89%d0%b5%d0%b3%d0%be-%d0%ba%d0%bb%d1%8e%d1%87%d0%b0-%d0%bd%d0%b0-yubikey">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Этот раздел вам нужен, если у вас уже есть gpg-ключ и вы хотите его перенести на карту. &lt;em>Вы не сможете экспортировать приватный ключ с карты yubikey.&lt;/em>&lt;/p>
&lt;p>После того, как карта сконфигурирована, открываем режим редактирования ключа:&lt;/p>
&lt;pre>&lt;code>tungsten&amp;gt; gpg --expert --edit-key 21F7B93A71CDF86D649D8D0661BEBC7784A83F16
gpg (GnuPG/MacGPG2) 2.2.8; Copyright (C) 2018 Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Secret key is available.
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[ultimate] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Ключи переносятся командой &lt;code>keytocard&lt;/code>. На Yubikey есть только три слота под три типа (capability) ключа:&lt;/p>
&lt;ul>
&lt;li>Encryption key&lt;/li>
&lt;li>Authentication key&lt;/li>
&lt;li>Sign key&lt;/li>
&lt;/ul>
&lt;p>Если у вас больше ключей - то вы должны решить, какие ключи вы будете переносить. В примере выше - 2 sign ключа, по этому мастер мы переносить не будем - на yubikey уедут только три сабключа. Перед началом переноса ключей рекомендую сделать backup и положить его в безопасное место.&lt;/p>
&lt;p>Выберем ключ для переноса:&lt;/p>
&lt;pre>&lt;code>gpg&amp;gt; key 1
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb* rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[ultimate] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Перенесем его:&lt;/p>
&lt;pre>&lt;code>gpg&amp;gt; keytocard
Please select where to store the key:
(2) Encryption key
Your selection? 2
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb* rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[ultimate] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>После переноса снимем выделение с него:&lt;/p>
&lt;pre>&lt;code>gpg&amp;gt; key 1
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[ultimate] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>По аналогии перенесем 2 и 3 ключи:&lt;/p>
&lt;pre>&lt;code>gpg&amp;gt; key 2
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb* rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[ultimate] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
gpg&amp;gt; keytocard
Please select where to store the key:
(3) Authentication key
Your selection? 3
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb* rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[ultimate] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
gpg&amp;gt; key 2
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[ultimate] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
gpg&amp;gt; key 3
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb* rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[ultimate] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
gpg&amp;gt; keytocard
Please select where to store the key:
(1) Signature key
(3) Authentication key
Your selection? 1
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb* rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[ultimate] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>Все перенесено, сохраним и проверим:&lt;/p>
&lt;pre>&lt;code>gpg&amp;gt; save
tungsten&amp;gt; gpg --card-edit
Reader ...........: Yubico Yubikey 4 OTP U2F CCID
Application ID ...: D2760001240102010006070171690000
Version ..........: 2.1
Manufacturer .....: Yubico
Serial number ....: 07017169
Name of cardholder: [not set]
Language prefs ...: [not set]
Sex ..............: unspecified
URL of public key : [not set]
Login data .......: [not set]
Signature PIN ....: not forced
Key attributes ...: rsa2048 rsa2048 rsa2048
Max. PIN lengths .: 127 127 127
PIN retry counter : 3 0 3
Signature counter : 0
Signature key ....: 21F7 B93A 71CD F86D 649D 8D06 61BE BC77 84A8 3F16
created ....: 2018-08-08 14:51:38
Encryption key....: 7A30 6771 BB74 204F 54D5 8A61 1200 D2BB 8DFB 614C
created ....: 2018-08-08 14:51:38
Authentication key: DDB0 62D0 1BB4 4D01 3819 E450 0BC3 AD72 9F05 D736
created ....: 2018-08-08 14:54:07
General key info..: pub rsa2048/61BEBC7784A83F16 2018-08-08 Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
sec# rsa2048/61BEBC7784A83F16 created: 2018-08-08 expires: 2022-08-08
ssb&amp;gt; rsa2048/1200D2BB8DFB614C created: 2018-08-08 expires: 2022-08-08
card-no: 0006 07017169
ssb&amp;gt; rsa2048/0BC3AD729F05D736 created: 2018-08-08 expires: 2022-08-07
card-no: 0006 07017169
ssb&amp;gt; rsa2048/FAF7641B57B14FF2 created: 2018-08-08 expires: 2022-08-07
card-no: 0006 07017169
&lt;/code>&lt;/pre>
&lt;p>Обратите внимание, что мастер-ключ не лежит на карте – он пока еще хранится на компьютере (и внутри бэкапа). Имея доступ к мастер-ключу - можно редактировать срок жизни sub-ключа или отозвать (revoke) его. Очень важно хранить мастер в безопасности. Для этого мы вынесем его в холодное хранилище:&lt;/p>
&lt;ul>
&lt;li>у вас должна быть резервная копия мастер-ключа&lt;/li>
&lt;li>экспортируем публичный ключ&lt;/li>
&lt;li>удалим все &lt;em>секретные&lt;/em> ключи с компьютера&lt;/li>
&lt;li>импортируем обратно публичный ключ, сделав его доверенным&lt;/li>
&lt;/ul>
&lt;p>Экспортируем публичный ключ:&lt;/p>
&lt;pre>&lt;code>gpg --export --armour 61BEBC7784A83F16 &amp;gt; pub.asc
&lt;/code>&lt;/pre>
&lt;p>Уберем из компьютера yubikey и удалим приватный ключ:&lt;/p>
&lt;pre>&lt;code>gpg --edit-key 61BEBC7784A83F16
gpg&amp;gt; delkey
&lt;/code>&lt;/pre>
&lt;p>импортируем публичный ключ обратно:&lt;/p>
&lt;pre>&lt;code>gpg --import &amp;lt; pub.asc
&lt;/code>&lt;/pre>
&lt;p>повысим ему уровень доверия&lt;/p>
&lt;pre>&lt;code>gpg --edit-key 61BEBC7784A83F16
gpg&amp;gt; trust
sec rsa2048/61BEBC7784A83F16
created: 2018-08-08 expires: 2022-08-08 usage: SC
trust: ultimate validity: ultimate
ssb rsa2048/1200D2BB8DFB614C
created: 2018-08-08 expires: 2022-08-08 usage: E
ssb rsa2048/0BC3AD729F05D736
created: 2018-08-08 expires: 2022-08-07 usage: A
ssb rsa2048/FAF7641B57B14FF2
created: 2018-08-08 expires: 2022-08-07 usage: S
[none] (1). Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
Please decide how far you trust this user to correctly verify other users' keys
(by looking at passports, checking fingerprints from different sources, etc.)
1 = I don't know or won't say
2 = I do NOT trust
3 = I trust marginally
4 = I trust fully
5 = I trust ultimately
m = back to the main menu
Your decision? 5
Do you really want to set this key to ultimate trust? (y/N) y
&lt;/code>&lt;/pre>
&lt;p>Теперь проверим, что ключи на карте видны:&lt;/p>
&lt;pre>&lt;code>tungsten&amp;gt; gpg --card-edit
Reader ...........: Yubico Yubikey 4 OTP U2F CCID
Application ID ...: D2760001240102010006070171690000
Version ..........: 2.1
Manufacturer .....: Yubico
Serial number ....: 07017169
Name of cardholder: [not set]
Language prefs ...: [not set]
Sex ..............: unspecified
URL of public key : [not set]
Login data .......: [not set]
Signature PIN ....: not forced
Key attributes ...: rsa2048 rsa2048 rsa2048
Max. PIN lengths .: 127 127 127
PIN retry counter : 3 0 3
Signature counter : 0
Signature key ....: 21F7 B93A 71CD F86D 649D 8D06 61BE BC77 84A8 3F16
created ....: 2018-08-08 14:51:38
Encryption key....: 7A30 6771 BB74 204F 54D5 8A61 1200 D2BB 8DFB 614C
created ....: 2018-08-08 14:51:38
Authentication key: DDB0 62D0 1BB4 4D01 3819 E450 0BC3 AD72 9F05 D736
created ....: 2018-08-08 14:54:07
General key info..: pub rsa2048/61BEBC7784A83F16 2018-08-08 Paul Rudnitskiy &amp;lt;me@prudnitskiy.pro&amp;gt;
sec# rsa2048/61BEBC7784A83F16 created: 2018-08-08 expires: 2022-08-08
ssb&amp;gt; rsa2048/1200D2BB8DFB614C created: 2018-08-08 expires: 2022-08-08
card-no: 0006 07017169
ssb&amp;gt; rsa2048/0BC3AD729F05D736 created: 2018-08-08 expires: 2022-08-07
card-no: 0006 07017169
ssb&amp;gt; rsa2048/FAF7641B57B14FF2 created: 2018-08-08 expires: 2022-08-07
card-no: 0006 07017169
&lt;/code>&lt;/pre>
&lt;p>Отлично, ключи видны, можно пользоваться.&lt;/p>
&lt;h2 id="выводы" >Выводы
&lt;span>
&lt;a href="#%d0%b2%d1%8b%d0%b2%d0%be%d0%b4%d1%8b">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Использование gpg-ключа с карты практически ничем не отличается от использования ключа без карты. Для авторизации по ssh с использованием ключа вам потребуется RSA pubkey. Он создается от gpg subkey A (Auth capability). Если вы меняете auth-ключ – ssh-ключ поменяется тоже, имейте ввиду. Чтобы его получить - достаточно набрать команду &lt;code>ssh-add -L&lt;/code>&lt;/p>
&lt;pre>&lt;code>ssh-add -L
ssh-rsa AAAAB***************************** cardno:00007017169
&lt;/code>&lt;/pre>
&lt;p>Комментарий cardno подскажет, что ключ был импортирован из yubikey&lt;/p>
&lt;p>На каждую попытку использовать ключ yubikey будет требовать ввод User PIN. Yubikey весьма безопасен и надежен, если не делать глупых ошибок в его использовании и применении. И разумеется - нельзя забывать о бэкапах.&lt;/p></description></item><item><title>Systemd – очень быстрый старт</title><link>https://prudnitskiy.pro/post/2018-01-24-systemd-quickstart/</link><pubDate>Wed, 24 Jan 2018 21:00:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2018-01-24-systemd-quickstart/</guid><description>&lt;p>При работе в операционной системе нужно постоянно запускать разные программы. Следить за их состоянием. Перезапускать упавшее. Существует целый пласт утилит, который решает эту задачу (от простейшего init.d до навороченного svc). Сейчас в Linux стандартом де-факто стал systemd – его используют все современные дистрибутивы. Это – очень короткое и очень простое введение в systemd. Минимум текста – максимум пользы.&lt;/p>
&lt;p>SystemD – это менеджер загрузки. Он получает управление от ядра при старте операционной системы (init), запускает разные сервисы и следит за их состоянием (например – перезапускает упавшие). Идеолог – Леннар Поттеринг из RedHat. Systemd очень своеобразная штука, умеет она довольно много и устройство у нее довольно сложное. Systemd заслуженно любят за мощный и гибкий функционал – это здорово облегчает жизнь разработчика и админа. Systemd заслуженно ненавидят за тягу к изобретению уже реализованных в операционной системе вещей и спорное поведение в некоторых вопросах безопасности.&lt;/p>
&lt;p>Эта статья – краткое практическое руководство. Теории тут – минимум. Если вас интересует устройство systemd – вам в &lt;a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html">официальное руководство&lt;/a>.&lt;/p>
&lt;h2 id="введение-и-терминология" >Введение и терминология
&lt;span>
&lt;a href="#%d0%b2%d0%b2%d0%b5%d0%b4%d0%b5%d0%bd%d0%b8%d0%b5-%d0%b8-%d1%82%d0%b5%d1%80%d0%bc%d0%b8%d0%bd%d0%be%d0%bb%d0%be%d0%b3%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Systemd отвечает за запуск программ и сервисов после старта операционной системы. Он следит за процессом загрузки, решает что запустить и как. Строго говоря, он делает ровно то же самое, что делал SystemV init. Systemd писали значительно позже init – в нем пытались &lt;em>починить&lt;/em> вещи, которые в init сделаны плохо. Например, в init нет возможности сделать зависимость запуска одного сервиса от другого. Так же init не поддерживает параллельной загрузки. Параллельная загрузка сервисов радикально ускоряет старт операционной системы.&lt;/p>
&lt;h2 id="unit" >Unit
&lt;span>
&lt;a href="#unit">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Unit – это описание сервиса (в широком смысле этого слова). Unit-файл описывает все настройки сервиса, как его запускать, когда (очередность, зависимости) и что делать, если запуск не удался. Unit-ы, которые пишет пользователь руками – должны находится в &lt;code>/etc/systemd/system&lt;/code> и иметь окончание &lt;code>.service&lt;/code> в названии. Юниты, которые устанавливают пакеты – находятся в ином месте. Если в нескольких папках лежит юнит с одним и тем же именем – применяется тот, что лежит в &lt;code>/etc/systemd/system&lt;/code>. Пример юнита:&lt;/p>
&lt;pre>&lt;code>[Unit]
Description=etcd – highly-available key value store
Documentation=https://github.com/coreos/etcd
Documentation=man:etcd
After=network.target
Wants=network-online.target
[Service]
Environment=DAEMON_ARGS=
Environment=ETCD_NAME=%H
EnvironmentFile=-/etc/default/%p
WorkingDir=/var/lib/etcd
Type=notify
User=etcd
PermissionsStartOnly=true
ExecStart=/usr/bin/etcd $DAEMON_ARGS
Restart=on-abnormal
RestartSec=10s
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
&lt;/code>&lt;/pre>
&lt;p>Я специально взял юнит посложнее, чтобы пример был наглядным. На что обратить внимание:&lt;/p>
&lt;ul>
&lt;li>Description – человеко-читаемое описание. Показывается по команде &lt;code>service &amp;lt;name&amp;gt; status&lt;/code>&lt;/li>
&lt;li>After – начать загрузку после того, как начнется загрузка сервиса (или цели)&lt;/li>
&lt;li>Wants – опциональная зависимость. Подробнее ниже, в разделе про зависимости&lt;/li>
&lt;li>Environment – создать переменную окружения при запуске этого сервиса&lt;/li>
&lt;li>WorkingDir – демон запускается из этой папки. Аналогично &lt;code>cd /var/lib/etcd&lt;/code> перед запуском&lt;/li>
&lt;li>Type – тип сервиса. Подробнее ниже&lt;/li>
&lt;li>User – имя пользователя, от которого будет запущен сервис&lt;/li>
&lt;li>PermissionsStartOnly – используется, если перед стартом нужна какая-то специальная подготовка – создание папок, изменение прав и так далее. При &lt;code>PermissionsStartOnly=true&lt;/code> эти действия будут выполнятся от root. Без – от имени User&lt;/li>
&lt;li>ExecStart – что, собственно, запускать. Обязательно полный путь&lt;/li>
&lt;li>RestartOn – при каких условиях перезапускать&lt;/li>
&lt;li>WantedBy – в какой target должен быть установлен сервис. Подробнее – в разделе про target-ы&lt;/li>
&lt;/ul>
&lt;h3 id="виды-unit-ов" >Виды Unit-ов
&lt;span>
&lt;a href="#%d0%b2%d0%b8%d0%b4%d1%8b-unit-%d0%be%d0%b2">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Systemd может обслуживать процессы с разным поведением. Тип описывает, как systemd будет с ним взаимодействовать. Есть следующие варианты:&lt;/p>
&lt;ul>
&lt;li>&lt;code>Type=Simple&lt;/code> – самый стандартный тип. Процесс остается в foreground, stdout перехватывается systemd. Это тип по умолчанию.&lt;/li>
&lt;li>&lt;code>Type=Forking&lt;/code> – прямая противоположность. Процесс должен форкнуться и отсоединится от foreground. Для этого типа юнитов должен быть указан pid через директиву &lt;code>PIDFile&lt;/code>.&lt;/li>
&lt;li>&lt;code>Type=oneshot&lt;/code> – процесс, который успешно выполняется (не делая fork) и завершается. Пример – монтирование файловых систем. Рекомендуется добавить &lt;code>RemainAfterExit=yes&lt;/code> в юнит, чтобы результаты работы процесса остался в статусе юнита.&lt;/li>
&lt;li>&lt;code>Type=notify&lt;/code> – аналог simple, но в этом случае сам процесс сообщит systemd о том, что он закончил загрузку и готов к работе.&lt;/li>
&lt;/ul>
&lt;h3 id="взаимодействие-с-unit-ами" >Взаимодействие с unit-ами
&lt;span>
&lt;a href="#%d0%b2%d0%b7%d0%b0%d0%b8%d0%bc%d0%be%d0%b4%d0%b5%d0%b9%d1%81%d1%82%d0%b2%d0%b8%d0%b5-%d1%81-unit-%d0%b0%d0%bc%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>После каждого изменения файла юнита (создание/изменение/удаление) – нужно перечитывать изменения, так как состояния юнитов systemd кеширует:&lt;/p>
&lt;pre>&lt;code>systemctl daemon-reload
&lt;/code>&lt;/pre>
&lt;p>Запус, состояние, остановка:&lt;/p>
&lt;pre>&lt;code>#запуск
systemctl start [unit]
service [unit] start
#состояние
systemctl status [unit]
service [unit] status
#остановка
systemctl stop [unit]
service [unit] stop
#сервис в автозагрузку
systemctl enable [unit]
#полностью запретить запуск сервиса (даже команда service [unit] start не поможет)
systemctl mask [unit]
#разрешить запуск обратно
systemctl unmask [unit]
&lt;/code>&lt;/pre>
&lt;p>Systemd имеет свою собственную реализацию логирования (хотя по умолчанию в syslog копию сообщения он тоже отправляет). Чтение сообщений от сервисов – командой journalctl. Команда очень мощная, умеет много. Ниже примеры&lt;/p>
&lt;pre>&lt;code>#чтение информации по юниту
journalctl -u [UNIT]
#чтение по PID
journalctl _PID=12
#аналогично по конкретному файлу
journalctl /usr/bin/atd
#чтение информаций о юнитах, завершившихся с ошибкой
journalctl -xn
#чтение журнала с момента загрузки
journalctl -b
#чтение журнала с определенного момента
journalctl --since=&amp;quot;2018-01-24 10:15:10&amp;quot;
journalctl --since &amp;quot;10 minutes ago&amp;quot;
#постоянное отслеживание событий (аналог tail -f)
journalctl -f
#по умолчанию systemd обрезает строки по длине экрана. Запретим ему это:
journalctl -l
#фильтры можно комбинировать
journalctl -u redis -f -l --since &amp;quot;10 minutes ago&amp;quot;
&lt;/code>&lt;/pre>
&lt;h3 id="управление-зависимостями-очередность-загрузки-юнитов" >Управление зависимостями, очередность загрузки юнитов
&lt;span>
&lt;a href="#%d1%83%d0%bf%d1%80%d0%b0%d0%b2%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5-%d0%b7%d0%b0%d0%b2%d0%b8%d1%81%d0%b8%d0%bc%d0%be%d1%81%d1%82%d1%8f%d0%bc%d0%b8-%d0%be%d1%87%d0%b5%d1%80%d0%b5%d0%b4%d0%bd%d0%be%d1%81%d1%82%d1%8c-%d0%b7%d0%b0%d0%b3%d1%80%d1%83%d0%b7%d0%ba%d0%b8-%d1%8e%d0%bd%d0%b8%d1%82%d0%be%d0%b2">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Для управления зависимостями в unit есть ключевые слова &lt;code>Wants&lt;/code>, &lt;code>Requires&lt;/code> и &lt;code>After&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>After&lt;/code> – сервис начнет загрузку после того, как &lt;strong>начнет&lt;/strong> загружаться сервис, указанный в &lt;code>After&lt;/code>.&lt;/li>
&lt;li>&lt;code>Wants&lt;/code> – сервис начнет загрузку после того, как &lt;strong>закончит&lt;/strong> загружаться сервис, указанный в &lt;code>Wants&lt;/code>. Статус загрузки этого сервиса не важен – даже если он упал и загрузится не смог – юнит попытается стартовать. То есть зависимость эта опциональная, и нужна она только для того, чтобы наш сервис начал загружаться не раньше, чем другой – закончит.&lt;/li>
&lt;li>&lt;code>Requires&lt;/code> – сервис начнет загрузку после того, как сервис, указанный в &lt;code>Requires&lt;/code> закончит загрузку &lt;strong>успешно&lt;/strong>. Если сервис-зависимость загрузится не смог – наш сервис так же упадет с ошибкой (точнее – он даже не будет стартовать).&lt;/li>
&lt;/ul>
&lt;h2 id="targets" >Targets
&lt;span>
&lt;a href="#targets">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Target – целевое состояние системы. Именно Target определяет, какие сервисы будут загружены и в каком порядке. Аналог из мира sysV init – runlevel. Основные виды таргетов:&lt;/p>
&lt;ul>
&lt;li>&lt;code>poweroff&lt;/code> – отключение системы&lt;/li>
&lt;li>&lt;code>rescue&lt;/code> – режим восстановления, однопользовательский (init 1)&lt;/li>
&lt;li>&lt;code>multi-user&lt;/code> – сетевой режим без графической оболочки, (init 3)&lt;/li>
&lt;li>&lt;code>graphical&lt;/code> – сетевой режим с графической оболочкой (init 5)&lt;/li>
&lt;li>&lt;code>reboot&lt;/code> – перезагрузка&lt;/li>
&lt;li>&lt;code>emergency&lt;/code> – аварийная командная строка, минимальный функционал&lt;/li>
&lt;/ul>
&lt;p>Цели могут наследоваться друг от друга. Например, graphical включает в себя загрузку всего, что есть multiuser + после этого – подгрузку графической оболочки.&lt;/p>
&lt;p>Взаимодействие с целями:&lt;/p>
&lt;pre>&lt;code>#список целей
systemctl list-units --type=target
#перейти в нужную цель (например – загрузится из сетевого режима в графический)
systemctl isolate graphical.target
#выбрать target по умолчанию
systemctl set-default multi-user.target
&lt;/code>&lt;/pre>
&lt;h2 id="заключение" >Заключение
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>systemd на данный момент - стандарт в linux-based операционных системах. Инструмент мощный, удобный и популярный, пусть и не без особенностей. Надеюсь, эта статья поможет начать им пользоваться.&lt;/p></description></item><item><title>Потоковая репликация в PostgreSQL – короткое введение</title><link>https://prudnitskiy.pro/post/2018-01-05-pgsql-replica/</link><pubDate>Fri, 05 Jan 2018 21:00:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2018-01-05-pgsql-replica/</guid><description>&lt;p>PostgreSQL – великолепная база данных, во многом – лучше MySQL. При этом у PostgreSQL довольно мало документации (кроме официальной) – MySQL раньше стал популярен и сейчас элементарно чаще встречается. Руководств по настройке репликации в MySQL - полный интернет, а для PostgreSQL на русском я пошаговых инструкций просто не видел. Это – именно такая инструкция.&lt;/p>
&lt;h2 id="мотивация" >Мотивация
&lt;span>
&lt;a href="#%d0%bc%d0%be%d1%82%d0%b8%d0%b2%d0%b0%d1%86%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Репликация – это очень просто. Репликация означает копирование состояние одного сервера на другой. То есть – любые изменения, примененные на основной сервер (master) будут скопированы на его &amp;ldquo;заместителя&amp;rdquo; (slave). Для чего это нужно:&lt;/p>
&lt;ul>
&lt;li>Для распределения нагрузки. Slave не может записывать данные, но с него можно эти данные читать. По личному опыту, более 80% нагрузки на базу данных – это именно чтение в том или ином виде. Slave (или несколько) позволяют разгрузить мастер. Установка нескольких дешевых серверов чаще всего обходится дешевле, чем обновления одного, но дорогого (горизонтальное масштабирование дешевле вертикального. В некоторых случаях мешает закон Амдаля, но у нас не тот случай).&lt;/li>
&lt;li>Для построения отказоустойчивых систем. В случае, если с мастером &lt;strong>что-то случилось&lt;/strong> – превратить slave в master можно буквально за секунды, это снижает время простоя. Восстановление из резервной копии займет много больше времени. Кроме того, состояние slave-а будет максимально приближено к состоянию master-а на момент отказа. Бэкапы обычно делаются по расписанию. То есть – все данные, записанные после создания резервной копии и до отказа мастера можно считать потерянными безвозвратно.&lt;/li>
&lt;/ul>
&lt;p>Как и у всякой технологии, у репликации есть ограничения:&lt;/p>
&lt;ul>
&lt;li>Репликация в PostgreSQL – исключительно однонаправленная (master -&amp;gt; slave). PostgreSQL не поддерживает мультимастер (есть внешние решения, но они выходят за рамки этой статьи)&lt;/li>
&lt;li>Репликация дополняет бэкап, но не заменяет его. Реплика спасет данные, если с мастер-сервером что-то случилось: отказ электричества, сервер сгорел, жесткие диски умерли, пожар в ЦОД, правоохранительные органы изъяли оборудование и т.д. Репликация никак не поможет при логической ошибке (код запорол данные) или ошибке оператора (&amp;ldquo;призрак человека с консолью&amp;rdquo;).&lt;/li>
&lt;li>Особенность именно PostgreSQL - репликация возможна только всего сервера целиком, нельзя выбрать базы, которые будут реплицироваться (или не будут).&lt;/li>
&lt;li>По умолчанию репликация - асинхронная. Это значит, что мастер пишет данные постоянно, а slave вытаскивает изменения и применяет их у себя по мере возможности. Вообще, в норме это не вызывает проблем. Но, если вдруг у slave возникли с этим проблемы (мастер несравнимо мощнее и slave не успевает применять изменения, или проблемы с сетью между мастером и slave) – master &amp;ldquo;убежит&amp;rdquo; вперед. Данные при этом потеряны не будут, и slave догонит мастер, как только сможет. Такую ситуацию несложно отслеживать (дальше покажу, как), просто нужно иметь это ввиду. Репликацию можно сделать синхронной, чтобы гарантировать абсолютную консистентность данных между серверами, но это удорожает транзакции – производительность записи упадет, а нагрузка – вырастет.&lt;/li>
&lt;li>Репликация использует отдачу WAL-сегментов с мастера на slave-ы. Эти сегменты надо на мастере где-то хранить, то есть нужно запланировать дополнительное место для них.&lt;/li>
&lt;li>Репликация возможна только между серверами с общей мажорной версией (то есть реплицироваться 9.5 -&amp;gt; 9.5 можно, а с 9.4 -&amp;gt; 10.0 – нельзя). На всякий случай напомню, что до версии 10.0 обновления 9.4 -&amp;gt; 9.5 считались мажорными, а не минорными. У разных версий разный формат хранения данных.&lt;/li>
&lt;li>потоковая репликация возможна только в PostgreSQL 9 и выше. Она не работает в 7 и 8 версиях.&lt;/li>
&lt;/ul>
&lt;h2 id="мутные-технические-подробности" >Мутные технические подробности
&lt;span>
&lt;a href="#%d0%bc%d1%83%d1%82%d0%bd%d1%8b%d0%b5-%d1%82%d0%b5%d1%85%d0%bd%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%b8%d0%b5-%d0%bf%d0%be%d0%b4%d1%80%d0%be%d0%b1%d0%bd%d0%be%d1%81%d1%82%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Каждый postgresql-сервер пишет все изменения сначала в WAL (write-ahead log), и только затем – применяет изменения в реальное пространство базы данных. Это позволяет гарантировать целостность данных и отсутствие конфликтов изменений в табличном пространстве. В случае, если сервер по какой-то причине перезагрузился – он сначала проверяет текущий номер транзакции, примененный к табличному пространству (то есть - успешно завершенная запись). Затем сервер проверят WAL и дописывает разницу из WAL в tablespace. Номер транзакции всегда растет монотонно, что исключает конфликты очередности применения. Запись в WAL обходится дешевле, так как в WAL записываются только изменения, и они туда только последовательно пишутся (и эпизодически – последовательно читаются). Когда все транзакции из файла WAL считаются успешно примененными на сервер – WAL помечается как готовый (full) и удаляется. В случае репликации slave получает копию WAL с мастера (через специальный процесс wal streamer service - по одному на каждый slave). Для того, чтобы синхронизировать мастер со slave, нужно:&lt;/p>
&lt;ul>
&lt;li>скопировать текущее состояние мастера на slave.&lt;/li>
&lt;li>включить на мастере wal streaming (вещание wal-файлов)&lt;/li>
&lt;li>дождаться, пока slave не подключится к мастеру и не вытянет изменения и не применит их&lt;/li>
&lt;/ul>
&lt;h2 id="пошаговое-руководство" >Пошаговое руководство
&lt;span>
&lt;a href="#%d0%bf%d0%be%d1%88%d0%b0%d0%b3%d0%be%d0%b2%d0%be%d0%b5-%d1%80%d1%83%d0%ba%d0%be%d0%b2%d0%be%d0%b4%d1%81%d1%82%d0%b2%d0%be">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>В примере будут участвовать два сервера:&lt;/p>
&lt;ul>
&lt;li>master.db.local (10.0.0.1)&lt;/li>
&lt;li>slave.db.local (10.0.0.2)&lt;/li>
&lt;/ul>
&lt;p>Для упрощения считаем, что мастер уже настроен, запущен и работает. Slave – это пустой сервер без данных вообще, там только установлена ОС и сам postgres. Версии PostgreSQL на обоих серверах имеют одинаковый номер версии в майоре (к примеру 9.6.0 на master и 9.6.4 на slave). В данном примере я использую Debian и PostgreSQL 9.6. Для других ОС и версий PostgreSQL настройки отличатся не будут, но могут отличаться пути, по которым лежат конфиги и файлы данных.&lt;/p>
&lt;h3 id="настройка-master" >Настройка master
&lt;span>
&lt;a href="#%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b0-master">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Для начала поправим postgresql.conf. В Debian он находится по адресу &lt;code>/etc/postgresql/VERSION/CLUSTER/postgresql.conf&lt;/code>. В нашем примере это &lt;code>/etc/postgresql/9.6/master/postgresql.conf&lt;/code>&lt;/p>
&lt;pre>&lt;code>#master должен быть доступен по сети для slave
#listen_addresses может принимать несколько значений (через запятую)
#можно поставить * - postgres будет доступен на всех сетевых интерфейсах
listen_addresses = '10.0.0.1'
#режим хранения WAL-сегментов. Для репликации – только hot_standby
wal_level = hot_standby
#максимальное количство wal_sender.
#это максимум slave-ов, который сможет подключится к этому серверу
max_wal_senders = 5
#сколько заполненных WAL-сегментов хранить на мастере перед удалением
#число можно подобрать только экспериментально (больше изменений – больше WAL надо хранить)
wal_keep_segments = 32
#папка для архива. Удаленный WAL-сегмент будет скопирован туда
#архивом можно пользоваться для восстановления slave, если slave не успел выкачать WAL с мастера, а мастер его уже удалил
#там должно быть много места – сам postgres не будет чистить свой архив
archive_mode = on
archive_command = 'cp %p /var/lib/pg-archive/%f'
&lt;/code>&lt;/pre>
&lt;p>Теперь нужно разрешить slave-у подключаться к мастеру для репликации. Для этого отредактируем pg_hba.conf (лежит там же, где postgresql.conf), и добавим туда специального пользователя:&lt;/p>
&lt;pre>&lt;code>#TYPE DB USER ADDRESS #METHOD
host replication replication 10.0.0.2/32 md5
&lt;/code>&lt;/pre>
&lt;p>Теперь надо создать папку для архива:&lt;/p>
&lt;pre>&lt;code>mkdir /var/lib/pg-archive/
chown postgres /var/lib/pg-archive/
chmod 700 /var/lib/pg-archive/
&lt;/code>&lt;/pre>
&lt;p>И перезапустить master:&lt;/p>
&lt;pre>&lt;code>service postgresql restart
&lt;/code>&lt;/pre>
&lt;p>Создадим пользователя для репликации. Для этого в консоли самого постгреса выполним команду:&lt;/p>
&lt;pre>&lt;code>CREATE ROLE replication WITH REPLICATION PASSWORD 'Hw572BbvG7g4cwq5' LOGIN;
&lt;/code>&lt;/pre>
&lt;p>Пароль нам потребуется для авторизации slave-а на мастере. Рекомендуется делать его посложнее.
Для того, чтобы slave мог читать данные с мастера – на мастере должно быть разрешено соединение с портом postgresql (по умолчанию - 5432), проверьте firewall!&lt;/p>
&lt;h3 id="копируем-данные" >Копируем данные
&lt;span>
&lt;a href="#%d0%ba%d0%be%d0%bf%d0%b8%d1%80%d1%83%d0%b5%d0%bc-%d0%b4%d0%b0%d0%bd%d0%bd%d1%8b%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Для начала остановим postgres на slave и удалим данные из datadir на salve:&lt;/p>
&lt;pre>&lt;code>slave&amp;gt; service postgresql stop
slave&amp;gt; rm -rf /var/lib/postgresql/9.6/main/*
&lt;/code>&lt;/pre>
&lt;p>Теперь скопируем основной каталог данных с мастера (текущее состояние)&lt;/p>
&lt;pre>&lt;code>master&amp;gt; psql -c &amp;quot;SELECT pg_start_backup('sync', true)&amp;quot;
master&amp;gt; rsync -rahzP /var/lib/postgresql/9.6/main/ 10.0.0.2:/var/lib/postgresql/9.6/main/ --exclude=postmaster.pid
master&amp;gt; psql -c &amp;quot;SELECT pg_stop_backup()&amp;quot;
&lt;/code>&lt;/pre>
&lt;h3 id="настраиваем-salve" >Настраиваем salve
&lt;span>
&lt;a href="#%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%b0%d0%b8%d0%b2%d0%b0%d0%b5%d0%bc-salve">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Если вы хотите читать данные из slave - нужно включить режим hot_standby. Это полезно, если slave используется для распределения нагрузки на чтение. Если slave нужен исключительно как горячая замена мастеру на случай аварии – этот параметр можно не трогать. В конфиге &lt;code>/etc/postgresql/9.6/master/postgresql.conf&lt;/code> добавим:&lt;/p>
&lt;pre>&lt;code>hot_standby = on
&lt;/code>&lt;/pre>
&lt;p>В папке с данными (в нашем примере это &lt;code>/var/lib/postgresql/9.6/main/&lt;/code>) создадим файл с настройками репликации. Он должен называться &lt;code>recovery.conf&lt;/code>&lt;/p>
&lt;pre>&lt;code>standby_mode = 'on'
primary_conninfo = 'host=10.0.0.1 port=5432 user=replication password=Hw572BbvG7g4cwq5'
trigger_file = '/var/lib/postgresql/9.6/promote_to_master'
restore_command = 'cp /var/lib/pg-archive/%f &amp;quot;%p&amp;quot;'
&lt;/code>&lt;/pre>
&lt;p>Создадим на slave папку для архива WAL (так же, как это было сделано на master)&lt;/p>
&lt;pre>&lt;code>mkdir /var/lib/pg-archive/
chown postgres /var/lib/pg-archive/
chmod 700 /var/lib/pg-archive/
&lt;/code>&lt;/pre>
&lt;p>Теперь синхронизируем архив мастера с архивом slave, чтобы гарантировать успешный запуск:&lt;/p>
&lt;pre>&lt;code>master&amp;gt; rsync -rahzP /var/lib/pg-archive/ 10.0.0.2:/var/lib/pg-archive/
&lt;/code>&lt;/pre>
&lt;p>Поднимаем slave:&lt;/p>
&lt;pre>&lt;code>slave&amp;gt; service postgresql start
&lt;/code>&lt;/pre>
&lt;p>В журнале постгреса можно увидеть что сервис стартовал и готов обслуживать соединения:&lt;/p>
&lt;pre>&lt;code>2018-01-11 02:11:31 MSK [26781-1] LOG: database system is ready to accept read only connections
2018-01-11 02:11:31 MSK [26788-1] LOG: started streaming WAL from primary at 10B/33000000 on timeline 1
&lt;/code>&lt;/pre>
&lt;p>Чтобы WAL-сегменты не сожрали весь диск мастера подчистую – их надо периодически чистить. Несложный скрипт в crontab поможет:&lt;/p>
&lt;pre>&lt;code>10 6 * * * /usr/bin/find /var/lib/pg-archive/ -type f -mtime +7 -exec rm {} \;
&lt;/code>&lt;/pre>
&lt;p>В этом примере мы чистим архив от сегментов старше 7 дней, задача выполняется в 6:10 утра по времени сервера.&lt;/p>
&lt;h3 id="диагностика-и-ремонт" >Диагностика и ремонт
&lt;span>
&lt;a href="#%d0%b4%d0%b8%d0%b0%d0%b3%d0%bd%d0%be%d1%81%d1%82%d0%b8%d0%ba%d0%b0-%d0%b8-%d1%80%d0%b5%d0%bc%d0%be%d0%bd%d1%82">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Как проверить, что репликация работает? Проще всего - выяснить текущее положение WAL на мастере и slave:&lt;/p>
&lt;pre>&lt;code>master$ psql -c &amp;quot;SELECT pg_current_xlog_location()&amp;quot;
pg_current_xlog_location
--------------------------
0/2000000
(1 row)
slave$ psql -c &amp;quot;select pg_last_xlog_receive_location()&amp;quot;
pg_last_xlog_receive_location
-------------------------------
0/2000000
(1 row)
&lt;/code>&lt;/pre>
&lt;p>В норме положение мастера и slave должны быть близки или одинаковы (они будут одинаковы, если между выполнением команды на master и на slave на мастере не было изменений). Если на мастере число растет, а на slave – нет – репликация сломалась.
Самый простой способ восстановить репликацию:&lt;/p>
&lt;pre>&lt;code>#остановим slave:
slave&amp;gt; service postgresql stop
#скопируем архив WAL-сегментов с мастера на salve
master&amp;gt; rsync -rahzP /var/lib/pg-archive/ 10.0.0.2:/var/lib/pg-archive/
#запустим slave обратно:
slave&amp;gt; service postgresql start
&lt;/code>&lt;/pre>
&lt;p>Это сработает, если синхронизация была потеряна недавно (в конкретно нашем примере – не более 7 дней назад) и WAL-ы из архива еще не удалены. Если синхронизацию сломали давно – придется синхронизироваться с нуля, как описано в разделах &amp;ldquo;копируем данные&amp;rdquo; и &amp;ldquo;настраиваем slave&amp;rdquo;. То есть – чистить datadir на slave, копировать состояние, копировать архивы и т.д.&lt;/p>
&lt;h3 id="промотирование-перевод-slave-в-master" >Промотирование (перевод slave в master)
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%be%d0%bc%d0%be%d1%82%d0%b8%d1%80%d0%be%d0%b2%d0%b0%d0%bd%d0%b8%d0%b5-%d0%bf%d0%b5%d1%80%d0%b5%d0%b2%d0%be%d0%b4-slave-%d0%b2-master">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Это нужно в тех случаях, когда slave подменяет мастер на случай аварии. Для того, чтобы промотировать slave – нужно создать файл с именем, описанным в секции &lt;code>trigger_file&lt;/code> конфига &lt;code>recovery.conf&lt;/code>. В нашем примере это &lt;code>/var/lib/postgresql/9.6/promote_to_master&lt;/code>&lt;/p>
&lt;pre>&lt;code>touch /var/lib/postgresql/9.6/promote_to_master
&lt;/code>&lt;/pre>
&lt;p>Содержание файла может быть любым.&lt;/p>
&lt;p>После этого:&lt;/p>
&lt;ul>
&lt;li>slave перестанет реплицироваться с master&lt;/li>
&lt;li>slave станет доступен для операций записи&lt;/li>
&lt;li>slave начнет собственный отсчет WAL. Это значит, что даже если master вернется – смигрировать с него данные на slav e автоматически уже &lt;strong>не получится&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="выводы" >Выводы
&lt;span>
&lt;a href="#%d0%b2%d1%8b%d0%b2%d0%be%d0%b4%d1%8b">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Репликация – мощная, удобная и надежная техника. Репликация в postgresql позволяет легко распределить нагрузку и повысить надежность инсталляции. Эта конструкция работает очень надежно и почти никогда не ломается (привет MySQL!). Разумеется, нужно помнить, что:&lt;/p>
&lt;ul>
&lt;li>любая техника требует мониторинга. Проверяйте состояние реплик!&lt;/li>
&lt;li>репликация не заменяет backup, а только дополняет его.&lt;/li>
&lt;/ul></description></item><item><title>Duplicity – экстремально простой способ резервного копирования</title><link>https://prudnitskiy.pro/post/2017-09-30-duplicity/</link><pubDate>Sat, 30 Sep 2017 20:50:10 +0000</pubDate><guid>https://prudnitskiy.pro/post/2017-09-30-duplicity/</guid><description>&lt;p>Как гласит старинная шутка, системные администраторы делятся на две группы: те, которые не делают бэкапы, и те, которые уже делают бэкапы. Систем резеревного копирования существует великое множество, от простейшего самописного скрипта до огромных монстров ценой в &amp;ldquo;боинг&amp;rdquo;. Все системы нужны для разных целей и выполняют разные задачи.&lt;/p>
&lt;p>Основная, самая известная и популярная система в мире unix и linux – это, безусловно, bacula. Умеет bacula очень много - сложные расписания и политики хранения, шифрование данных и клиент-серверного трафика, управление операциями &amp;ldquo;на ходу&amp;rdquo;, десятки способов упаковки и проверки данных. Полный список возможностей bacula занимает несколько страниц мелкого текста. Основной минус бакулы находится ровно там, где находится ее плюс. Внедрение и настройка бакулы - это приключение, как минимум, на неделю. Документации очень много (но ее все равно не хватает). Бакула состоит из 4 самостоятельных компонентов (director, storage, filedaemon, console), каждый из которых настраивается и живет отдельно. Все эти компоненты имеют сложные взаимоотношения и должны быть доступны друг другу напрямую, что тоже жизнь не облегчает. Элементарный конфиг bacula легко может весить десятки килобайт (и bacula очень трепетно относится к опечаткам в конфиге - он в лучшем случае вообще не прочитается, а в худшем сервис упадет). В случае, если нужно делать резервные копии с одного-двух серверов - bacula - явный оверкилл. Вместо сложного комбайна нужен простой и понятный молоток. И такой молоток есть - он называется duplicity.&lt;/p>
&lt;p>Duplicity - это очень просто. Это одна-единственная команда, которая запускается на том сервере, откуда будут копироваться данные. Все, что она может:&lt;/p>
&lt;ul>
&lt;li>сделать резервную копию. Резервная копия пакуется в блоки (назывются тома), и, по желанию, шифруются. Резервная копия может быть или полной, или инкрементальной. Уровень определяется возрастом копии - если последняя полная копия старше определенного возраста - будет сделана полная, если нет - инкрементальная копия.&lt;/li>
&lt;li>отправить резервную копию на удаленный сервер. Удаленный сервер может быть rsync, ftp, scp, s3 (вариантов много). Можно хранить прямо в файловой системе. Устройства хранения (ленточные библиотеки, дисковые массивы) – не поддерживатюся.&lt;/li>
&lt;li>найти расходждения между каталогом и определенной версией бекапа. Полезно, чтобы понять, что изменилось с момента бэкапа.&lt;/li>
&lt;li>показать список файлов в бэкапе.&lt;/li>
&lt;li>восстановить файлы из бэкапа (или весь бэкап целиком).&lt;/li>
&lt;li>почистить удаленный сервер от старых бэкапов.&lt;/li>
&lt;/ul>
&lt;p>На этом функционал duplicity заканчивается. Ничего сложного, головоломного, неочевидного. Система, понятная, как кирпич.&lt;/p>
&lt;h2 id="установка-и-настройка" >Установка и настройка
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d0%b8-%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Duplicty входит в пакет с одноименным названием, и устанавливается традиционно для вашей операционной системы:&lt;/p>
&lt;pre>&lt;code>#debian, ubuntu
apt-get install duplicity
#centos, redhat, fedora
yum install duplicity
&lt;/code>&lt;/pre>
&lt;p>Теперь нужно решить, куда будут отправляться пакеты. Duplicty не может работать с удаленным сервером самостоятельно - в зависимости от типа удаленного сервера ему потребуется тот или иной пакет. Сам duplicity только &amp;ldquo;дирижирует процессом&amp;rdquo;. Самые ходовые типы серверов и пакеты:&lt;/p>
&lt;ul>
&lt;li>ftp, ftps (ftp over TLS): ncftp&lt;/li>
&lt;li>rsync: rsync&lt;/li>
&lt;li>s3 (aws S3, openstack swift, ceph object gateway, minio): boto&lt;/li>
&lt;/ul>
&lt;p>Если планируется шифровать и/или подписывать бэкап - нужно сгенерировать gpg-ключ. Шифровать бэкап рекомендуется, если нет доверия серверу хранения. Правило хорошего тона гласят, что доверия нет никогда и никому. Помните о том, что бэкап, по сути – отложеное по времени нарушение безопасности. Ключ генерируется вполне традиционым способом:&lt;/p>
&lt;pre>&lt;code>gpg --gen-key
&lt;/code>&lt;/pre>
&lt;p>Параметры ключа (размер, алгоритм) менять не обязательно, они вполне разумны. После окончания генерации GPG вернет идентификатор ключа. Его так же можно посмотреть вот так:&lt;/p>
&lt;pre>&lt;code>gpg --list-keys
/root/.gnupg/pubring.gpg
------------------------
pub 2048R/F6822D5F 2017-01-28
uid Paul I Rudnitskiy (bck server) &amp;lt;admin@prudnitskiy.pro&amp;gt;
sub 2048R/292EB891 2017-01-28
&lt;/code>&lt;/pre>
&lt;p>ID нам чуть дальше пригодится, рекомендую его запомнить.&lt;/p>
&lt;p>Так же очень рекомендуется сделать разеревную копию GPG-ключа. Если бэкап зашифрован - потеря ключа автоматически означает потерю возможности восстановить данные из бэкапа. Выгрузим ключ, чтобы сохранить его в надежное место:&lt;/p>
&lt;pre>&lt;code>gpg --export-secret-keys -a F6822D5F &amp;gt; backup.asc
&lt;/code>&lt;/pre>
&lt;h2 id="резервное-копирование" >Резервное копирование
&lt;span>
&lt;a href="#%d1%80%d0%b5%d0%b7%d0%b5%d1%80%d0%b2%d0%bd%d0%be%d0%b5-%d0%ba%d0%be%d0%bf%d0%b8%d1%80%d0%be%d0%b2%d0%b0%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Общий принцип - &lt;code>duplicity [args] {source} {destination}&lt;/code>. Аргументов множество, ниже я приведу пример и распишу, что означает каждый. Проще всего сделать shell-скрипт с командой и типовыми аргументами, чтобы не вспоминать их каждый раз&lt;/p>
&lt;pre>&lt;code>duplicity --verbosity notice \
--encrypt-key &amp;quot;F6822D5F&amp;quot; \
--full-if-older-than 14D \
--num-retries 3 \
--asynchronous-upload \
--volsize 100 \
--archive-dir /var/tmp/.duplicity \
--log-file /var/log/duplicity.log \
--exclude &amp;quot;/var/lib/postgresql/9.5/main/archive&amp;quot; \
&amp;quot;/var/lib/postgresql/9.5/main/&amp;quot; \
&amp;quot;ftp://bckuser:iem4ob9bah1FohNi@verysecret.prudnitskiy.pro/pgsql&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>На что обратить внимание:&lt;/p>
&lt;ul>
&lt;li>&lt;em>verbosity&lt;/em> - уровень &amp;ldquo;говорливости&amp;rdquo; при работе. Рекомендуется info при отладке (показывает файлы и текущие операции) и notice в production (кратко сообщает о текущем этапе работы)&lt;/li>
&lt;li>&lt;em>encrypt-key&lt;/em> - ID ключа для шифрования. Важен, если ключей несколько. Если шифровать не нужно - используйте аргумент &lt;code>--no-encryption&lt;/code>. При шифровании gpg спросит пароль ключа шифрования. Побеждается или настройкой gpg-agent или созданием переменной &lt;code>PASSPHRASE&lt;/code> с паролем.&lt;/li>
&lt;li>&lt;em>full-if-older-than&lt;/em> - через срок после создания полной копии нужно сделать не инкрементальную, а снова полную копию. В данном примере - 14 дней.&lt;/li>
&lt;li>&lt;em>volsize&lt;/em> - размер одного тома в мегабайтах. Каждый том пакуется и загружается на сервер отдельно, это отдельный файл.&lt;/li>
&lt;li>&lt;em>archive-dir&lt;/em> - папка, где duplicity локально хранит метаданные (информацию о томах и их содержимом). Копия метаданных лежит на сервере. Если по какой-то причине метаданные пропадут - duplicity придется скачать копию метаданных с сервера перед началом бэкапа. Размер папки метаданных пропорционально зависит от количества файлов и количества бэкапов, так что стоит выделить ей побольше места.&lt;/li>
&lt;li>&lt;em>exclude&lt;/em> - позволяет исключить папку из бэкапа. аргументов exclude может быть несколько.&lt;/li>
&lt;li>&lt;em>destination&lt;/em> - последний аргумент, куда копируем данные. Задается в виде классического url. URL для копии в локальную файловую систему имеет вид &lt;code>file:///path/to/folder&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>Проверка состояния бэкапов на удаленном сервере:&lt;/p>
&lt;pre>&lt;code>duplicity collection-status &amp;quot;ftp://bckuser:iem4ob9bah1FohNi@verysecret.prudnitskiy.pro/pgsql&amp;quot; \
--archive-dir /var/tmp/.duplicity
&lt;/code>&lt;/pre>
&lt;p>Пример ответа:&lt;/p>
&lt;pre>&lt;code>NcFTP version is 3.2.5
Local and Remote metadata are synchronized, no sync needed.
Last full backup date: Fri Sep 15 04:10:03 2017
Collection Status
-----------------
Connecting with backend: FTPBackend
Archive dir: /var/tmp/.duplicity/c9edc22d8a99b972fdf4bd3cec26e19f
Found 1 secondary backup chain.
Secondary chain 1 of 1:
-------------------------
Chain start time: Thu Aug 31 04:10:03 2017
Chain end time: Thu Sep 14 04:10:02 2017
Number of contained backup sets: 15
Total number of contained volumes: 252
Type of backup set: Time: Num volumes:
Full Thu Aug 31 04:10:03 2017 137
Incremental Fri Sep 1 04:10:02 2017 6
----------------------------CUT----------------------------------------
-------------------------
Found primary backup chain with matching signature chain:
-------------------------
Chain start time: Fri Sep 15 04:10:03 2017
Chain end time: Fri Sep 29 04:10:03 2017
Number of contained backup sets: 15
Total number of contained volumes: 245
Type of backup set: Time: Num volumes:
Full Fri Sep 15 04:10:03 2017 142
Incremental Sat Sep 16 04:10:02 2017 8
----------------------------CUT----------------------------------------
Incremental Fri Sep 29 04:10:03 2017 7
-------------------------
No orphaned or incomplete backup sets found.
&lt;/code>&lt;/pre>
&lt;p>Duplicity не позволяет помечать бэкап как устаревший автоматически (retention в терминологии &amp;ldquo;взрослых&amp;rdquo; систем). Чистить ненужные бэкапы придется в ручном режиме:&lt;/p>
&lt;pre>&lt;code>duplicity --verbosity notice \
--archive-dir /var/tmp/.duplicity \
--force \
remove-all-but-n-full 4 \
&amp;quot;ftp://bckuser:iem4ob9bah1FohNi@verysecret.prudnitskiy.pro/pgsql&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Эта команда удалит все бэкапы старше 4 последних полных бэкапов. В примере выше мы делали полный бекап каждые 2 недели, то есть duplicity удалит бэкапы старше 2 месяцев (8 недель). Если убрать ключ &lt;code>--force&lt;/code> – duplicity найдет старые бэкапы, но не будет их удалять - только выведет на консоль. Забывать о чистке не рекомендуется - место на сервере для резервных копий может неожиданно кончиться и оставить вас без свежих бэкапов. Выясняется это весьма болезненно.&lt;/p>
&lt;h2 id="проверка-и-восстановление" >Проверка и восстановление
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%be%d0%b2%d0%b5%d1%80%d0%ba%d0%b0-%d0%b8-%d0%b2%d0%be%d1%81%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Посмотрим файлы, которые у нас есть в бэкапе:&lt;/p>
&lt;pre>&lt;code>duplicity --archive-dir /var/tmp/.duplicity list-current-files \
&amp;quot;ftp://bckuser:iem4ob9bah1FohNi@verysecret.prudnitskiy.pro/pgsql&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Пример ответа:&lt;/p>
&lt;pre>&lt;code>NcFTP version is 3.2.5
Local and Remote metadata are synchronized, no sync needed.
Last full backup date: Sat Sep 29 04:10:03 2017
Mon Oct 2 04:10:02 2017 .
Mon Aug 29 21:07:04 2016 PG_VERSION
Mon Oct 2 04:10:02 2017 backup_label
-----------------------CUT---------------------------------
&lt;/code>&lt;/pre>
&lt;p>Команда выше покажет состояние на момент &lt;em>последнего&lt;/em> бэкапа. Чтобы получить информацию из более старых бэкапов, нужно использовать ключ &lt;code>-t&lt;/code>. К примеру, &lt;code>-t6D&lt;/code> вернет информацию о бэкапе, сделаном 6 дней назад.&lt;/p>
&lt;p>Восстановление данных выглядит ровно так же, как бэкап, нужно просто поменять местами source (откуда брать данные) и destination:&lt;/p>
&lt;pre>&lt;code>duplicity --verbosity notice \
--encrypt-key &amp;quot;F6822D5F&amp;quot; \
--archive-dir /var/tmp/.duplicity \
--log-file /var/log/duplicity.log \
&amp;quot;ftp://bckuser:iem4ob9bah1FohNi@verysecret.prudnitskiy.pro/pgsql&amp;quot; \
&amp;quot;/var/lib/postgresql/9.5/main/&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>На что обратить внимание:&lt;/p>
&lt;ul>
&lt;li>Если нужно восстановить бэкап на определенную дату - выручает ключ &lt;code>-t&lt;/code>&lt;/li>
&lt;li>Для восстановления определенного файла нужно использовать ключ &lt;code>--file-to-restore&lt;/code>. Таких ключей может быть несколько.&lt;/li>
&lt;li>Восстановление возможно только в совершенно пустую папку&lt;/li>
&lt;li>Для восстановления duplicity вытащит с сервера резервных копий &lt;em>весь&lt;/em> полный бэкап и все инкрементальные бэкапы с момента полного до точки восстановления. Места уйдет много.&lt;/li>
&lt;/ul></description></item><item><title>Как (и зачем) перевести блог на статический сайт</title><link>https://prudnitskiy.pro/post/2017-09-15-jekyll/</link><pubDate>Fri, 15 Sep 2017 21:40:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2017-09-15-jekyll/</guid><description>&lt;p>Согласно &lt;a href="https://w3techs.com/technologies/overview/programming_language/all">статстике W3Tech&lt;/a> 98.5% современных сайтов – это динамические сайты. Строго говоря – это программы (порой – большие и сложные программы), мощные многоэтажные системы, связаные со сложными системами хранения данных. Каждое посещение такого сайта – это выполнение кода, что требует ресурсов сервера и времени. При этом реально в большинстве случаев вся эта мощь не используется – большинство сайтов довольно компактные и редко обновляются. А значит – мощная, сложная, гибкая, многокомпонентная, что самое страшное – потенциально ненадежная система, в общем-то, не нужна.&lt;/p>
&lt;p>Перевод сайта с динамики на статику – это простой и удобный способ обойтись без сложностей, не потеряв гибкости и удобства.&lt;/p>
&lt;h2 id="необязательная-предыстория" >Необязательная предыстория
&lt;span>
&lt;a href="#%d0%bd%d0%b5%d0%be%d0%b1%d1%8f%d0%b7%d0%b0%d1%82%d0%b5%d0%bb%d1%8c%d0%bd%d0%b0%d1%8f-%d0%bf%d1%80%d0%b5%d0%b4%d1%8b%d1%81%d1%82%d0%be%d1%80%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Когда интернет только появился – все сайты были сверстаны статически. Каждый сайт был простым набором физических файлов. Эти файлы лежали на физическом диске. При обращении к URL веб-сервер транслировал относительный путь в путь в файловой системе, физически читал файл с диска и отдавал его клиенту. Такой подход очень просто программируется, написать простейший web-server на любом современном языке можно за пару часов. При статической верстке очень легко управлять кешированием - достаточно читать атрибуты файла и отправлять их в заголовок. Проблемы начались с ростом объема сайта. Если вы создаете страницы по очереди - вы можете писать их руками, по одной. Проблемы начинаются, когда нужно поменять что-то во всех страницах разом. Десять страниц можно поменять руками. 20 - сложно. 100 - очень сложно. На пятой тысяче вы сильно пожалеете, что вообще вписались в эту задачу. Так же все эти файлы физически лежат на диске и занимают прорву места. Причем большая часть этих файлов - совершенно одинаковая (верстка и художественное оформление у страниц общее, отличаются они только содержанием).&lt;/p>
&lt;p>Для того, чтобы решить эту проблему - была придумана динамическая верстка и базы данных.&lt;/p>
&lt;p>Работало (и работает до сих пор) концептуально это очень просто:&lt;/p>
&lt;ul>
&lt;li>Запрос из сети вызывает выполнение кода на сервере (это и есть наш сайт, точнее - его часть).&lt;/li>
&lt;li>При выполнении код выясняет, какие данные требуются пользователю.&lt;/li>
&lt;li>Часть данных может быть прямо в коде (название сайта, имя автора, год публикации), а часть – лежит во внешнем хранилище, например - в базе данных.&lt;/li>
&lt;li>Код лезет в базу данных и вытаскивает оттуда нужные данные.&lt;/li>
&lt;li>Код загружает шаблон, на основе которого он будет рисовать страницу. Шаблон - это та же страница с версткой, дизайном и всеми атрибутами.В ней нет только реальных данных, вместо них там стоят метки вида &lt;code>{заголовок будет тут}&lt;/code>.&lt;/li>
&lt;li>Код вставляет в шаблон все необходимые данные и рисует страницу. Обычно готовая страница лежит в оперативной памяти сервера и ждет отдачи.&lt;/li>
&lt;li>Сервер получает от кода сообщение о готовности и отрисованую страницу.&lt;/li>
&lt;li>Сервер отдает страницу пользователю.&lt;/li>
&lt;/ul>
&lt;p>Современный сервер выполняет весь этот набор действий довольно быстро, но за конечное время. Обычно полный цикл занимает 100-200 миллисекунд + еще 50-100 миллисекунд требуется на доступ к базе. Проблемы начинаются на больших нагрузках. Либо резко кончаются ресурсы (каждый запрос обрабатывается независимым куском кода и в базу тоже ходит независимо). Либо сервер ставит запросы на обработку в очередь и сайт начинает тормозить (или вообще отваливается, если пользователь просто не успел дождаться своей очереди).&lt;/p>
&lt;p>Динамические сайты – это фантастически удобно. Когда данные лежат во внешнем хранилище – можно организовать туда доступ из нескольких мест. Например, сделать зоомагазины для кошек и для собак, но товары держать в общей базе. Это позволит показывать на каждом сайте уникальные для именно этого сайта товары + общие товары для обеих групп покупателей. Базы позволяют делать &amp;ldquo;срезы&amp;rdquo; данных по любому направлению. Это позволяет показать пользователю любой набор информации из базы, ограничив его любыми критериями. Данные всегда забираются из базы, а значит, обновив данные в базе мы моментально обновим их на сайте, никаких задержек. Динамические сайты используют для отображения шаблоны, а значит – не нужно муторно перерисовывать каждую страницу, если в ней нашлась какая-то проблема. Одна правка в одном месте сразу поправит все.&lt;/p>
&lt;p>По этой причине динамические сайты стали основой современного интернета. Статические сайты никто не делает, потому, что это неудобно и трудозатраты кажутся неадекватными. Однако, если собрать статистику по сайтам в интернете, выясняется, что:&lt;/p>
&lt;ul>
&lt;li>Подавляющее большинство сайтов имеет очень маленький размер – единицы, в редком случае десятки, в очень редком - сотни страниц. К примеру, возьмем блог. Это будет хороший блог очень обязательного человека, который пишет пост раз в неделю. В году всего 52 недели, то есть за каждый год существования блог вырастет на 52 страницы. За 10 лет - 520 страниц. Много ли вы видели десятилетних блогов?&lt;/li>
&lt;li>Подавляющее большинство сайтов очень редко обновляется, и им просто не нужна высокая легкость и скорость обновления.&lt;/li>
&lt;li>Подавляющее большинство сайтов очень редко посещается. Тут нужно сделать небольшое отступление и рассказать про кеш.&lt;/li>
&lt;/ul>
&lt;p>Идея кеширования в том, что если пользователи часто запрашивают некие данные - их проще не готовить по всей цепочке, а сохранить в уже подготовленном виде и отдавать сразу. Вместо 300 мсек на запрос получаем 10 мсек + освобождаем ресурсы сервера (так, как данные не надо готовить и отрисовывать, можно отдать уже готовую отрисованную страницу). Основная проблема кеша – его срок жизни. В момент, когда он создается, указывается, сколько времени должен жить объект. Когда объект закончит свое существование и будет удален - первый пользователь, который пойдет в обход кеша - вызовет запуск кода (и создание нового объекта). Отсюда вытекает две проблемы:&lt;/p>
&lt;ul>
&lt;li>Если сайт обновился - пользователи об этом не узнают, пока не умрет кешированный объект. Единственный способ избежать этого - при обновлении сайта найти и удалить объекты, которые ссылаются на необновленные данные.&lt;/li>
&lt;li>Если пользователи приходят редко - кеширование не имеет никакого смысла, потому, что объект кеша умрет раньше, чем его кто-то увидит.&lt;/li>
&lt;/ul>
&lt;p>При этом кеш сам по себе съедает ресурсы – для хранения кешированных объектов выделяется память, плюс кто-то должен выяснять, что отдавать пользователю – кешированный объект или идти к серверу за новым (и кешировать его).&lt;/p>
&lt;p>Еще одна серьезная проблема динамических сайтов – это безопасность. Динамический сайт – это код. В коде бывают ошибки. Более того – в коде &lt;em>вероятны&lt;/em> ошибки. Потенциально ошибка грозит утечкой данных сайта (в лучшем случае) или вовсе – захватом сервера, где сайт живет. Если у вас есть динамический сайт – вам нужен кто-то, кто будет следить за его состоянием. Обновлять код. Отслеживать попытки взлома и реагировать на них.&lt;/p>
&lt;p>Собственно, для решения этих проблем были придуманы генераторы статических сайтов. Это была попытка взять &amp;ldquo;лучшее из двух миров&amp;rdquo; – просту и легкость работы статического сайта и удобство работы с динамическими данными.&lt;/p>
&lt;h2 id="что-такое-jekyll" >Что такое Jekyll
&lt;span>
&lt;a href="#%d1%87%d1%82%d0%be-%d1%82%d0%b0%d0%ba%d0%be%d0%b5-jekyll">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Jekyll – один из многих генераторов статических сайтов. Генераторы пытаются совмещать несовемстимое – удобство обслуживания сайта динамического и легкость сайта, сверстанного статически. Работает это следующим образом:&lt;/p>
&lt;ul>
&lt;li>Данные для сайта сохраняются в виде текстовых файлов в специальном формате (он простой).&lt;/li>
&lt;li>Внешний вид и верстка сайта оформляется шаблонами (используется движок &lt;a href="https://shopify.github.io/liquid/">liquid&lt;/a> от shopify).&lt;/li>
&lt;li>Команда &lt;code>jekyll build&lt;/code> проверяет все данные и отрисовывает сайт по шаблону в виде набора статичных файлов. Готовые файлы сохраняются на диск.&lt;/li>
&lt;li>Готовые статичные файлы можно положить на сервер и сделать доступными в сети.&lt;/li>
&lt;/ul>
&lt;h3 id="когда-вам-нужен-jekyll-pros" >Когда вам нужен jekyll (pros)
&lt;span>
&lt;a href="#%d0%ba%d0%be%d0%b3%d0%b4%d0%b0-%d0%b2%d0%b0%d0%bc-%d0%bd%d1%83%d0%b6%d0%b5%d0%bd-jekyll-pros">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;ul>
&lt;li>Если у вас небольшой сайт (PR-страница, личный или корпоративный блог).&lt;/li>
&lt;li>Если ваш сайт обновляется сравнительно редко и делает это один человек (или несколько, но вы можете договорится о процедуре обновления).&lt;/li>
&lt;li>Если вам нужно очень сильно сэкономить (хостинг статических файлов можно найти бесплатно).&lt;/li>
&lt;li>Если сайт некрупный, но планируется &lt;strong>очень&lt;/strong> большая нагрузка (статический сайт будет обрабатываться быстрее динамического).&lt;/li>
&lt;li>Если вам очень важна безопасность, но нет средств на программиста, который будет поддерживать код вашего сайта (jekyll создает статические страницы, а на сервере никакой код не выполняется в принципе – ломать там нечего).&lt;/li>
&lt;/ul>
&lt;h3 id="когда-вам-не-нужен-jekyll-contras" >Когда вам не нужен jekyll (contras)
&lt;span>
&lt;a href="#%d0%ba%d0%be%d0%b3%d0%b4%d0%b0-%d0%b2%d0%b0%d0%bc-%d0%bd%d0%b5-%d0%bd%d1%83%d0%b6%d0%b5%d0%bd-jekyll-contras">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;ul>
&lt;li>Если у вас по-настоящему большой сайт и счет страниц идет на десятки тысяч. В принципе jekyll может работать с большими объемами данных, но это будет неудобно.&lt;/li>
&lt;li>Если ваш сайт обновляется очень часто (новостное агентство, форум).&lt;/li>
&lt;li>Если работа вашего сайта зависит от поведения пользователя на сайте (социальная сеть, персонализированные новости, интернет-магазин).&lt;/li>
&lt;li>Если ваш сайт обновляется многими и из многих точек (twitter, сервис блогов).&lt;/li>
&lt;li>Если нагрузка на ваш сайт по-настоящему велика и вы знаете, как заставить ваш код работать быстрее примитивной выгрузки данных с диска (да, это возможно). Но тогда я не понимаю, зачем вы вообще читаете эту простыню.&lt;/li>
&lt;/ul>
&lt;h2 id="установка" >Установка
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Для работы jekyll вам потребуется ruby, способов его установки настолько много, что я не буду на этом сейчас останавливаться. После установки ruby ставим гем jekyll:&lt;/p>
&lt;pre>&lt;code>&amp;gt; gem install jekyll
&lt;/code>&lt;/pre>
&lt;p>Теперь переходим в папку, где будет лежать сайт. На всякий случай напомню, что это не тот сайт, который будет доступен в сети, а тот, который служит источником данных. Создадим &amp;ldquo;пустой&amp;rdquo; сайт:&lt;/p>
&lt;pre>&lt;code>&amp;gt; jekyll new ./testsite
Running bundle install in ~/testsite...
Bundler: Fetching gem metadata from https://rubygems.org/...........
Bundler: Fetching version metadata from https://rubygems.org/..
Bundler: Fetching dependency metadata from https://rubygems.org/.
Bundler: Resolving dependencies...
Bundler: Fetching public_suffix 3.0.0
Bundler: Installing public_suffix 3.0.0
Bundler: Using bundler 1.15.2
Bundler: Using colorator 1.1.0
Bundler: Using ffi 1.9.18
Bundler: Using forwardable-extended 2.6.0
Bundler: Using rb-fsevent 0.10.2
Bundler: Fetching kramdown 1.15.0
Bundler: Installing kramdown 1.15.0
Bundler: Using liquid 4.0.0
Bundler: Using mercenary 0.3.6
Bundler: Using rouge 1.11.1
Bundler: Using safe_yaml 1.0.4
Bundler: Fetching addressable 2.5.2
Bundler: Installing addressable 2.5.2
Bundler: Using rb-inotify 0.9.10
Bundler: Using pathutil 0.14.0
Bundler: Fetching sass-listen 4.0.0
Bundler: Installing sass-listen 4.0.0
Bundler: Using listen 3.0.8
Bundler: Fetching sass 3.5.1
Bundler: Installing sass 3.5.1
Bundler: Using jekyll-watch 1.5.0
Bundler: Using jekyll-sass-converter 1.5.0
Bundler: Using jekyll 3.5.0
Bundler: Using jekyll-feed 0.9.2
Bundler: Using minima 2.1.1
Bundler: Bundle complete! 4 Gemfile dependencies, 22 gems now installed.
Bundler: Use `bundle info [gemname]` to see where a bundled gem is installed.
Bundler: The latest bundler is 1.16.0.pre.2, but you are currently running 1.15.2.
Bundler: To update, run `gem install bundler --pre`
New jekyll site installed in ~/testsite.
&lt;/code>&lt;/pre>
&lt;p>Самый простой способ убедится, что сайт создался и работает - собрать его. Команда &lt;code>jekyll serve&lt;/code> обработает имеющиеся данные и соберет статический сайт, а затем запустит маленький веб-сервер, чтобы можно было посмотреть на сайт. Эту команду надо выполнить внутри папки сайта:&lt;/p>
&lt;pre>&lt;code>&amp;gt; cd ./testsite
&amp;gt; jekyll serve
Configuration file: /home/testsite/_config.yml
Deprecation: The 'gems' configuration option has been renamed to 'plugins'. Please update your config file accordingly.
Source: /home/testsite
Destination: /home/testsite/_site
Incremental build: disabled. Enable with --incremental
Generating...
done in 0.812 seconds.
Auto-regeneration: enabled for '/home/testsite'
Server address: http://127.0.0.1:4000/
Server running... press ctrl-c to stop.
&lt;/code>&lt;/pre>
&lt;p>Теперь можно зайти браузером на &lt;code>http://127.0.0.1:4000&lt;/code> и полюбоваться на сайт:&lt;/p>
&lt;p>![jekyll new]({{ site.baseurl }}{% link /assets/img/jekyll-new.png %})&lt;/p>
&lt;h2 id="быстрый-старт" >Быстрый старт
&lt;span>
&lt;a href="#%d0%b1%d1%8b%d1%81%d1%82%d1%80%d1%8b%d0%b9-%d1%81%d1%82%d0%b0%d1%80%d1%82">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Jekyll изначально - движок для блогов. Это не значит, что на нем можно писать только блоги, просто с блогами там работать легче всего. Все блог-посты, которые будут видны на сайте, jekyll ищет в каталоге &lt;code>_posts&lt;/code>. Название у файла должно соответствовать шаблону &lt;code>YYYY-MM-DD-slug.md&lt;/code>, где:&lt;/p>
&lt;ul>
&lt;li>YYYY год в четырехсимвольном формате (2010)&lt;/li>
&lt;li>MM месяц в двухсимвольном формате (03 – март).&lt;/li>
&lt;li>DD в двухсимвольном формате (08 - 8 Марта).&lt;/li>
&lt;li>slug - произвольное название статьи на английском языке. Регистр букв (большая-маленькая) – учитываться не будет. Реально slug нужен на тот случай, если у вас два сообщения в один день.&lt;/li>
&lt;li>md - подсказка, что это формат markdown. Jekyll поддерживает и другие форматы, но в данном примере я буду рассматривать markdown, он очень простой.&lt;/li>
&lt;/ul>
&lt;p>Заголовок (шапка) файла тоже имеет определенные требования, вот пример:&lt;/p>
&lt;pre>&lt;code>---
layout: post
title: &amp;quot;Текст про 8 марта&amp;quot;
date: &amp;quot;2010-03-08 8:00:00+03:00&amp;quot;
---
&lt;/code>&lt;/pre>
&lt;p>Что тут написано:&lt;/p>
&lt;ul>
&lt;li>&lt;code>layout: post&lt;/code> указывает jekyll, какой шаблон нужно использовать для отрисовки (перевода) данного статического текста в html-страницу. Post - стандартный шаблон, который идет в комплекте, и если нет уверенности – проще всего брать его.&lt;/li>
&lt;li>&lt;code>title&lt;/code> - это заголовок страницы. Именно этот текст будет отображен в списке постов на главной странице и именно этот текст будет в шапке страницы, когда пользователь ее откроет.&lt;/li>
&lt;li>&lt;code>date&lt;/code> - дата и время публикации. Время указывается в 24-формате с точностью до секунды, через &lt;code>+&lt;/code> (или &lt;code>-&lt;/code>) указывается тайм-зона. Ее указывать не обязательно, но тогда будет использоваться та, что указана в настройках. Эти дата и время будут показаны на сайте. Если их не указать – дата публикации будет взята из названия файла (если указать - из этого поля, а дата из названия будет игнорироваться).&lt;/li>
&lt;/ul>
&lt;p>Пропускаем строку после заголовка и можно писать текст&lt;/p>
&lt;h3 id="лирическое-отступление-markdown" >Лирическое отступление: markdown
&lt;span>
&lt;a href="#%d0%bb%d0%b8%d1%80%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%be%d0%b5-%d0%be%d1%82%d1%81%d1%82%d1%83%d0%bf%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5-markdown">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Markdown – это простой язык разметки. Он нужен для того, чтобы разделять в тексте заголовки и абзацы, делать текст &lt;strong>жирным&lt;/strong> или &lt;em>курсивным&lt;/em>. HTML, на котором написаны страницы, которые лежат в интернете – тоже язык разметки. Но HTML – язык сложный, мощный, гибкий и не прощающий ошибок. Markdown – напротив, специально сделан предельно простым, пусть и в ущерб гибкости.&lt;/p>
&lt;p>Markdown прекрасно понимает переносы строк. Нужно отделить один абзац от другого – достаточно одной пустой строки между ними.&lt;/p>
&lt;p>Для заголовков используется символ &lt;code>#&lt;/code>. Ставится он только с одной стороны и заголвок считается только с новой строки. Пример:&lt;/p>
&lt;ul>
&lt;li>&lt;code># заголовок&lt;/code> заголовок первого уровня (H1). Самый крупный.&lt;/li>
&lt;li>&lt;code>## заголовок поменьше&lt;/code> - заголовок второго уровня (h2). Поменьше.&lt;/li>
&lt;li>&lt;code>### подзаголовок&lt;/code> - заголовок третьего уровня. Самый маленький.&lt;/li>
&lt;/ul>
&lt;p>Для оформления текста внутри абзаца:&lt;/p>
&lt;ul>
&lt;li>&lt;code>**жирный**&lt;/code> - две звездочки сделают текст жирным (&lt;strong>bold&lt;/strong>).&lt;/li>
&lt;li>&lt;code>*курсивный*&lt;/code> - одна звездочка сделает текст наклонным (&lt;em>italic&lt;/em>)&lt;/li>
&lt;li>&lt;code>***жирный и курсивный***&lt;/code> - три звездочки сделают текст и жирным и курсивным &lt;em>&lt;strong>сразу&lt;/strong>&lt;/em>&lt;/li>
&lt;/ul>
&lt;p>Для ссылок:&lt;/p>
&lt;ul>
&lt;li>&lt;code>[ссылка обычная](https://yandex.ru)&lt;/code> - создаст обычную ссылку. Текст будет взят из &lt;code>[]&lt;/code>, а вести она будет по адресу &lt;code>()&lt;/code>.&lt;/li>
&lt;li>&lt;code>![картинка](https://yandex.ru/image.jpg)&lt;/code> - на странице появится картинка. Обратите внимание на &lt;code>!&lt;/code> в начале.&lt;/li>
&lt;/ul>
&lt;p>Чтобы создать список - начинайте строку с символа &lt;code>-&lt;/code> или &lt;code>*&lt;/code> и пробела за ним. Если у вас группа строк идет без разрыва, одна за другой – это будет воспринято как список:&lt;/p>
&lt;pre>&lt;code>- первый пункт
- второй
- третий
тут немного текста
- первый пункт второго списка
- второй пункт второго списка
&lt;/code>&lt;/pre>
&lt;p>Полное описание стандарта можно найти &lt;a href="https://daringfireball.net/projects/markdown/syntax">вот тут&lt;/a> (на английском языке). Существует огромное количество текстовых редакторов с поддержкой markdown, которые прямо во время редактирования показывают, каким будет оформление текста. Лично я пишу этот текст в прекрасном редакторе Sublime3.&lt;/p>
&lt;h3 id="настройки-сайта" >Настройки сайта
&lt;span>
&lt;a href="#%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b8-%d1%81%d0%b0%d0%b9%d1%82%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Глобальные настройки сайта находятся в файле &lt;code>_config.yml&lt;/code>. Он довольно очевидный и легко читается. Что я рекомендую в нем поменять:&lt;/p>
&lt;ul>
&lt;li>title - заголовок сайта. Отображается на каждой странице&lt;/li>
&lt;li>description - описание сайта. Отображается на каждой странице стандартного шаблона внизу экрана&lt;/li>
&lt;li>email, twitter_username, github_username - необязательные поля. Если есть - отображаются внизу экрана.&lt;/li>
&lt;li>url - адрес вашего сайта в сети. Важен для внутренних ссылок.&lt;/li>
&lt;li>baseurl - нужен в том случае, если jekyll является не основным сайтом, а только его частью и расположен в отдельной локации (к пример - по адресу &lt;code>/blog/&lt;/code>). Baseurl будет автоматически добавляется перед началом каждого адреса, который есть в jekyll. Это довольно редкая настройка.&lt;/li>
&lt;li>timezone - временная зона по умолчанию, задается в стандартном виде &lt;code>Регион/Город&lt;/code>. Типичная настройка для европейской части России - &lt;code>Europe/Moscow&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>Обычно настройки достаточно поменять один раз.&lt;/p>
&lt;h3 id="дополнительные-страницы" >Дополнительные страницы
&lt;span>
&lt;a href="#%d0%b4%d0%be%d0%bf%d0%be%d0%bb%d0%bd%d0%b8%d1%82%d0%b5%d0%bb%d1%8c%d0%bd%d1%8b%d0%b5-%d1%81%d1%82%d1%80%d0%b0%d0%bd%d0%b8%d1%86%d1%8b">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Обычно в блоге кроме собственно постов есть статические страницы, например – описание сайта или страница контактов. Jekyll позволяет создать такие страницы. Эти страницы не отображаются в списке постов на главной, но зато они видны в шапке сайта (сверху). Такие страницы нужно создавать прямо в корне (папке, где находятся все файлы jekyll) и в их названии не обязательно должна быть дата, достаточно просто имени и расширения md. Имя должно содержать только английские буквы, точку и тире (в противном случае могут быть сюрпризы). У страницы в заголовке должен быть обязательный атрибут &lt;code>permalink&lt;/code> – это указание jekyll, по какому адресу эта страница должна быть видна на сайте. В остальном такие файлы ничем не отличаются от файлов блог-постов, которые я описывал выше.&lt;/p>
&lt;h3 id="генерация-и-выкладка" >Генерация и выкладка
&lt;span>
&lt;a href="#%d0%b3%d0%b5%d0%bd%d0%b5%d1%80%d0%b0%d1%86%d0%b8%d1%8f-%d0%b8-%d0%b2%d1%8b%d0%ba%d0%bb%d0%b0%d0%b4%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Итак, текст написан, можем выкладывать. Чтобы собрать сайт из страниц-заготовок - используйте команду &lt;code>jekyll build&lt;/code>. Ответ будет выглядеть примерно так:&lt;/p>
&lt;pre>&lt;code>&amp;gt; jekyll build
Configuration file: /home/testsite/_config.yml
Source: /home/testsite
Destination: /home/testsite/_site
Incremental build: disabled. Enable with --incremental
Generating...
done in 1.683 seconds.
Auto-regeneration: disabled. Use --watch to enable.
&lt;/code>&lt;/pre>
&lt;p>В нормальном состоянии jekyll не должен как-то ругаться, выбрасывать предупреждения или ошибки. Если они все же есть – рекомендую их внимательно прочитать. Обычно прямо в тексте ошибки есть указание на то, как ее исправить.&lt;/p>
&lt;p>Готовые к выкладке файлы будут ждать в папке &lt;code>_site&lt;/code>. Теперь достаточно просто скопировать их на хостинг (подойдет совершенно любой хостинг, который позволяет загружать на него файлы) - и сайт доступен в интернете. На хостинг нужно отправлять только содержимое папки &lt;code>_site&lt;/code>, ничего больше отправлять не нужно! Для размещения сайта можно, например, использовать совершенно бесплатный &lt;a href="https://pages.github.com/">github pages&lt;/a>, но в принципе – найти хостинг бесплатный или очень дешевый хостинг - несложно. Благо, все, что от него требуется – возможность хоть в каком-то виде отправлять на него файлы.&lt;/p>
&lt;h3 id="добавление-удаление-контента" >Добавление-удаление контента
&lt;span>
&lt;a href="#%d0%b4%d0%be%d0%b1%d0%b0%d0%b2%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5-%d1%83%d0%b4%d0%b0%d0%bb%d0%b5%d0%bd%d0%b8%d0%b5-%d0%ba%d0%be%d0%bd%d1%82%d0%b5%d0%bd%d1%82%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>В обновлении сайта нет ничего сложного, но на всякий случай я опишу его тезисно:&lt;/p>
&lt;ul>
&lt;li>пишем новый текст. Файл кладем в &lt;code>_posts&lt;/code>, если это запись в блоге или в корень сайта на жестком диске, если это – простая страница&lt;/li>
&lt;li>выполняем &lt;code>jekyll build&lt;/code>, чтобы пересобрать сайт&lt;/li>
&lt;li>загружаем содержимое папки &lt;code>_site&lt;/code> на хостинг. Если какие-то файлы на хостинге уже есть с прошлого раза – перезаписываем.&lt;/li>
&lt;li>сайт обновлен и готов к использованию&lt;/li>
&lt;/ul></description></item><item><title>Резервное копироварие mysql с помощью xtrabackup</title><link>https://prudnitskiy.pro/post/2016-04-21-xtrabackup/</link><pubDate>Thu, 21 Apr 2016 00:20:10 +0000</pubDate><guid>https://prudnitskiy.pro/post/2016-04-21-xtrabackup/</guid><description>&lt;p>MySQL - сверх-популярный сервер баз данных. Его используют (или использовали) практически все. Одна из самых популярных задач в системном администрировании - бэкап (и восстановление). Или, как подвид - миграция данных (бэкап + последующее восстановление). Это делают практически все. И практически все используют для mysql_dump, что категорически неправильно и часто просто опасно. В этой статье я расскажу, почему mysql_dump - это плохое решение и что с ним можно сделать.&lt;/p>
&lt;h2 id="проблема" >Проблема
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%be%d0%b1%d0%bb%d0%b5%d0%bc%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>У mysql_dump есть три основных проблемы - скорость, неконсистентность и блокировки. Все три проблемы проистекают из его архитектуры, так что вылечить их невозможно. Чтобы понять проблемы, опишу алгоритм работы mysql_dump:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>mysql_dump получает список таблиц в базе&lt;/p>
&lt;/li>
&lt;li>
&lt;p>он проходит по списку по алфавиту (уже опасный момент)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>для каждой таблицы он делает три действия:&lt;/p>
&lt;/li>
&lt;li>
&lt;p>сначала он снимает структуру. Это очень быстрое действие.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>затем таблица блокируется на запись (целиком)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>после этого mysql_dump выгружает все данные (грубо говоря - делает &lt;code>SELECT * FROM table&lt;/code>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>все выгруженное отправляется на stdout. Обычно stdout перенаправляется в файл (классическая конструкция: &lt;code>mysql_dump dbname &amp;gt; file.sql&lt;/code>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>после того, как сканирование таблицы заканчивается - блокировка снимается и dump переходит к следующей таблице.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Самая серьезная проблема, которая лежит на поверхности - блокировки. В момент, когда mysql_dump блокирует таблицу - записать в нее что-либо становится невозможно. В лучшем случае изменения в таблице будут накапливаться (если приложение умеет копить изменения и работать с базой асинхронно, как gorm). В худшем случае приложение упадет с ошибкой записи, а пользователь получит фигу в виде ошибки 500. Проблема консистентности лежит глубже, а потому она много опаснее, так как сходу эти грабли неочевидны, а по лбу бьют больно. Рассмотрим пример. У нас есть база, в которой лежит 3 таблицы: &amp;ldquo;affilates&amp;rdquo;, &amp;ldquo;logs&amp;rdquo; и &amp;ldquo;organisations&amp;rdquo;. Таблица logs очень большая. Таблицы affilates и organisations связаны через внешний ключ. Приложение вставляет запись в &amp;ldquo;affilates&amp;rdquo;, а затем - пачку записей в &amp;ldquo;organisations&amp;rdquo; с ключом, указывающим на запись в &amp;ldquo;affilates&amp;rdquo;. По логике работы mysql_dump, первой будет блокирована и сдамплена affilates. Записи в organisations можно вставлять только для уже существующих affilates, целосность данных не нарушается. После того, как affilates закончится и разблокируется, будет заблокирована logs. Как я уже писал, по условиям задачи она у нас большая и копируется, скажем, час (вполне реальный срок для большой таблицы). При этом никто не мешает создать запись в affilates, а потом из organisations сослаться на эту новую запись. Так, как упаковка affilates уже завершена - в дамп новая запись не попадет. После того, как мы упакуем organisations - в organisations образуются записи, ссылающиеся на не существовавшие в момент дампа ключи. И восстановить такой дамп без определенных магических движений будет невозможно. Ну и в качестве бонуса - мы потеряем данные, которые были созданы в процессе дампа, то есть целосность дампа будет на момент &lt;em>начала&lt;/em> операции, а не ее &lt;em>окончания&lt;/em>. Чтобы бороться со всеми этими проблемами и был придуман xtrabackup.&lt;/p>
&lt;h2 id="установка-и-настройка" >установка и настройка
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d0%b8-%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>xtrabackup - отдельный инструмент от компании percona. Из-за этого в большинстве штатных системных репозиториев он отсутствует - нужно ставить его из репозитория percona. Установка для debian и ubuntu:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">wget https://repo.percona.com/apt/percona-release_0.1-3.&lt;span style="color:#66d9ef">$(&lt;/span>lsb_release -sc&lt;span style="color:#66d9ef">)&lt;/span>_all.deb
dpkg -i percona-release_0.1-3.&lt;span style="color:#66d9ef">$(&lt;/span>lsb_release -sc&lt;span style="color:#66d9ef">)&lt;/span>_all.deb
apt-get update
apt-get install percona-xtrabackup&lt;/code>&lt;/pre>&lt;/div>
&lt;p>То же самое для RHEL-based (CentOS, RedHat, Fedora, ScientificLinux)&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpm
yum clean all
yum makecache
yum install -y percona-xtrabackup&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Для удобства работы с xtrabackup (особенно, если хочется с его помощь делать резервные копии автоматически) рекомендуется создать файл-ответчик с паролем администратора сервера. Назовем его, к примеру, /root/.percona. Пример такого файла:&lt;/p>
&lt;pre>&lt;code>[client]
user=root
password=YYYYYYYY
&lt;/code>&lt;/pre>
&lt;h2 id="примерение" >Примерение
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%b8%d0%bc%d0%b5%d1%80%d0%b5%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;h3 id="простой-вариант---резервная-копия-всего-сервера-целиком" >Простой вариант - резервная копия всего сервера целиком:
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%be%d1%81%d1%82%d0%be%d0%b9-%d0%b2%d0%b0%d1%80%d0%b8%d0%b0%d0%bd%d1%82---%d1%80%d0%b5%d0%b7%d0%b5%d1%80%d0%b2%d0%bd%d0%b0%d1%8f-%d0%ba%d0%be%d0%bf%d0%b8%d1%8f-%d0%b2%d1%81%d0%b5%d0%b3%d0%be-%d1%81%d0%b5%d1%80%d0%b2%d0%b5%d1%80%d0%b0-%d1%86%d0%b5%d0%bb%d0%b8%d0%ba%d0%be%d0%bc">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">innobackupex --rsync --defaults-file&lt;span style="color:#f92672">=&lt;/span>/root/.percona --no-timestamp /var/tmp/backup
innobackupex --rsync --defaults-file&lt;span style="color:#f92672">=&lt;/span>/root/.percona --no-timestamp --apply-log /var/tmp/backup&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Восстановление выглядит еще проще. Нужно просто остановить процесс mysql и положить файлы в datadir (обычно это /var/lib/mysql/), а затем - запустить mysql обратно. Перед запуском - обязательно сменить права доступа на файлы, чтобы файлами владел владелец процесса mysql:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">service mysql stop
rm -rf /var/lib/mysql/*
mv /var/tmp/backup/* /var/lib/mysql/
chown -R mysql:mysql /var/lib/mysql/
service mysql start&lt;/code>&lt;/pre>&lt;/div>
&lt;h3 id="усложненный-вариант---создаем-mysql-slave-от-имеющегося-мастера" >Усложненный вариант - создаем mysql slave от имеющегося мастера:
&lt;span>
&lt;a href="#%d1%83%d1%81%d0%bb%d0%be%d0%b6%d0%bd%d0%b5%d0%bd%d0%bd%d1%8b%d0%b9-%d0%b2%d0%b0%d1%80%d0%b8%d0%b0%d0%bd%d1%82---%d1%81%d0%be%d0%b7%d0%b4%d0%b0%d0%b5%d0%bc-mysql-slave-%d0%be%d1%82-%d0%b8%d0%bc%d0%b5%d1%8e%d1%89%d0%b5%d0%b3%d0%be%d1%81%d1%8f-%d0%bc%d0%b0%d1%81%d1%82%d0%b5%d1%80%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#75715e">#on master&lt;/span>
innobackupex --rsync --defaults-file&lt;span style="color:#f92672">=&lt;/span>/root/.percona --no-timestamp /var/tmp/backup
innobackupex --rsync --defaults-file&lt;span style="color:#f92672">=&lt;/span>/root/.percona --no-timestamp --apply-log /var/tmp/backup
rsync -rahP /var/tmp/backup NEW.SERVER.IP:/var/tmp/
&lt;span style="color:#75715e">#выдадим права для slave, чтобы он мог читать данные из master-сервера:&lt;/span>
mysql --defaults-file&lt;span style="color:#f92672">=&lt;/span>/root/.percona -Bse &lt;span style="color:#e6db74">&amp;#34;GRANT REPLICATION SLAVE ON *.* TO &amp;#39;replica&amp;#39;@&amp;#39;NEW.SLAVE.SEVER.IP&amp;#39; IDENTIFIED BY &amp;#39;XXXXXXXX&amp;#39;&amp;#34;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>innobackupex создает специальный файл с информацией о текущем бинлоге и позиции в этом бинлоге. Эта информация необходима для подключения slave - чтобы slave мог знать, с какого точно момента в прошлом была сделана эта копия базы (и начал синхронизацию именно с нужного момента). Файл называется &lt;code>xtrabackup_binlog_info&lt;/code>. Содержимое у него выглядит примерно вот так:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">mariadb-bin.000003 &lt;span style="color:#ae81ff">642&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Подключим slave-сервер к master-серверу. Для этого остановим mysql и подложим в datadir файлы, которые мы скопировали с master:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">service mysql stop
rm -rf /var/lib/mysql/*
mv /var/tmp/backup/* /var/lib/mysql/
chown -R mysql:mysql /var/lib/mysql
service mysql start&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Теперь подключим slave к master. Для этого в консоли mysql:&lt;/p>
&lt;pre>&lt;code>--- на всякий случай почистим остатки старой конфигурации slave.
--- В принципе их быть не должно.
STOP SLAVE;
RESET SLAVE;
--- настроим подключение к master
--- log_file и log_pos - из xtrabackup_binlog_info
CHANGE MASTER TO MASTER_HOST='NEW.MASTER.SERVER.IP',
MASTER_USER='replica',
MASTER_PASSWORD='YYYYYYYY',
MASTER_LOG_FILE='mariadb-bin.000003',
MASTER_LOG_POS=642;
--- запустим процесс репликации
START SLAVE
--- убедимся, что нет ошибок
SHOW SLAVE STATUS \G
&lt;/code>&lt;/pre>
&lt;h3 id="сложный-вариант---переносим-отдельную-таблицу" >сложный вариант - переносим отдельную таблицу
&lt;span>
&lt;a href="#%d1%81%d0%bb%d0%be%d0%b6%d0%bd%d1%8b%d0%b9-%d0%b2%d0%b0%d1%80%d0%b8%d0%b0%d0%bd%d1%82---%d0%bf%d0%b5%d1%80%d0%b5%d0%bd%d0%be%d1%81%d0%b8%d0%bc-%d0%be%d1%82%d0%b4%d0%b5%d0%bb%d1%8c%d0%bd%d1%83%d1%8e-%d1%82%d0%b0%d0%b1%d0%bb%d0%b8%d1%86%d1%83">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Искушающе простой способ (остановить mysql, подсунуть файлы с таблицей и запустить обратно) - не сработает, техника немного сложнее. Чтобы восстановить таблицу, нужно подготовить таблицу внутри резеврной копии к экспорту:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">xtrabackup --prepare --export --target-dir&lt;span style="color:#f92672">=&lt;/span>/var/tmp/backup&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Теперь нужно создать таблицу с именем экспортируемой таблицы. Структура и содержимое не важны, важно только имя таблицы (имя базы тоже можно не учитывать):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sql" data-lang="sql">mysql&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#66d9ef">CREATE&lt;/span> &lt;span style="color:#66d9ef">TABLE&lt;/span> ineedtorestore (a int(&lt;span style="color:#ae81ff">11&lt;/span>) &lt;span style="color:#66d9ef">DEFAULT&lt;/span> &lt;span style="color:#66d9ef">NULL&lt;/span>) ENGINE&lt;span style="color:#f92672">=&lt;/span>InnoDB &lt;span style="color:#66d9ef">DEFAULT&lt;/span> CHARSET&lt;span style="color:#f92672">=&lt;/span>latin1;
mysql&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#66d9ef">ALTER&lt;/span> &lt;span style="color:#66d9ef">TABLE&lt;/span> ineedtorestore DISCARD TABLESPACE;&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Кстати, если при вводе второй таблицы выскочит ошибка &lt;code>ERROR 1030 (HY000): Got error -1 from storage engine&lt;/code>, то нужно включить в my.cnf настройку &lt;code>innodb_file_per_table&lt;/code>.&lt;/p>
&lt;p>Теперь нужно скопировать файлы с именем таблицы, которую мы будем восстанавливать, в каталог базы и перечитать файлы командой:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sql" data-lang="sql">mysql&lt;span style="color:#f92672">&amp;gt;&lt;/span> &lt;span style="color:#66d9ef">ALTER&lt;/span> &lt;span style="color:#66d9ef">TABLE&lt;/span> ineedtorestore IMPORT TABLESPACE;&lt;/code>&lt;/pre>&lt;/div>
&lt;p>После этого мы получим новую таблицу из бэкапа.&lt;/p></description></item><item><title>Отслеживаем PHP с помощью PINBA на debian</title><link>https://prudnitskiy.pro/post/2015-11-26-pinba/</link><pubDate>Thu, 26 Nov 2015 16:21:06 +0000</pubDate><guid>https://prudnitskiy.pro/post/2015-11-26-pinba/</guid><description>&lt;p>PHP - исключительно популярный язык программирования, до сих пор огромное количество проектов пишется именно на нем. Язык ругают за отвратительный дизайн, неудобный синтаксис, кривое поведение в спорных случаях, отсутствие нормальных средств отладки - но его популярность это никак не снижает. Самое страшное для админа - ситуация, когда на сильно нагруженном проекте начинает тормозить код. Стандартные средства отладки (xprof, xdebug) роняют производительность языка в яму (накладные расходы - вплоть до пятикратного падения скорости), и как отлаживать сложный код на живую - совершенно неясно. Именно для борьбы с такими проблемами придумана PINBA - расширение для мониторинга скорости кода. Тут я расскажу, как установить PINBA (клиент, сервер и интерфейс) на debian и что с ними потом делать.&lt;/p>
&lt;h2 id="как-это-работает" >Как это работает
&lt;span>
&lt;a href="#%d0%ba%d0%b0%d0%ba-%d1%8d%d1%82%d0%be-%d1%80%d0%b0%d0%b1%d0%be%d1%82%d0%b0%d0%b5%d1%82">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>В отличае от XProf PINBA практически не замедляет работу скрипта. В базовом варианте она не требует никакой модификации PHP кода и никак на его выполнение не влияет. Устройство очень простое, штатно PINBA состоит из двух частей. Во-первых - это PHP extenstion (pinba.so), который отслеживает время выполнения скрипта (а так же - адрес скрипта и URL, нагрузку на CPU, память и код завершения). По окончании выполнения запроса он отправляет данные на сервер pinba. Сервер - это MySQL, собранный со специальным плагином (libpinba.so). Сервер принимает на определенном порту UDP-датаграммы и складывает их в базу. Интерфейсом для чтения статистики служит MySQL, что позволяет сравнительно легко анализировать данные и писать к ним свои интерфейсы. Важно, что php extension (генератор) не проверяет целостность отправленных данных или качество их доставки - он просто считает и отправляет.&lt;/p>
&lt;p>Вот как будет выглядеть наша инсталляция:&lt;/p>
&lt;p>&lt;img src="https://prudnitskiy.pro/media/uploads/pinba.png" alt="https://prudnitskiy.pro/media/uploads/pinba.png" title="схема инсталляции">&lt;/p>
&lt;h2 id="установка-клиент" >Установка: клиент
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d0%ba%d0%bb%d0%b8%d0%b5%d0%bd%d1%82">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>В debian репозитории DotDeb есть нужный нам клиент (генератор статистики) и проще всего его прямо оттуда и поставить. Если у вас еще не установлен DotDeb - вот &lt;a href="https://www.dotdeb.org/instructions/" title="инструкция">инструкция&lt;/a>. После этого просто ставим пакет:&lt;/p>
&lt;pre>&lt;code>apt-get install -y php5-pinba
&lt;/code>&lt;/pre>
&lt;p>И настраиваем его, поправив файл /etc/php5/mods-available/pinba.ini&lt;/p>
&lt;pre>&lt;code>extension=pinba.so
pinba.enabled=1
pinba.server=172.16.10.10:30002
&lt;/code>&lt;/pre>
&lt;p>В этом примере предполагается, что сервер, собирающий статистику у нас имеет адрес 172.16.10.10 и порт 30002. После этого перезапускаем php и установка клиента на этом закончена.&lt;/p>
&lt;h2 id="установка-сервер" >Установка: сервер
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d1%81%d0%b5%d1%80%d0%b2%d0%b5%d1%80">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>С установкой сервера все несколько сложнее, так как пакет pinba-server есть только у dotdeb и он сломан. Его прийдется собирать из исходного кода. Для начала на сервер статистики поставим сам mysql. Это должен быть именно стандартный mysql, а не maria или percona:&lt;/p>
&lt;pre>&lt;code>apt-get install mysql-server-5.6 mysql-client-5.6 libmysqlclient18 libmysqlclient18-dev
&lt;/code>&lt;/pre>
&lt;p>Теперь поставим инструменты разработки, они потребуются нам, чтобы собрать пакет:&lt;/p>
&lt;pre>&lt;code>apt-get install build-essential protobuf-compiler libmysqlclient-dev \
libjudydebian1 libevent-dev libjudy-dev git libevent-2.0-5 libtool \
libevent-core-2.0-5 libevent-extra-2.0-5 libevent-openssl-2.0-5 \
libevent-pthreads-2.0-5 libprotobuf-dev libprotobuf-lite7 libprotobuf7 git-core
&lt;/code>&lt;/pre>
&lt;p>Переходим в tmp, выгружаем код pinba engine (сервер статистики) и исходный код mysql server:&lt;/p>
&lt;pre>&lt;code>cd /var/tmp
git clone 'https://github.com/tony2001/pinba_engine'
apt-get source mysql-server
&lt;/code>&lt;/pre>
&lt;p>Нам потребуется header-file от существующего mysql-сервера, скопируем. Я не знаю, какая версия mysql-server будет у вас, у меня это mysql-5.6-5.6.25.&lt;/p>
&lt;pre>&lt;code> cp '/usr/include/mysql/mysql_version.h' /var/tmp/mysql-5.6-5.6.25/include/
cp '/usr/include/mysql/my_config.h' /var/tmp/mysql-5.6-5.6.25/include/
&lt;/code>&lt;/pre>
&lt;p>Нам нужно узнать текущие опции сборки mysql:&lt;/p>
&lt;pre>&lt;code>OPTIONS=&amp;quot;$(VISUAL=\&amp;quot;$(which 'cat')\&amp;quot; mysqlbug | grep 'Configured with' | sed -e 's/.*configure -v //')&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Соберем модуль:&lt;/p>
&lt;pre>&lt;code>cd pinba_engine
./buildconf.sh
./configure ${OPTIONS} \
--with-mysql='${MYSQL_SOURCES}' \
--with-judy \
--with-protobuf \
--with-event \
--libdir='/usr/lib/mysql/plugin/'
make
make install
&lt;/code>&lt;/pre>
&lt;p>Библиотека собрана, теперь можно установить плагин на сервер и создать базу, где мы будем хранить статистику:&lt;/p>
&lt;pre>&lt;code>mysql --execute=&amp;quot;INSTALL PLUGIN pinba SONAME 'libpinba_engine.so';&amp;quot; --user=root
mysql --execute=&amp;quot;CREATE DATABASE pinba DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_unicode_ci;&amp;quot; --user=root
mysql --user=root 'pinba' &amp;lt; '/tmp/pinba_engine/default_tables.sql'
mysql --user=root --execute=&amp;quot;grant all on pinba.* to pinbauser@localhost identified by 'Hkx77jg8t6zGw6J5'&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Теперь сообщим серверу настройки pinba. Для этого поправим /etc/mysql/my.cnf. В секции [mysqld] добавим следующее:&lt;/p>
&lt;pre>&lt;code>pinba_port = 30002
pinba_address = 172.16.10.10
pinba_stats_gathering_period = 10000
pinba_stats_history = 900
pinba_temp_pool_size = 10000
pinba_request_pool_size = 10000
&lt;/code>&lt;/pre>
&lt;p>Чтобы изменения вступили в силу - надо перезапустить mysql. Разумеется, порт UDP/30002 не должен быть заблокирован в firewall. Настройка сервера на этом закончена, будемт ставить интерфейс.&lt;/p>
&lt;h2 id="установка-интерфейс" >Установка: интерфейс
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d0%b8%d0%bd%d1%82%d0%b5%d1%80%d1%84%d0%b5%d0%b9%d1%81">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Эту роль у нас будет выполнять Intaro&amp;rsquo;s pinboard. Интерфейс довольно простой, но удобный и симпатичный. В принципе, его можно поставить на любой сервер, с которого есть доступ к mysql, в моем примере это будет тот же сервер, куда мы собираем статистику. Для работы pinboard потребуется nginx, php5 (версии не менее 5.5) и php composer. Установим:&lt;/p>
&lt;pre>&lt;code>apt-get install -y php5-cli php5-common php5-curl php5-fpm php5-gd php5-mysql nginx-full
curl -sS https://getcomposer.org/installer | php
&lt;/code>&lt;/pre>
&lt;p>Выгрузим код:&lt;/p>
&lt;pre>&lt;code>cd /var/www
git clone git://github.com/intaro/pinboard.git --branch=v1.5.2
&lt;/code>&lt;/pre>
&lt;p>Установим зависимости:&lt;/p>
&lt;pre>&lt;code>cd pinboard
php composer.phar install
&lt;/code>&lt;/pre>
&lt;p>Чтобы интерфейс знал адрес и параметры соединения с базой, поправим настройки в файле &amp;lsquo;config/parameters.yml&amp;rsquo;:&lt;/p>
&lt;pre>&lt;code>db:
host: 127.0.0.1
name: pinba
user: pinbauser
pass: Hkx77jg8t6zGw6J5
&lt;/code>&lt;/pre>
&lt;p>остальное менять не нужно. Мигрируем базу:&lt;/p>
&lt;pre>&lt;code>./console migrations:migrate
&lt;/code>&lt;/pre>
&lt;p>Добавляем задание в крон для агрегации данных:&lt;/p>
&lt;pre>&lt;code>./console register-crontab
&lt;/code>&lt;/pre>
&lt;p>Теперь осталось настроить nginx. Для этого создадим файл /etc/nginx/sites-enabled/pinba со следующим содержанием:&lt;/p>
&lt;pre>&lt;code>server {
listen 80;
server_name pinba.ourdomian;
access_log /var/log/nginx/pinba.access.log;
error_log /var/log/nginx/pinba.error.log;
root /var/www/pinboard/web;
location = / {
try_files @site @site;
}
location / {
try_files $uri $uri/ @site;
}
location ~ \.php$ {
return 404;
}
location @site {
fastcgi_pass unix:///var/run/php5-fpm.sock;
include fastcgi_params;
fastcgi_param SCRIPT_FILENAME $document_root/index.php;
}
location ~ /\.(ht|svn|git) {
deny all;
}
}
&lt;/code>&lt;/pre>
&lt;p>Теперь достаточно просто перезапустить nginx и можно пользоваться нашим новым интерфейсом. Важно понимать, что статистика агрегируется раз в N минут (частоту спросит сам pinboard при миграции данных), но данные в секции live доступны в любой момент.&lt;/p></description></item><item><title>Миграция на mongo replica set без потери данных</title><link>https://prudnitskiy.pro/post/2015-09-06-mongo-shard/</link><pubDate>Sun, 06 Sep 2015 00:13:48 +0000</pubDate><guid>https://prudnitskiy.pro/post/2015-09-06-mongo-shard/</guid><description>&lt;p>По сути - это не статья, а, скорее, просто памятка, чтобы самому не забыть. MongoDB - популярный документо-ориентированный движок управления базой. Штатно он имеет две разных технологии кластеризации: репликационные наборы (replica set) и шардирование (shard). Разница проста - в случае реплики на всех узлах данные одинаковы и любой узел может выступать источником данных (&lt;strong>внимание, mongodb не является CAP-полной базой, так что точность данных тут под большим вопросом!&lt;/strong>), что обеспечивает отказоустойчивость. В случае шардирования данные &amp;ldquo;размазаны&amp;rdquo; по всему набору шарда, но каждый сервер внутри шарда имеет только свои данные. За счет этого распределяется нагрузка (например, с трех узлов данные можно читать параллельно), но снижается надежность - упавший узел означает потерю части данных шарда. В данной статье будет описание, как переехать с единичной монги на репсет не потеряв при этом данные.&lt;/p>
&lt;p>Важной особенностью репсета является тот факт, что в нем всегда только один мастер, и запись можно производить только на мастер. Таким забавным способом mongo борется с потенциальными конфликтами конкурентной записи данных (задача, на самом деле, куда как непростая, Riak это ярко демонстрирует). В случае, если мастер умер - производятся выборы нового мастера. К слову, пока они идут - в репсет нельзя записать ничего, от слова совсем.&lt;/p>
&lt;h2 id="инструкция" >Инструкция
&lt;span>
&lt;a href="#%d0%b8%d0%bd%d1%81%d1%82%d1%80%d1%83%d0%ba%d1%86%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Итак, у нас есть одна MongoDB, к которой подключено приложение и мы хотим перевести это приложение на работу с кластером. Авторы mongo рекомендуют иметь нечетное количество узлов в наборе для гарантии достижения кворума, то есть потребуется 3 сервера. В отличае от MySQL - управление выбором узлов для чтения и записи в монго возложено на драйвер (то есть - коннектор языка программирования к базе, а не на саму базу). Перед началом работ очень рекомендую, умеет ли ваш драйвер работать с репсетами. Первое, что нужно поменять - это в файле настроек указать IP адрес, на который mongo привязывается (она должна быть доступна по сети) и задать параметр replicationSet. Один инстанс mongo может одновременно находится только в одном replication set. Параметр - не динамический, mongo надо перезапустить для его применения. Вписываем в /etc/mongo:&lt;/p>
&lt;pre>&lt;code>#имя replica set. Должно быть уникальным, но единым для всего набора
replSet=replica1
#bind_ip закомментирован - слушать на всех доступных адресах.
#bind_ip=
port=27017
&lt;/code>&lt;/pre>
&lt;p>Перезапускаем mongo, подключаемся к консоли (команда mongo) и инициируем набор:&lt;/p>
&lt;pre>&lt;code># service mongodb restart
# mongo
&amp;gt; rs.initiate()
{
&amp;quot;info2&amp;quot; : &amp;quot;no configuration explicitly specified -- making one&amp;quot;,
&amp;quot;me&amp;quot; : &amp;quot;db1.cluser:27017&amp;quot;,
&amp;quot;ok&amp;quot; : 1
}
&lt;/code>&lt;/pre>
&lt;p>Чтобы быть уверенными, что мастером останется именно тот сервер, с которого мы начинаем конфигурирование (и на котором храним данные, которые не хотим потерять) - повысим ему приоритет в наборе. Мастер выбирается по принципу - случайный из максимального доступного приоритета, приоритет 0 будет означать, что данный сервер стать мастером не сможет никогда.&lt;/p>
&lt;pre>&lt;code>replica1:PRIMARY&amp;gt; cfg = rs.conf()
{
&amp;quot;_id&amp;quot; : &amp;quot;replica1&amp;quot;,
&amp;quot;version&amp;quot; : 1,
&amp;quot;members&amp;quot; : [
{
&amp;quot;_id&amp;quot; : 0,
&amp;quot;host&amp;quot; : &amp;quot;db1.cluster:27017&amp;quot;,
&amp;quot;arbiterOnly&amp;quot; : false,
&amp;quot;buildIndexes&amp;quot; : true,
&amp;quot;hidden&amp;quot; : false,
&amp;quot;priority&amp;quot; : 1,
&amp;quot;tags&amp;quot; : {
},
&amp;quot;slaveDelay&amp;quot; : 0,
&amp;quot;votes&amp;quot; : 1
}
],
&amp;quot;settings&amp;quot; : {
&amp;quot;chainingAllowed&amp;quot; : true,
&amp;quot;heartbeatTimeoutSecs&amp;quot; : 10,
&amp;quot;getLastErrorModes&amp;quot; : {
},
&amp;quot;getLastErrorDefaults&amp;quot; : {
&amp;quot;w&amp;quot; : 1,
&amp;quot;wtimeout&amp;quot; : 0
}
}
}
replica1:PRIMARY&amp;gt; cfg.members[0].priority = 100
100
replica1:PRIMARY&amp;gt; rs.reconfig(cfg)
{ &amp;quot;ok&amp;quot; : 1 }
&lt;/code>&lt;/pre>
&lt;p>Проверим состояние нашей реплики:&lt;/p>
&lt;pre>&lt;code>replica1:PRIMARY&amp;gt; rs.status()
{
&amp;quot;set&amp;quot; : &amp;quot;replica1&amp;quot;,
&amp;quot;date&amp;quot; : ISODate(&amp;quot;2015-08-20T19:38:18.845Z&amp;quot;),
&amp;quot;myState&amp;quot; : 1,
&amp;quot;members&amp;quot; : [
{
&amp;quot;_id&amp;quot; : 0,
&amp;quot;name&amp;quot; : &amp;quot;db1.cluster:27017&amp;quot;,
&amp;quot;health&amp;quot; : 1,
&amp;quot;state&amp;quot; : 1,
&amp;quot;stateStr&amp;quot; : &amp;quot;PRIMARY&amp;quot;,
&amp;quot;uptime&amp;quot; : 96,
&amp;quot;optime&amp;quot; : Timestamp(1440099489, 1),
&amp;quot;optimeDate&amp;quot; : ISODate(&amp;quot;2015-08-20T19:38:09Z&amp;quot;),
&amp;quot;electionTime&amp;quot; : Timestamp(1440099465, 2),
&amp;quot;electionDate&amp;quot; : ISODate(&amp;quot;2015-08-20T19:37:45Z&amp;quot;),
&amp;quot;configVersion&amp;quot; : 2,
&amp;quot;self&amp;quot; : true
}
],
&amp;quot;ok&amp;quot; : 1
}
&lt;/code>&lt;/pre>
&lt;p>Все ок. Ставим новый (пустой) сервер с mongo, прописываем в настройках replica set, запускаем. Теперь надо новый сервер добавить в набор:&lt;/p>
&lt;pre>&lt;code>replica1:PRIMARY&amp;gt; rs.add(&amp;quot;db2.cluster:27017&amp;quot;)
{ &amp;quot;ok&amp;quot; : 1 }
&lt;/code>&lt;/pre>
&lt;p>Узлы кластера должны быть доступны друг другу по порту, на котором работает mongo (по умолчанию 27017). Если используются имена, а не IP-адреса - важно убедится в том, что они правильно определяются со всех машин. Сервера общаются асинхронно, все со всеми. Проверим состояние нашего набора:&lt;/p>
&lt;pre>&lt;code>replica1:PRIMARY&amp;gt; rs.status()
{
&amp;quot;set&amp;quot; : &amp;quot;replica1&amp;quot;,
&amp;quot;date&amp;quot; : ISODate(&amp;quot;2015-08-20T21:16:13.381Z&amp;quot;),
&amp;quot;myState&amp;quot; : 1,
&amp;quot;members&amp;quot; : [
{
&amp;quot;_id&amp;quot; : 0,
&amp;quot;name&amp;quot; : &amp;quot;db1.cluster:27017&amp;quot;,
&amp;quot;health&amp;quot; : 1,
&amp;quot;state&amp;quot; : 1,
&amp;quot;stateStr&amp;quot; : &amp;quot;PRIMARY&amp;quot;,
&amp;quot;uptime&amp;quot; : 77,
&amp;quot;optime&amp;quot; : Timestamp(1440105350, 1),
&amp;quot;optimeDate&amp;quot; : ISODate(&amp;quot;2015-08-20T21:15:50Z&amp;quot;),
&amp;quot;electionTime&amp;quot; : Timestamp(1440105297, 1),
&amp;quot;electionDate&amp;quot; : ISODate(&amp;quot;2015-08-20T21:14:57Z&amp;quot;),
&amp;quot;configVersion&amp;quot; : 3,
&amp;quot;self&amp;quot; : true
},
{
&amp;quot;_id&amp;quot; : 1,
&amp;quot;name&amp;quot; : &amp;quot;db2.cluster:27017&amp;quot;,
&amp;quot;health&amp;quot; : 1,
&amp;quot;state&amp;quot; : 5,
&amp;quot;stateStr&amp;quot; : &amp;quot;STARTUP2&amp;quot;,
&amp;quot;uptime&amp;quot; : 23,
&amp;quot;optime&amp;quot; : Timestamp(0, 0),
&amp;quot;optimeDate&amp;quot; : ISODate(&amp;quot;1970-01-01T00:00:00Z&amp;quot;),
&amp;quot;lastHeartbeat&amp;quot; : ISODate(&amp;quot;2015-08-20T21:16:12.351Z&amp;quot;),
&amp;quot;lastHeartbeatRecv&amp;quot; : ISODate(&amp;quot;2015-08 20T21:16:12.363Z&amp;quot;),
&amp;quot;pingMs&amp;quot; : 0,
&amp;quot;syncingTo&amp;quot; : &amp;quot;db1.cluster:27017&amp;quot;,
&amp;quot;configVersion&amp;quot; : 3
}
],
&amp;quot;ok&amp;quot; : 1
}
&lt;/code>&lt;/pre>
&lt;p>Статус STARTUP2 означает, что новый член набора синхронизируется (выгружает данные) с мастером. так, как по умолчанию приоритет у новых серверов - 1, даже после окончания, даже случайно этот сервер не сможет стать мастером, что убережет нас от потери данных.&lt;/p>
&lt;p>Дождавшись синхронизации (state у нового сервера должен будет изменится на SECONDARY) - добавляем еще один сервер по точно такой же схеме:&lt;/p>
&lt;pre>&lt;code>replica1:PRIMARY&amp;gt; rs.add(&amp;quot;db3.cluster:27017&amp;quot;)
{ &amp;quot;ok&amp;quot; : 1 }
&lt;/code>&lt;/pre>
&lt;p>И снова ждем состояния SECONDARY. Теперь можно снизить приоритет основного сервера, чтобы он стал равноправным членом кластера:&lt;/p>
&lt;pre>&lt;code>replica1:PRIMARY&amp;gt; cfg.members[0].priority = 1
1
replica1:PRIMARY&amp;gt; rs.reconfig(cfg)
{ &amp;quot;ok&amp;quot; : 1 }
&lt;/code>&lt;/pre>
&lt;p>И теперь убедимся, что все ок:&lt;/p>
&lt;pre>&lt;code>replica1:PRIMARY&amp;gt; rs.status()
{
&amp;quot;set&amp;quot; : &amp;quot;replica1&amp;quot;,
&amp;quot;date&amp;quot; : ISODate(&amp;quot;2015-08-21T10:15:11.851Z&amp;quot;),
&amp;quot;myState&amp;quot; : 1,
&amp;quot;members&amp;quot; : [
{
&amp;quot;_id&amp;quot; : 0,
&amp;quot;name&amp;quot; : &amp;quot;db1.cluster:27017&amp;quot;,
&amp;quot;health&amp;quot; : 1,
&amp;quot;state&amp;quot; : 1,
&amp;quot;stateStr&amp;quot; : &amp;quot;PRIMARY&amp;quot;,
&amp;quot;uptime&amp;quot; : 46815,
&amp;quot;optime&amp;quot; : Timestamp(1440152107, 1),
&amp;quot;optimeDate&amp;quot; : ISODate(&amp;quot;2015-08-21T10:15:07Z&amp;quot;),
&amp;quot;electionTime&amp;quot; : Timestamp(1440105297, 1),
&amp;quot;electionDate&amp;quot; : ISODate(&amp;quot;2015-08-20T21:14:57Z&amp;quot;),
&amp;quot;configVersion&amp;quot; : 4,
&amp;quot;self&amp;quot; : true
},
{
&amp;quot;_id&amp;quot; : 1,
&amp;quot;name&amp;quot; : &amp;quot;db2.cluster:27017&amp;quot;,
&amp;quot;health&amp;quot; : 1,
&amp;quot;state&amp;quot; : 2,
&amp;quot;stateStr&amp;quot; : &amp;quot;SECONDARY&amp;quot;,
&amp;quot;uptime&amp;quot; : 46761,
&amp;quot;optime&amp;quot; : Timestamp(1440152107, 1),
&amp;quot;optimeDate&amp;quot; : ISODate(&amp;quot;2015-08-21T10:15:07Z&amp;quot;),
&amp;quot;lastHeartbeat&amp;quot; : ISODate(&amp;quot;2015-08-21T10:15:09.856Z&amp;quot;),
&amp;quot;lastHeartbeatRecv&amp;quot; : ISODate(&amp;quot;2015-08-21T10:15:09.997Z&amp;quot;),
&amp;quot;pingMs&amp;quot; : 0,
&amp;quot;syncingTo&amp;quot; : &amp;quot;db1.cluster:27017&amp;quot;,
&amp;quot;configVersion&amp;quot; : 4
},
{
&amp;quot;_id&amp;quot; : 2,
&amp;quot;name&amp;quot; : &amp;quot;db3.cluster:27017&amp;quot;,
&amp;quot;health&amp;quot; : 1,
&amp;quot;state&amp;quot; : 2,
&amp;quot;stateStr&amp;quot; : &amp;quot;SECONDARY&amp;quot;,
&amp;quot;uptime&amp;quot; : 46550,
&amp;quot;optime&amp;quot; : Timestamp(1440152107, 1),
&amp;quot;optimeDate&amp;quot; : ISODate(&amp;quot;2015-08-21T10:15:07Z&amp;quot;),
&amp;quot;lastHeartbeat&amp;quot; : ISODate(&amp;quot;2015-08-21T10:15:09.856Z&amp;quot;),
&amp;quot;lastHeartbeatRecv&amp;quot; : ISODate(&amp;quot;2015-08-21T10:15:09.997Z&amp;quot;),
&amp;quot;pingMs&amp;quot; : 0,
&amp;quot;syncingTo&amp;quot; : &amp;quot;db1.cluster:27017&amp;quot;,
&amp;quot;configVersion&amp;quot; : 4
}
],
&amp;quot;ok&amp;quot; : 1
}
&lt;/code>&lt;/pre></description></item><item><title>Быстрая миграция MySQL на failover cluster</title><link>https://prudnitskiy.pro/post/2015-05-01-xtradb-quickstart/</link><pubDate>Fri, 01 May 2015 22:13:22 +0000</pubDate><guid>https://prudnitskiy.pro/post/2015-05-01-xtradb-quickstart/</guid><description>&lt;p>MySQL - одна из самых ходовых, распространенных и простых во внедрении СУБД. Этот СУБД использует, наверное, половина всех проектов веба. Исключительная простота установки и внедрения, распространенность, поддержка &amp;ldquo;из коробки&amp;rdquo; во всех ходовых языках программирования для веб (perl, PHP, ruby, python, JS/node). Из-за мнимой простоты внедрения на потенциальные проблемы внедрения внимания просто не обращают - 90% проектов не доживут до того момента, когда заботливо разложенные авторами MySQL грабли больно ударят по лбу.&lt;/p>
&lt;p>Одна из серьезных грабель MySQL - серьезные проблемы с производительностью и надежностью. Тюнинг MySQL сложен, так, как изначально MySQL задуман для быстрого внедрения в небольшом проекте. Кроме того, имея серьезный, высоконагруженный проект, хочется снизить риск отказа базы данных (согласно закону Паркинсона, все, что может сломаться - сломается, и частно - в самый неудачный момент). В данной статье я распишу, как мигрировать одиночный MySQL на кластер из трех равновесных машин (для надежности - отказ любого сервера не оставит вас без базы) с автоматическим распределением нагрузки.&lt;/p>
&lt;p>В данном примере участвуют три сервера:&lt;/p>
&lt;ul>
&lt;li>db1 (IP 10.10.171.2)&lt;/li>
&lt;li>db2 (IP 10.10.171.3)&lt;/li>
&lt;li>db3 (IP 10.10.171.4)&lt;/li>
&lt;/ul>
&lt;p>DB1 - &amp;ldquo;старый&amp;rdquo; сервер с обычным MySQL, данные с которого мигрируют в кластер. DB2 и DB3, соответственно - свежие сервера. В принципе, установка свежего кластера &amp;ldquo;с нуля&amp;rdquo; (без данных) - не будет отличаться практически ничем. Изначально статья ориентирована на Debian, но для CentOS сделаны необходимые отступления, благо отличий немного.&lt;/p>
&lt;h2 id="немного-истории" >Немного истории
&lt;span>
&lt;a href="#%d0%bd%d0%b5%d0%bc%d0%bd%d0%be%d0%b3%d0%be-%d0%b8%d1%81%d1%82%d0%be%d1%80%d0%b8%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Percona XtraDB - это ответвление (fork) изначального MySQL, созданного Монти Видениусом. В какой-то момент Видениус продал свой проект, и это сильно затормозило развитие проекта. Так, как проект обладал спорным качеством когда и был (с другой стороны) очень популярен - появилось огромное количество патчей, которые расширяли, углубляли и ускоряли кодовую базу. Самыми известным были набор патчей от google и набор патчей от Петра Зайцева. Последний создал компанию Percona, в рамках которой оптимизирует MySQL и консультирует пользователей этой системы. Он же выпускает свой форк MySQL, в котором собирает удачно работающие патчи. Как следствие - percona sql server с одной стороны надежнее, с другой - функциональнее, да и просто быстрее. В определенный момент был выпущен специальный дистрибутив XtraDB Cluster с набором библиотек Gallera Cluster - очень удачного и производительного решения для кластеризации MySQL&lt;/p>
&lt;h2 id="подготовка" >Подготовка
&lt;span>
&lt;a href="#%d0%bf%d0%be%d0%b4%d0%b3%d0%be%d1%82%d0%be%d0%b2%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>XtraDB cluster не входит в стандартные дистрибутивы ОС (ни для Debian, ни для CentOS), по этому, нужно добавить дистрибутивы&lt;/p>
&lt;p>Для Debian (все операции проводим от root):&lt;/p>
&lt;pre>&lt;code>#получаем ключи репозитория
apt-key adv --keyserver keys.gnupg.net --recv-keys 1C4CBDCDCD2EFD2A
#добавляем в файл /etc/apt/sources.list следующие строки:
deb http://repo.percona.com/apt VERSION main
deb-src http://repo.percona.com/apt VERSION main
#где VERSION - версия вашего debian:
# 6.0 - squeeze
# 7.0 - wheezy
# 8.0 - jessie
#обновляем кеш:
apt-get update
&lt;/code>&lt;/pre>
&lt;p>Для CentOS:&lt;/p>
&lt;pre>&lt;code>#добавляем репозиторий
yum install http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpm
#на всякий случай - обновляем кеш
yum clean all &amp;amp;&amp;amp; yum makecache
&lt;/code>&lt;/pre>
&lt;p>теперь установим xtradb.&lt;/p>
&lt;p>&lt;strong>В момент установки MySQL server будет удален из системы. Вы НЕ потеряете базы и данные в них, но сервис не будет работать до тех пор, пока вы не закончите настройку&lt;/strong>&lt;/p>
&lt;pre>&lt;code>#debian
apt-get install -y percona-xtradb-cluster-55
#centos
yum install -y Percona-XtraDB-Cluster-55
&lt;/code>&lt;/pre>
&lt;p>Чтобы члены кластера могли общаться друг с другом, на каждом сервере нужно разрешить доступ со всех членов кластера по портам &lt;em>4444&lt;/em> и &lt;em>4567&lt;/em>. Кроме того, со всех серверов, которые будут использовать кластер БД нужно разрешить доступ на порт &lt;em>3306&lt;/em> (штатный порт mysq) и &lt;em>9199&lt;/em> (об этом - далее).&lt;/p>
&lt;h2 id="настройка-кластера" >Настройка кластера
&lt;span>
&lt;a href="#%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b0-%d0%ba%d0%bb%d0%b0%d1%81%d1%82%d0%b5%d1%80%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Добавим в /etc/my.cnf (в debian он может называться /etc/mysql/my.cnf - если он уже есть - правим его!) следующие строки:&lt;/p>
&lt;pre>&lt;code>[mysqld]
#расположение физических файлов баз
datadir=/var/lib/mysql
#пользователь, от которого запускается сервер
user=mysql
#путь к библиотеке синхронизации, перед добавлением убедитесь, что файл по этому пути существует
wsrep_provider=/usr/lib64/libgalera_smm.so
#список IP всех членов кластера. Параметр идентичен на всех узлах кластера
wsrep_cluster_address=gcomm://10.10.171.2,10.10.171.3,10.10.171.4
binlog_format=ROW
default_storage_engine=InnoDB
innodb_autoinc_lock_mode=2
#IP адрес узла, на котором мы настраиваем кластер
wsrep_node_address=10.10.171.2
wsrep_sst_method=xtrabackup-v2
#имя кластера. Уникальное для инсталляции, но единое для всех узлов
wsrep_cluster_name=axsystems_xtradb_test
#имя пользователя и пароль для синхронизации
wsrep_sst_auth=&amp;quot;syncuser:Ttm3wsbPE72Km96R&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>запустим первый узел в кластере. Если вы мигрируете кластер с существующего MySQL на percona - это надо делать на старом сервере, где данные. Этот узел в кластере будет образцом - остальные заберут с него данные&lt;/p>
&lt;pre>&lt;code>/etc/init.d/mysql bootstrap-pxc
&lt;/code>&lt;/pre>
&lt;p>создадим пользователя для синхронизации:&lt;/p>
&lt;pre>&lt;code>mysql@db1&amp;gt; CREATE USER 'syncuser'@'localhost' IDENTIFIED BY 'Ttm3wsbPE72Km96R';
mysql@db1&amp;gt; GRANT RELOAD, LOCK TABLES, REPLICATION CLIENT ON *.* TO 'syncuser'@'localhost';
mysql@db1&amp;gt; FLUSH PRIVILEGES;
&lt;/code>&lt;/pre>
&lt;p>скопируем конфигурацию на DB2, и внесем необходимые изменения:&lt;/p>
&lt;pre>&lt;code>[mysqld]
#расположение физических файлов баз
datadir=/var/lib/mysql
#пользователь, от которого запускается сервер
user=mysql
#путь к библиотеке синхронизации, перед добавлением убедитесь, что файл по этому пути существует
wsrep_provider=/usr/lib64/libgalera_smm.so
#список IP всех членов кластера. Параметр идентичен на всех узлах кластера
wsrep_cluster_address=gcomm://10.10.171.2,10.10.171.3,10.10.171.4
binlog_format=ROW
default_storage_engine=InnoDB
innodb_autoinc_lock_mode=2
#IP адрес узла, на котором мы настраиваем кластер.
wsrep_node_address=10.10.171.3
wsrep_sst_method=xtrabackup-v2
#имя кластера. Уникальное для инсталляции, но единое для всех узлов
wsrep_cluster_name=axsystems_xtradb_test
#имя пользователя и пароль для синхронизации
wsrep_sst_auth=&amp;quot;syncuser:Ttm3wsbPE72Km96R&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Теперь подключим новый узел в кластер:&lt;/p>
&lt;pre>&lt;code>/etc/init.d/mysql start
&lt;/code>&lt;/pre>
&lt;p>Запускаться он будет долго, так как ему надо снять копию с работающего уже члена кластера. К слову - в этот момент кластер уже работает и ваши пользователи могут использовать базу.&lt;/p>
&lt;p>Как только mysql на втором сервере стартует успешно - можно проверить состояние кластера. Для этого в mysql консоли любого сервера пишем:&lt;/p>
&lt;pre>&lt;code>mysql&amp;gt; show status like 'wsrep%';
+----------------------------+--------------------------------------+
| Variable_name | Value |
+----------------------------+--------------------------------------+
| wsrep_local_state_uuid | c2883338-834d-11e2-0800-03c9c68e41ec |
[...]
| wsrep_local_state | 4 |
| wsrep_local_state_comment | Synced |
[...]
| wsrep_cluster_size | 2 |
| wsrep_cluster_status | Primary |
| wsrep_connected | ON |
[...]
| wsrep_ready | ON |
+----------------------------+--------------------------------------+
40 rows in set (0.01 sec)
&lt;/code>&lt;/pre>
&lt;p>как видно - status - synced, размер кластера - 2 (узла). Все работает, по аналогии добавляем третий узел (не забудьте поменять wsrep_node_address в настройках!)&lt;/p>
&lt;h2 id="failover-доступ" >failover-доступ
&lt;span>
&lt;a href="#failover-%d0%b4%d0%be%d1%81%d1%82%d1%83%d0%bf">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Большая часть современного ПО, работающая с MySQL, не может нормально обрабатывать несколько серверов. По этому мы будем использовать haproxy для распределения нагрузки. В этом примере haproxy ставится на каждый сервер, который использует mysql. HAProxy есть в базовом репозитории любого современного дистрибутива, так что просто ставим пакет:&lt;/p>
&lt;pre>&lt;code>#debian
apt-get install -y haproxy
#centos
yum install -y haproxy
&lt;/code>&lt;/pre>
&lt;p>Теперь настраиваем его. Пишем в конфигурацию /etc/haproxy/haproxy.cfg:&lt;/p>
&lt;pre>&lt;code>global
log 127.0.0.1 local2
chroot /var/lib/haproxy
pidfile /var/run/haproxy.pid
maxconn 4000
user haproxy
group haproxy
daemon
#stats socket /var/lib/haproxy/stats
defaults
log global
mode http
option tcplog
option dontlognull
retries 3
redispatch
maxconn 2000
contimeout 5000
clitimeout 50000
srvtimeout 50000
#webui со статистикой. Обязательно используйте пароль (или закройте доступ к порту)
listen stats 0.0.0.0:8086
mode http
stats enable
stats uri /
stats realm &amp;quot;balancer&amp;quot;
stats auth logan:q6SJYy5cB3KKy34z
#собственно, mysql кластер
listen mysql-cluster 0.0.0.0:3306
mode tcp
balance roundrobin
option httpchk
server db1 10.10.171.2:3306 check port 9199 inter 12000 rise 3 fall 3
server db2 10.10.171.3:3306 check port 9199 inter 12000 rise 3 fall 3
server db3 10.10.171.4:3306 check port 9199 inter 12000 rise 3 fall 3
&lt;/code>&lt;/pre>
&lt;p>Порт 9199 haproxy будет использовать, чтобы убедится, что член кластера работоспособен и функционирует, как нужно. Сам XtraDB кластер не ждет соединений на 9199 порту. Нам потребуется специальный сервис, который будет локально проверять работу xtradb-cluster сервера для HAProxy. Сервис проверки очень прост, это не демон, так что его будет запускать супердемон xinetd. Вернемся на db1. Для начала - установим xinetd:&lt;/p>
&lt;pre>&lt;code>#centos
yum install -y xinetd
#debian
apt-get install -y xinetd
&lt;/code>&lt;/pre>
&lt;p>Создадим там файл /etc/xinetd.d/mysqlchk со следующим содержимым:&lt;/p>
&lt;pre>&lt;code>service mysqlchk
{
disable = no
flags = REUSE
socket_type = stream
port = 9199
wait = no
user = nobody
server = /usr/bin/clustercheck
server_args = syncuser Ttm3wsbPE72Km96R 1 /var/tmp/mss.log 0 /etc/my.cnf
log_on_failure += USERID
only_from = 0.0.0.0/0
per_source = UNLIMITED
}
&lt;/code>&lt;/pre>
&lt;p>Немного подробностей о том, что тут написано. Главные настройки - это server_args. Они позиционные, так что очередность путать нельзя:&lt;/p>
&lt;ul>
&lt;li>имя пользователя для проверки. Нужны права CONNECT и REPLICATION CLIENT&lt;/li>
&lt;li>пароль&lt;/li>
&lt;li>отвечать, что сервер доступен, если он - донор (то есть остальные сервера в данный момент синхронизируются с него)&lt;/li>
&lt;li>путь к файлу журнала&lt;/li>
&lt;li>отвечать, что сервер &lt;em>не доступен&lt;/em>, если он сейчас readonly (синхронизируется или заблокирован). Если поставить 1 - haproxy будет считать сервер в статусе readonly доступным&lt;/li>
&lt;li>путь к my.cnf. В некоторых версиях debian он находится в /etc/mysql/my.cnf&lt;/li>
&lt;/ul>
&lt;p>пользователь и пароль в директиве server_args - из конфигурации mysql (выше). Обратите внимание на путь к my.cnf, в некоторых версиях debian он находится в /etc/mysql/my.cnf&lt;/p>
&lt;p>Так же нужно добавить следующую строку в /etc/services:&lt;/p>
&lt;pre>&lt;code>mysqlchk 9199/tcp #mysqlcheck
&lt;/code>&lt;/pre>
&lt;p>После этого можно перезапустить xinetd. Проверим, что сервис проверки работает, как задумано:&lt;/p>
&lt;pre>&lt;code>db1&amp;gt; telnet 127.0.0.1 9199
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
HTTP/1.1 200 OK
Content-Type: text/plain
Connection: close
Content-Length: 40
Percona XtraDB Cluster Node is synced.
Connection closed by foreign host.
&lt;/code>&lt;/pre>
&lt;p>Эту последовательность действий надо повторить на всех машинах - членах кластера.&lt;/p>
&lt;p>Теперь можно спокойно перезапустить haproxy, зайти на страницу статистики (в данном примере - http://[SERVER_IP]:8086/) и убедится, что haproxy видит все сервера кластера. После этого можно спокойно прописывать на сервере-пользователе БД локальный адрес 127.0.0.1, порт и все остальные настройки - без изменений - и теперь у вас есть отказоустойчивый кластер баз mysql&lt;/p>
&lt;h2 id="послесловие" >послесловие
&lt;span>
&lt;a href="#%d0%bf%d0%be%d1%81%d0%bb%d0%b5%d1%81%d0%bb%d0%be%d0%b2%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Не смотря на то, что данное решение кажется &amp;ldquo;идеальным решением&amp;rdquo;, у него есть и слабые стороны. На всякий случай, опишу их:&lt;/p>
&lt;ul>
&lt;li>Ведение кластеризации требует накладных расходов. Они очень незначительны (по моим замерам не получалось более 2% от базовой производительности сервера). Частично это нивелируется тем, что Percona быстрее, чем штатный MySQL, частично - тем, что мы используем балансировку нагрузки. Однако не упомянуть об этом было бы нечестно. Накладные расходы растут с увеличением количества узлов в кластере.&lt;/li>
&lt;li>Percona Xtradb cluster крайне плохо поддерживает таблицы типа MyISAM. Об этом даже пишут в официальной документации. Если вам нужен MyISAM - я очень не рекомендую использовать xtradb cluster&lt;/li>
&lt;li>Данная конфигурация отвечает исключительно за репликацию, шардирование (разделение данных между серверами в зависимости от содержимого, например - пользователи с четным ID - на правый сервер, с нечетным - на левый) - тут отсутствует.&lt;/li>
&lt;/ul>
&lt;h3 id="в-случае-аварии" >в случае аварии
&lt;span>
&lt;a href="#%d0%b2-%d1%81%d0%bb%d1%83%d1%87%d0%b0%d0%b5-%d0%b0%d0%b2%d0%b0%d1%80%d0%b8%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Если что-то из описанного в статье работает не так, как описано (или не работает вовсе) - попробуйте проверить ваши последние шаги. Самые частые проблемы, с которыми сталкивался я, это:&lt;/p>
&lt;ul>
&lt;li>Закрытые порты не дают узлам кластера общаться между собой (4444 используется для общения и координации, 4567 - для передачи данных свеже добавленным узлам).&lt;/li>
&lt;li>Проблемы с линковкой (ошибка xtrabackup is exited: Perl:DBD is not installed, при этом Perl:DBD в системе есть). Это решается простым удалением всех пакетов, связанных с MySQL и установкой XtraDB cluster заново.&lt;/li>
&lt;li>Подавляющее большинство ошибок можно диагностировать чтением log-файла. /var/log/mysql.log (для debian) или /var/log/mysqld.log (centos) - ваш друг.&lt;/li>
&lt;/ul></description></item><item><title>Мигрируем Debian на softraid без потери данных</title><link>https://prudnitskiy.pro/post/2014-12-25-debian-to-mdraid/</link><pubDate>Thu, 25 Dec 2014 12:23:35 +0000</pubDate><guid>https://prudnitskiy.pro/post/2014-12-25-debian-to-mdraid/</guid><description>&lt;p>Современные жесткие диски - чудо инженерии и техники. Пластины из магниево-алюминиевого сплава несутся со скоростью 120 оборотов в секунду, при этом считывающую голову от поверхности диска отделяет расстояние в 1/10 толщины человеческого волоса. Сама голова перемещается в любую точку всего за 2мс, что вызывает боковую перегрузку в фантастические 550G. Современные диски обладают впечатляющим объемом, большой линейной скоростью (что на чтение, что на запись) и минимальной задержкой поиска. И платят они за это (кроме цены) серьезным падением надежности. Старенькие Seagate Barracude и Quantum Fireball 6-10 гигабайт объемом без каких-либо нареканий жили десятилетиями, еще более старинные IBM на сотни мегабайт можно было безопасно вскрыть и закрыть в домашних условиях без специальной подготовки. Современные модели крайне чувствительны к вибрациям, тряске, углу наклона, удару и даже шуму (sic!). Средний срок жизни современного террабайтника - три года, если он эксплуатируется не слишком активно. Диски для серверов и NAS живут год-два. Если раньше RAID считался дорогой экзотикой серверного мира (по типу SCSI), то сейчас программный soft-raid - абсолютная необходимость, без которого сервер просто нельзя устанавливать.&lt;/p>
&lt;p>В данной статье я расскажу, как мигрировать Debian Linux (в статье используется 7 версия, но с 6 тоже проблем не будет) с одного диска на зеркало из двух. В принципе, методика миграции универсальна, и Ubuntu или CentOS можно мигрировать точно так же. В качестве RAID будем использовать его программную реализацию (mdraid), что позволит сэкономить на железе. В общем случае использование mdraid оправдано, если у вас не очень много дисков (очень много - это больше 10), не используется сложный raid-алгоритм (RAID5/RAID6 и их потомки) и нет большой нагрузки на IOT. Если top показывает, что IO wait ушел куда-то к 50% - время подумать о покупке аппаратного решения.&lt;/p>
&lt;p>В моем примере используется стандартная разбивка от Неметт:&lt;/p>
&lt;pre>&lt;code>/dev/sda5 473M 148M 302M 33% /
/dev/sda1 472M 30M 418M 7% /boot
/dev/sda6 949M 33M 917M 4% /tmp
/dev/sda7 5.5G 829M 4.5G 16% /usr
/dev/sda8 448G 674M 425G 1% /var
&lt;/code>&lt;/pre>
&lt;p>&lt;em>Внимание! FreeBSD мигрируется по иной схеме, так как во FreeBSD нет mdraid, вместо него используется GEOM. Не пытайтесь адаптировать данную статью для FreeBSD! Если вам нужна статья по миграции FreeBSD - напишите в комментариях, я напишу такую инструкцию отдельно&lt;/em>
&lt;a name="more">&lt;/a>&lt;/p>
&lt;h2 id="подготовка-и-миграция-данных" >Подготовка и миграция данных
&lt;span>
&lt;a href="#%d0%bf%d0%be%d0%b4%d0%b3%d0%be%d1%82%d0%be%d0%b2%d0%ba%d0%b0-%d0%b8-%d0%bc%d0%b8%d0%b3%d1%80%d0%b0%d1%86%d0%b8%d1%8f-%d0%b4%d0%b0%d0%bd%d0%bd%d1%8b%d1%85">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>В данной статье я предполагаю, что у нас два одинаковых диска, /dev/sda - это реальный, а /dev/sdb - свеже установленный. Все действия производятся от root.&lt;/p>
&lt;p>Для начала нам потребуется немного ПО:&lt;/p>
&lt;pre>&lt;code>apt-get install mdmadm rsync screen
&lt;/code>&lt;/pre>
&lt;p>screen в данной ситуации ставится, чтобы избежать проблем, если во время копирования данных поломается сеть. Если копируете локально (с консоли) - он вам не нужен&lt;/p>
&lt;p>проверим геометрию:&lt;/p>
&lt;pre>&lt;code>#sfdisk -d /dev/sda
Warning: extended partition does not start at a cylinder boundary.
DOS and Linux will interpret the contents differently.
# partition table of /dev/sda
unit: sectors
/dev/sda1 : start= 2048, size= 997376, Id=83, bootable
/dev/sda2 : start= 999424, size= 1000000, Id=83
/dev/sda3 : start= 2000894, size=974770178, Id= 5
/dev/sda4 : start= 0, size= 0, Id= 0
/dev/sda5 : start= 2000896, size= 7811072, Id=82
/dev/sda6 : start= 9814016, size= 1951744, Id=83
/dev/sda7 : start= 11767808, size= 11716608, Id=83
/dev/sda8 : start= 23486464, size=953284608, Id=83
&lt;/code>&lt;/pre>
&lt;p>Warning можно игнорировать. На данном этапе рекомендую проверить, что на диске-получателе геометрии нет. Если там есть данные, то при копировании геометрии они умрут, и шансов восстановить их без скальпеля не будет:&lt;/p>
&lt;pre>&lt;code>sfdisk -d /dev/sdb
Warning: extended partition does not start at a cylinder boundary.
DOS and Linux will interpret the contents differently.
# partition table of /dev/sda
unit: sectors
&lt;/code>&lt;/pre>
&lt;p>Копируем геометрию:&lt;/p>
&lt;pre>&lt;code>sfdisk -d /dev/sda | sfdisk /dev/sdb
&lt;/code>&lt;/pre>
&lt;p>Лирическое отступление. Если у вас большие диски и используется GPT-таблица - sfdisk вам не поможет, потребуется установить программу &lt;code>gdisk&lt;/code> и переносить уже ей:&lt;/p>
&lt;pre>&lt;code>#переносим раздел
sgdisk -R /dev/sdb /dev/sda
#рандомизируем GUID
sgdisk -G /dev/sdb
&lt;/code>&lt;/pre>
&lt;p>Теперь у нас есть два идентичных по разбивке диска. Соберем из второго диска RAID. В нашей ситуации это зеркало (raid-1), по этому RAID будет работать, даже если в массиве остался один диск (так как по идеологии RAID-1 диски совершенно равноправны). Мы создадим по одному raid на каждый раздел диска, включая своп (это гарантирует, что система нормально запустится, если любой диск выйдет из строя). Так как в нормальном случае при сборке зеркала надо указывать два диска, вместо отсутствующего мы будем использовать ключевое слово missing&lt;/p>
&lt;p>Важное примечание. GRUB первой версии не может загружаться с новой версии mdraid-массива. Специально для boot-раздела нужно указать старую версию дискового массива (ключом &amp;ndash;metadata=0.90). В моем примере это md0:&lt;/p>
&lt;pre>&lt;code>mdadm --create /dev/md0 --level 1 --raid-devices=2 missing /dev/sdb1 --metadata=0.90
mdadm --create /dev/md1 --level 1 --raid-devices=2 missing /dev/sdb2
mdadm --create /dev/md2 --level 1 --raid-devices=2 missing /dev/sdb5
mdadm --create /dev/md3 --level 1 --raid-devices=2 missing /dev/sdb6
mdadm --create /dev/md4 --level 1 --raid-devices=2 missing /dev/sdb7
mdadm --create /dev/md4 --level 1 --raid-devices=2 missing /dev/sdb8
&lt;/code>&lt;/pre>
&lt;p>Массив собрался, проверим:&lt;/p>
&lt;pre>&lt;code>cat /proc/mdstat
Personalities : [raid1]
md5 : active raid1 sdb8[1]
476511040 blocks super 1.2 [2/1] [_U]
md4 : active raid1 sdb7[1]
5854144 blocks super 1.2 [2/1] [_U]
md3 : active raid1 sdb6[1]
975296 blocks super 1.2 [2/1] [_U]
md2 : active raid1 sdb5[1]
3903424 blocks super 1.2 [2/1] [_U]
md1 : active raid1 sdb2[1]
499712 blocks super 1.2 [2/1] [_U]
md0 : active raid1 sdb1[1]
499712 blocks [2/1] [_U]
&lt;/code>&lt;/pre>
&lt;p>Выглядит вроде норм (обратите внимание на md0!), можно форматировать наши новые разделы. Я очень рекомендую использовать метки (label) при форматировании - это здорово облегчает жизнь при проблемах. Метка выставляется ключем -L&lt;/p>
&lt;pre>&lt;code>#так, как у нас GRUB1, который не умеет работать с ext4 - загрузочный раздел поставим на ext3
mkfs.ext3 /dev/md0 -L /boot
[...]
mkfs.ext4 /dev/md1 -L /
[...]
mkswap /dev/md2 -L swap
[...]
mkfs.xfs /dev/md3 -L /tmp
[...]
mkfs.ext4 /dev/md4 -L /usr
[...]
mkfs.ext4 /dev/md5 -L /var
&lt;/code>&lt;/pre>
&lt;p>После того, как все отформатируется, можно монтировать:&lt;/p>
&lt;pre>&lt;code>mount /dev/md1 /mount
#создадим каталоги для виртуальных систем, которые создаются при запуске ОС
mkdir /mount/dev mount/proc /mount/sys
#теперь создадим пути для монтирования наших разделов
mkdir /mount/boot /mount/tmp /mount/usr /mount/var
# и смонтируем необходимые для миграции каталоги
mount /dev/md0 /mount/boot
mount /dev/md4 /mount/usr
mount /dev/md5 /mount/var
&lt;/code>&lt;/pre>
&lt;p>Теперь у нас есть две файловых системы: реальная, с которой сервер сейчас загружен и &amp;ldquo;пустая&amp;rdquo;, структурно повторяющая реальную. И во вторую можно копировать данные из первой. Процедура длительная, крайне рекомендую проводить ее через screen. Перед началом рекомендуется остановить все сервисы, которые активно пишут в жесткий диск (например, mysql) - иначе есть риск получить неконсистентность данных:&lt;/p>
&lt;pre>&lt;code>#переключаемся в screen
screen -dR
#начинаем копировать. Нужно указать в качестве исключений при копирвании служебные
#файловые системы (proc, sys, dev, selinux, если он есть)
#и служебные каталоги самих файлсистем. в ext3/ext4 таким является lost+found,
#это учет inode-сирот и копировать его бессмысленно
#и, разумеется, надо исключить каталог, в который мы копируем - иначе будет петля
rsync -rahzP --exclude=/dev --exclude=/proc --exclude=/sys \
--exclude=/lost+found --exclude=/boot/lost+found --exclude=/var/lost+found --exclude=/usr/lost+found \
--exclude=/mount / /mount/
&lt;/code>&lt;/pre>
&lt;h3 id="переключение-на-новый-диск" >Переключение на новый диск
&lt;span>
&lt;a href="#%d0%bf%d0%b5%d1%80%d0%b5%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5-%d0%bd%d0%b0-%d0%bd%d0%be%d0%b2%d1%8b%d0%b9-%d0%b4%d0%b8%d1%81%d0%ba">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Теперь нам нужно установить загрузчик на второй диск. Прелесть загрузчика в том, что он живет в загрузочной области, которая не отображается на файловую систему, а значит, копировать его &amp;ldquo;в лоб&amp;rdquo; - бессмысленно. Загрузчик ставится на диск, а не на раздел. Если у вас 10 дисков - ставить надо на все, которые в теории должны быть загрузочными&lt;/p>
&lt;pre>&lt;code>grub-install /dev/sdb
&lt;/code>&lt;/pre>
&lt;p>После переноса данных начинается самое сложное - правка путей. В старых версиях linux адресация дисков была относительной, master в канале ide0 назывался hda, slave ide 1 - hde (hdd был зарезервирован). Это вызывало интересные коллизии в SCSI и SATA, где адресация внутри шины не абсолютна, и после перезагрузки диски могли легко поменяется местами - просто потому, что кто-то очнулся раньше. Поэтому в новых версиях введен механизм block uuid, у каждого блочного устройства есть абсолютно уникальный идентификатор, и обращения к дискам идут строго по нему.&lt;/p>
&lt;p>Нам нужно получить список всех блочных идентификаторов, их выдает команда blkid:&lt;/p>
&lt;pre>&lt;code>blkid
/dev/sda5: UUID=&amp;quot;b7b1edbd-308d-489f-8289-43126f1a9b70&amp;quot; TYPE=&amp;quot;swap&amp;quot;
/dev/sda1: UUID=&amp;quot;1b2e76b3-ffc9-4846-a210-02ed19373976&amp;quot; TYPE=&amp;quot;ext3&amp;quot; SEC_TYPE=&amp;quot;ext2&amp;quot; LABEL=&amp;quot;/boot&amp;quot;
/dev/sda2: UUID=&amp;quot;07ca4a9e-4262-44d4-a8e4-31ae37306003&amp;quot; TYPE=&amp;quot;ext4&amp;quot;
/dev/sda6: UUID=&amp;quot;b7ab9817-7e56-455c-99f6-9c0d9a8e23d6&amp;quot; TYPE=&amp;quot;xfs&amp;quot;
/dev/sda7: UUID=&amp;quot;8e6777bf-a565-4983-9851-ff358a1d0da3&amp;quot; TYPE=&amp;quot;ext4&amp;quot;
/dev/sda8: UUID=&amp;quot;591e3e16-db6d-4caa-87d3-f0d3b8848b98&amp;quot; TYPE=&amp;quot;ext4&amp;quot;
/dev/sdb1: UUID=&amp;quot;a96db57d-5724-63e6-769a-12bac1c5caa9&amp;quot; TYPE=&amp;quot;linux_raid_member&amp;quot;
/dev/sdb2: UUID=&amp;quot;0b338f2d-c26b-d8c0-f8c4-5384672d5ebb&amp;quot; UUID_SUB=&amp;quot;f459ad18-3892-50ff-b2f0-d9cec2490d65&amp;quot; LABEL=&amp;quot;ffs:1&amp;quot; TYPE=&amp;quot;linux_raid_member&amp;quot;
/dev/sdb5: UUID=&amp;quot;5438f240-b120-69f1-0eb9-fd89f7deb762&amp;quot; UUID_SUB=&amp;quot;ff19fb3c-c5ce-ad49-2825-28cb490c98d9&amp;quot; LABEL=&amp;quot;ffs:2&amp;quot; TYPE=&amp;quot;linux_raid_member&amp;quot;
/dev/sdb6: UUID=&amp;quot;a769e010-9f0e-0861-c1fc-d120e436004a&amp;quot; UUID_SUB=&amp;quot;27db9864-f01a-5dac-9e26-ff75a8e5ccb9&amp;quot; LABEL=&amp;quot;ffs:3&amp;quot; TYPE=&amp;quot;linux_raid_member&amp;quot;
/dev/sdb7: UUID=&amp;quot;40aef537-e1b0-de63-8412-2c0d49e8a73c&amp;quot; UUID_SUB=&amp;quot;3bb89ea7-6b8b-7952-98d8-1fb080c548f4&amp;quot; LABEL=&amp;quot;ffs:4&amp;quot; TYPE=&amp;quot;linux_raid_member&amp;quot;
/dev/sdb8: UUID=&amp;quot;d1e75e0e-5434-b700-dd83-a571d7b5ae3b&amp;quot; UUID_SUB=&amp;quot;f7602eb7-2169-8fed-e8fb-bc8feb04b431&amp;quot; LABEL=&amp;quot;ffs:5&amp;quot; TYPE=&amp;quot;linux_raid_member&amp;quot;
/dev/md0: LABEL=&amp;quot;/boot&amp;quot; UUID=&amp;quot;9f2ec8da-9f6c-417c-81c2-39fd2e1b8dd9&amp;quot; SEC_TYPE=&amp;quot;ext2&amp;quot; TYPE=&amp;quot;ext3&amp;quot;
/dev/md1: LABEL=&amp;quot;/&amp;quot; UUID=&amp;quot;9441c57c-c88f-4476-8e8d-b9a281292170&amp;quot; TYPE=&amp;quot;ext4&amp;quot;
/dev/md2: LABEL=&amp;quot;swap&amp;quot; UUID=&amp;quot;bb4a83e7-1e21-434c-9d27-2b53a9431bdb&amp;quot; TYPE=&amp;quot;swap&amp;quot;
/dev/md3: LABEL=&amp;quot;/tmp&amp;quot; UUID=&amp;quot;5f5b2216-3766-4b00-a8a7-0bd1330c8393&amp;quot; TYPE=&amp;quot;xfs&amp;quot;
/dev/md4: LABEL=&amp;quot;/usr&amp;quot; UUID=&amp;quot;f9d85aee-3ef2-409d-8406-351e0dfd81ab&amp;quot; TYPE=&amp;quot;ext4&amp;quot;
/dev/md5: LABEL=&amp;quot;/var&amp;quot; UUID=&amp;quot;7a36dd15-2a40-475e-b3e1-257569ca2958&amp;quot; TYPE=&amp;quot;ext4&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Много-много страшного текста (а я говорил, что label - очень помогает!). Теперь нам нужно поменять одни UID на другие. Менять можно в любом текстовом редакторе. Главное их не перепутать. Я рекомендую скопировать UID-ы куда-нибудь примерно в таком виде:&lt;/p>
&lt;pre>&lt;code>1b2e76b3-ffc9-4846-a210-02ed19373976 -&amp;gt; 9f2ec8da-9f6c-417c-81c2-39fd2e1b8dd9
07ca4a9e-4262-44d4-a8e4-31ae37306003 -&amp;gt; 9441c57c-c88f-4476-8e8d-b9a281292170
&lt;/code>&lt;/pre>
&lt;p>Менять UUID надо в двух местах:&lt;/p>
&lt;ul>
&lt;li>/mount/etc/fstab - список файловых систем. Там нужно поменять все UID&lt;/li>
&lt;li>/mount/boot/grub/grub.cfg - конфигурация загрузчика. Тут будут только UUID разделов /boot и /, но будет их, в отличие от fstab, несколько&lt;/li>
&lt;/ul>
&lt;p>Если у вас нет доступа к BIOS и вы не можете поменять приоритет загрузки дисков, новый конфиг grub из /mount/boot/grub/grub.cfg нужно скопировать на место старого (/boot/grub/grub.cfg).&lt;/p>
&lt;p>Данные скопированы, и теперь можно спокойно перезагружать сервер:&lt;/p>
&lt;pre>&lt;code>sync
reboot
&lt;/code>&lt;/pre>
&lt;p>После того, как сервер вновь станет отвечать на внешние раздражители, проверим, что он загрузился с новых дисков:&lt;/p>
&lt;pre>&lt;code>#mount
/dev/md0 on /boot type ext3 (rw,relatime,errors=continue,user_xattr,acl,barrier=1,data=ordered)
/dev/md3 on /tmp type xfs (rw,relatime,attr2,delaylog,noquota)
/dev/md4 on /usr type ext4 (rw,relatime,user_xattr,barrier=1,data=ordered)
/dev/md5 on /var type ext4 (rw,relatime,user_xattr,barrier=1,data=ordered)
&lt;/code>&lt;/pre>
&lt;p>Теперь осталось только проверить, что данные не потерялись по дороге и можно добавлять старый диск в новый RAID (напомню, сейчас наши массивы состоят из одного диска каждый, и RAID, строго говоря, не являются). До добавления старого диска мы еще можем обращаться к данным на нем, так убедитесь, что все данные переехали на новый диск и ничего не забыто. Шансов восстановить данные с диска, добавленного в RAID - нулевые:&lt;/p>
&lt;pre>&lt;code>mdadm /dev/md0 --add /dev/sda1
mdadm /dev/md1 --add /dev/sda2
mdadm /dev/md2 --add /dev/sda5
mdadm /dev/md3 --add /dev/sda6
mdadm /dev/md4 --add /dev/sda7
mdadm /dev/md5 --add /dev/sda8
&lt;/code>&lt;/pre>
&lt;p>Теперь остается только дождаться окончания синхронизации массива, а посмотреть состояние можно так:&lt;/p>
&lt;pre>&lt;code>cat /proc/mdstat
&lt;/code>&lt;/pre></description></item><item><title>Мониторинг задержек при помощи smokeping</title><link>https://prudnitskiy.pro/post/2014-10-24-smokeping/</link><pubDate>Fri, 24 Oct 2014 10:48:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2014-10-24-smokeping/</guid><description>&lt;p>Как-то мне (в очередной раз) потребовалось настроить мониторинг доступности клиентского сервиса через интернет. В процессе настройки я обнаружил, что не смотря на существование очень простого, понятного и удобного инструмента под названием SmokePing, по нему практически нет документации на русском (а документация на английском очень ограничена и запрятана в странном месте). Поэтому я решил написать эту небольшую вводную статью.&lt;/p>
&lt;h2 id="о-чем-речь" >О чем речь
&lt;span>
&lt;a href="#%d0%be-%d1%87%d0%b5%d0%bc-%d1%80%d0%b5%d1%87%d1%8c">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>SmokePing - инструмент для мониторинга задержки во времени ответа. Изначально был написан для проверки качества сети (то есть - для провайдеров) - скачки в задержках и (особенно) потери пакетов демонстрируют потенциальные перебои в работе и вообще ничего хорошего означать не могут. В дальнейшем автор несколько расширил инструмент, и теперь он может следить за задержками, в принципе, в чем угодно, что может быть полезно разработчикам и админам высконагруженного проекта, который должен отвечать за заданный промежуток времени. Автор инструмента - широко известный в сисадминских кругах Тоби Этикер, тот самый, что придумал RRD (и следом - RRDTool), а затем - MRTG. Эти два инструмента используются, наверное, в 90% всех провайдерах услуг связи.&lt;/p>
&lt;h2 id="терминология-и-схема-работы" >Терминология и схема работы
&lt;span>
&lt;a href="#%d1%82%d0%b5%d1%80%d0%bc%d0%b8%d0%bd%d0%be%d0%bb%d0%be%d0%b3%d0%b8%d1%8f-%d0%b8-%d1%81%d1%85%d0%b5%d0%bc%d0%b0-%d1%80%d0%b0%d0%b1%d0%be%d1%82%d1%8b">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Сам по себе SmokePing устроен очень просто, если не сказать - примитивно. Изначально стартует один демон, который управляет всеми процедурами проверок. Для каждого способа проверки (название в терминах SP - Probe) стартует своя копия демона, которая отвечает за проверки именно этим способом. Раз в 5 минут демон проводит серию измерений и записывает результаты. Все результаты в &amp;ldquo;сыром виде&amp;rdquo; записываются в стандартный RRD (по одной RRD на каждый объект). Также в комплект поставки входит вебморда, которая отвечает за рисование графиков. Графики строго одиночные (комбинировать задержку с трех хостов на один график не дадут), но их можно масштабировать и двигаться в них по времени. Веб-интерфейс использует старый-добрый CGI, и вся эта конструкция написана на perl. SmokePing позволяет проводить измерения с нескольких разных машин (в терминах SP - Slave), но данные сгружать в одну точку для анализа. На борту имеется служба уведомлений, но все-таки это &amp;lsquo;не мониторинг&amp;rsquo;, это именно статистика качества ответов (как быстро пришел ответ и какой разлет в показателях).&lt;/p>
&lt;h2 id="установка" >Установка
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>В данном примере я рассматриваю Debian Linux, но SmokePing уверенно работает на практически любой ОС (требуется perl, librrd, желательно - fping, curl и dig).
Установка стандартная:&lt;/p>
&lt;pre>&lt;code>apt-get install smokeping
&lt;/code>&lt;/pre>
&lt;p>Если у вас еще нет вебсервера, нужен соответствующий, с поддержкой CGI. Я использовал lighttpd:&lt;/p>
&lt;pre>&lt;code>apt-get install lighttpd
&lt;/code>&lt;/pre>
&lt;p>Все настройки находятся в /etc/smokeping/config.d/&lt;/p>
&lt;ul>
&lt;li>Alerts - уведомления&lt;/li>
&lt;li>Database - место хранения данных. Трогать аккуратно!&lt;/li>
&lt;li>General - основные&lt;/li>
&lt;li>Presentation - внешний вид веб-морды (путь к шаблону веб-страницы, размеры графиков по умолчанию и тому подобное)&lt;/li>
&lt;li>Probes - способы мониторинга, подробнее ниже&lt;/li>
&lt;li>Slaves - дочерние зонды, которые позволяют мониторить загрузку из нескольких точек&lt;/li>
&lt;li>Targets - цели, которые мы мониторим&lt;/li>
&lt;/ul>
&lt;p>Сначала настроим основы. Самая важная настройка - предпоследняя. Если неправильно настроить URL - картинок с графиком не будет:&lt;/p>
&lt;pre>&lt;code>#/etc/smokeping/config.d/General
*** General ***
owner = Paul 'Logan' Rudnitskiy
contact = admin@DOMAIN
mailhost = mail.DOMAIN
cgiurl = httpa://monitoring.domain/smokeping/smokeping.cgi
syslogfacility = local0
&lt;/code>&lt;/pre>
&lt;p>Теперь настроим зонды (способы проверки):&lt;/p>
&lt;pre>&lt;code>#/etc/smokeping/config.d/Probes
*** Probes ***
+ FPing
binary = /usr/bin/fping
++ FPingNormal
offset = 0%
++ FPingLarge
packetsize = 5000
offset = 50%
&lt;/code>&lt;/pre>
&lt;p>В данном случае мы настроили две способа проверки одним зондом (FPing). Мы заранее определили путь к программе, которая проводит проверку (/usr/bin/fping), и можем проверять простыми пакетами или большими. графа offset нужна, чтобы не проверять один хост одновременно обычными и большими пакетами (это искажает результаты). Offset всегда в процентах и считается от начала цикла проверки.&lt;/p>
&lt;p>Добавим еще способов:&lt;/p>
&lt;pre>&lt;code>#/etc/smokeping/config.d/Probes
[...]
+ FPing6
binary = /usr/bin/fping6
+ DNS
binary = /usr/bin/dig
lookup = name.example
pings = 3
step = 60
offset = 10%
timeout = 2
+ Curl
binary = /usr/bin/curl
step = 60
timeout = 5
urlformat = http://%host%/
&lt;/code>&lt;/pre>
&lt;p>Теперь поподробнее, что тут появилось:&lt;/p>
&lt;ul>
&lt;li>pings - количество запросов за цикл проверки. По умолчанию 5, но это число можно менять&lt;/li>
&lt;li>step - длительность цикла проверки. Все проверки должны быть завершены за один цикл и записаны в базу. По умолчанию - 300sec (5 минуту)&lt;/li>
&lt;li>offset нам уже знаком&lt;/li>
&lt;li>timeout - тайм-аут в секундах&lt;/li>
&lt;li>lookup - специфичный параметр для плагина dig - какое имя нужно запрашивать на DNS&lt;/li>
&lt;li>urlformat - специфичный параметр для плагина curl. Подходит любой URL, который curl может обработать&lt;/li>
&lt;/ul>
&lt;p>Важно! Если вы меняете pings или step - вам прийдется пересоздать RRD-базу, так как изменить формат хранения данных в базе невозможно - он задается единожды и не может быть отредактирован. Соответственно, при изменении этой настройки вы потеряете статистику.&lt;/p>
&lt;p>Вооружившись probe-ами, создадим цели мониторинга:&lt;/p>
&lt;pre>&lt;code>#/etc/smokeping/config.d/Targets
*** Targets ***
#зонд из прошлого конфига
probe = FPingNormal
#верхушка меню. Меню поддерживают иерархию, очень удобно
+ network
menu = Network reachability
title = Network reachability (ICMP)
++ work
menu = Work
title = Work
+++ web1
menu = web1
title = web1
host = 10.0.0.1
+++ web2
menu = web2
title = web2
host = 10.0.0.2
#здесь мы будем мониторить время ответа веб-сервера
#зонд можно задать как для пункта меню (он наследуется по иерархии)
#и даже для отдельного хоста
#но нужно сначала задать зонд, и только потом - его настройки.
+ WEB
menu = web
title = web
probe = Curl
++ web1
menu = web1
title = web1
host = 10.0.0.1
# а это уже меню, потому, что мы проверяем не только HTTP
++ web2
menu = web2
title = web2
+++ web2www
menu = www
title = www
host = 10.0.0.2
+++ web2ftp
menu = www
title = www
host = 10.0.0.2
urlformat = ftp://%host%/pub/
&lt;/code>&lt;/pre>
&lt;p>Можно запускать smokeping, он уже будет собирать данные и сохранять статистику. Теперь хорошо бы на нее посмотреть. Настроим Lighttpd:&lt;/p>
&lt;pre>&lt;code>#/etc/lighttpd/conf-enabled/10-cgi.conf
server.modules += ( &amp;quot;mod_cgi&amp;quot; )
server.modules += ( &amp;quot;mod_setenv&amp;quot; )
$HTTP[&amp;quot;url&amp;quot;] =~ &amp;quot;^/smokeping&amp;quot; {
alias.url = (
&amp;quot;/smokeping/smokeping.cgi&amp;quot; =&amp;gt; &amp;quot;/usr/lib/cgi-bin/smokeping.cgi&amp;quot;
&amp;quot;/smokeping&amp;quot; =&amp;gt; &amp;quot;/usr/share/smokeping/www/&amp;quot;,
)
server.indexfiles = (&amp;quot;smokeping.cgi&amp;quot;)
#чтобы статистика была доступна только тем, кому можно ее смореть:
auth.backend = &amp;quot;htpasswd&amp;quot;
auth.backend.htpasswd.userfile = &amp;quot;/var/www/.htpasswd&amp;quot;
auth.require = ( &amp;quot;&amp;quot; =&amp;gt; (
&amp;quot;method&amp;quot; =&amp;gt; &amp;quot;basic&amp;quot;,
&amp;quot;realm&amp;quot; =&amp;gt; &amp;quot;icinga&amp;quot;,
&amp;quot;require&amp;quot; =&amp;gt; &amp;quot;valid-user&amp;quot;
) )
}
&lt;/code>&lt;/pre>
&lt;p>После перезапуска lighttpd можно открывать &lt;a href="http://monitoring.domain/smokeping">http://monitoring.domain/smokeping&lt;/a> и смотреть графики. В идеале надо подождать минут 30 (хотя бы), чтобы smping успел наполнить базу хоть какой-то статистикой.&lt;/p>
&lt;p>Вот так выглядит нормальный график:&lt;/p>
&lt;p>&lt;img src="https://prudnitskiy.pro/media/uploads/smokeping2.png?1" alt="График">&lt;/p>
&lt;p>А это график -курильщика- сервера, которому явно нехорошо&lt;/p>
&lt;p>&lt;img src="https://prudnitskiy.pro/media/uploads/smokeping3.png?1" alt="График курильщика">&lt;/p></description></item><item><title>Коротко о безопасности в сети или краткое руководство для практикующих параноиков</title><link>https://prudnitskiy.pro/post/2014-09-17-practical-paranoia/</link><pubDate>Wed, 17 Sep 2014 16:08:23 +0000</pubDate><guid>https://prudnitskiy.pro/post/2014-09-17-practical-paranoia/</guid><description>&lt;p>Кто-то, возможно, не поверит, но написать эту статью я собирался довольно давно. Недавние события (утечка личных фотографий звезд и 7 миллионов почтовых паролей от google и yandex) не была поводом, но подтолкнула меня к перу. Безопасности в интернете (и вообще - в ИТ) обычный пользователь уделяет на диво мало внимания, не в пример безопасности физической. Кто-то не хочет ничего делать потому, что лень, кто-то считает, что ему “как честному человеку скрывать нечего” (да-да, я встречал такой лозунг неоднократно, особенно, когда вводили цензуру в интернете на территории 1/5 части суши).&lt;/p>
&lt;p>Некоторые (и довольно многие!) считают, что связаные с ИТ опасности эфемерны. Ну - украдут анкету во Вконтакте - зарегистрируюсь по-новой, думают они. Но. Подавляющее большинство пользователей не представляет, насколько чревато на самом деле халатное отношение к безопасности, как сильно и как больно это может ударить. Так, как я постоянно сталкиваюсь с неприятными последствиями подобных ситуаций - я и решил написать краткое введение. Ниже я расскажу, как много данных оставляет пользователь в мире, как эти данные могут быть использованы и что с этим всем можно сделать.&lt;/p>
&lt;h2 id="откуда-берутся-данные" >Откуда берутся данные?
&lt;span>
&lt;a href="#%d0%be%d1%82%d0%ba%d1%83%d0%b4%d0%b0-%d0%b1%d0%b5%d1%80%d1%83%d1%82%d1%81%d1%8f-%d0%b4%d0%b0%d0%bd%d0%bd%d1%8b%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Удивительный факт номер один - в интернете ‘очень’ много информации о пользователе. Удивительный факт номер два - по большей части информацию эту пользователи туда добавляют добровольно. Условно все данные о пользователе в интернете можно поделить на три группы:&lt;/p>
&lt;ul>
&lt;li>открытые - их пользователь добавляет сам (например - твиты или фоточки в фейсбучек). Эти данные доступны публично без специальных мер.&lt;/li>
&lt;li>скрытые - их исподволь собирают разные сервисы для личных нехороших целей (история поиска и координаты мест, откуда пользователь ходил в сеть, график работы в сети и скорость чтения страниц - имя им миллион). Сервисы очень ревностно оберегают эти данные - это их хлеб, а иногда - и икра.&lt;/li>
&lt;li>личные - этими данными пользователь не собирается делится вовсе. Например, сюда можно отнести почтовую переписку. Ну или фотографии, сделанные для себя-любимого (или предназначенные для одной-единственной пары глаз). В теории доступ к этим данным есть только у пользователя.&lt;/li>
&lt;/ul>
&lt;p>Удивительно, но факт - вытащить скрытные данные намного сложнее, чем личные. Личные данные пользователь защищает сам, а вот скрытные данные защищаются не хуже, чем Форт Нокс. Крупные порталы, такие, как google, yandex, facebook, mail.ru, MSN/HotMail/Bing знают о пользователе просто-таки невероятно много. Причина такого интереса проста, как мычание - это маркетинг. Начал эту войну Google - кому-то из руководства пришла в голову светлая мысль анализировать поисковые запросы пользователя, и показывать ему рекламу исходя из этих запросов. Если пользователь ищет что-то вроде “Лодка резиновая купить Москва” - показать ему объявление о продаже резиновой лодки выглядит вполне разумным. Чем сложнее и изощреннее персонализация, чем больше рекламная сеть знает о своем пользователе - тем более точные объявления она должна пользователю показывать - это выгодно, потому, что рекламная сеть получает деньги за клики пользователя, и каждое объявление, которое пользователь просмотрел, но кликать не стал - потенциальная потеря доходов. Следующим гвоздиком в гроб privacy стала персонализация самих поисковых запросов. Поисковик нужен для того, чтобы пользователь нашел то, что его интересует. Проблема в том, что поисковый сервис не знает (и не может знать), что именно ищет пользователь, когда пишет, скажем “Динамо”. Электромеханическую машину? Спортивный клуб “Динамо”? А может - практику нездоровых отношений? Или что-то еще? Чтобы вычленить нужные пользователю данные из безбрежного океана информации - поисковик должен учесть, что делал пользователь раньше. Чем больше данных он учтет - тем более точным будет ответ на вопрос пользователя. Это, кстати, порождает забавный эффект, известный как “пузырь фильтров”: пользователь своей активностью как-бы запирает себя в круге своих интересов. Если он начнет искать что-то выходящее из круга его обычных поисков - у него начнутся серьезные проблемы, ведь поисковая система будет считать, что ему это просто не нужно. Поисковики следят за пользователями не только на страницах поиска (что искал? на какую ссылку ушел? вернулся ли? сколько времени провел на странице?) но и на страницах сайтов тоже. Все основные поисковики имеют бесплатный модуль статистики и аналитики поведения пользователя. У Google это Google analytics, у Яндекс - Метрика. Скрипт метрики сидит на подавляющем большинстве сайтов и внимательные глаза Яндекса/Гугла/Майкрософт постоянно наблюдают за его поведением. Откуда пришел? Что делал? Куда кликал? Сколько потратил на страницу? Мало? Много? Часть этой информации аналитика покажет пользователю (то есть владельцу сайта, на котором стоит счетчик), но и для себя сохранит, понятное дело. За счет повсеместного распространения аналитики в сочетании с рекламными блоками (да, они тоже учитывают поведение пользователя) - поисковик знает о поведении пользователя буквально все. К слову, широко распространенные скидочные карты магазинов (они же программы лояльности) - из той же оперы. Карточка привязана к определенному человеку, и это делает жизнь этого человека практически прозрачной - магазин точно знает, что купил клиент, когда и на какую сумму.&lt;/p>
&lt;h2 id="кому-они-достаются" >Кому они достаются?
&lt;span>
&lt;a href="#%d0%ba%d0%be%d0%bc%d1%83-%d0%be%d0%bd%d0%b8-%d0%b4%d0%be%d1%81%d1%82%d0%b0%d1%8e%d1%82%d1%81%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Как я уже показал выше, информации в интернете о пользователе хранится очень много. Имея к этой информации доступ, можно составить практически полный портрет жизни пользователя, причем порой можно узнать о пользователе такое, чего он не знает о себе сам. Информация о поведении пользователя очень важна для поисковых систем (реклама), соцсетей (опять реклама), и особенно - магазинов (большая вероятность покупки означает большую прибыль). Сервисы очень тщательно оберегают скрытую информацию - это основа их конкурентного преимущества. Потеря массива информации о пользователе грозит миллиардными убытками. Но это, разумеется, не значит, что нет способа эту информацию использовать в своих нехороших целях.&lt;/p>
&lt;p>Открытую информацию могут (и будут) использовать в криминальных целях. Люди удивительно беспечны, и выдают в сеть уйму интересного. Возможно, тут играет роль субъективное понимание своей личной странички (твитера, вконтактика, google+) как персонального пространства, помеси кухонной посиделки с друзьями и дневника. Это ошибка. Нужно помнить о том, что:&lt;/p>
&lt;ul>
&lt;li>Информация, выложенная в интернет останется там, с очень большой долей вероятности, навсегда. Стереть информацию из сети полностью - невозможно.&lt;/li>
&lt;li>Информация, выложенная в интернет - рано или поздно станет доступна всем. Даже тем, кому она не предназначалась.&lt;/li>
&lt;/ul>
&lt;p>Нужно понимать, что фото с веселой попойки могут быть миной, заложенной под вашу карьеру (прецеденты были). А твит &amp;ldquo;уезжаем на две недели в Турцию&amp;rdquo; - готовым приглашением для вора-домушника (особенно, если геолокация не отключена и есть фотографии и твиты из квартиры).&lt;/p>
&lt;p>Разберемся, кому ваши данные могут потребоваться. Основных адресатов трое: криминал, бизнес и государство. Криминал по большей части &amp;ldquo;бомбит по площадям&amp;rdquo; - учетные данные (логины-пароли) закупаются и продаются миллионами, в первую очередь - для рассылки спама и вирусов. Точно так же покупаются и продаются номера кредитных карт (никогда не храните их на ПК! И в телефоне тоже не надо). В редких случаях личные данные используют для вымогательства - вирус шифрует все файлы пользователя и просит денег на расшифровку. Разумеется - делает это робот без вмешательства человека. В очень-очень редких случаях встречается работа на заказ, когда профессиональный взломщик работает против конкретного пользователя. Именно так было с Алексеем Навальным, именно так было с Дженифер Лоуренс. Причина, по которой копают на заказ может быть сложной, и защищаться от заказа тоже непросто (хотя вполне реально - создателя Bitcoin Сатоши Накамото безуспешно ищут уже пять лет, а создатель крупнейшей биржи криминального товара Ужасный Пират Робертсон попался совершенно случайно). Защита от заказной атаки дело непростое и явно выходит за рамки данного текста.&lt;/p>
&lt;p>Бизнес. Бизнес обожает пользовательские данные и собирает их везде, где может. Мог бы - в душу залез и в желудке бы устроился. Причину я уже описал выше - это маркетинг. Проанализировав покупки и поведение пользователя бизнес сможет предложить товар или услугу, которую пользователь, с большой долей вероятности, купит. Повышение конверсии (соотношение между затратами на рекламу и отдачей в виде покупки) - одно из важнейших занятий в бизнесе. Разумеется, такие умозрительные понятия, как неприкосновенность частной жизни бизнес волнует очень мало, прибыль интересует много больше. Если бы данные, накопленные бизнесами, жили внутри - это не было бы проблемой, но периодически эти данные утекают (хотя и очень редко, а для их использования нужна немалая квалификация, сделать это способны единицы). Опасность утечки подобных данных очевидна, как я уже упоминал выше - сервис может знать о клиенте просто-таки удивительно много и вдумчивый анализ данных покажет жизнь пользователя как на ладони. Государства стараются воевать с бизнесом, чтобы сохранить монополию на слежку, но это битва без конца и края - на стороне государства вся мощь репрессивного аппарата, но бизнес выигрывает за счет гибкости и скорости принятия решений.&lt;/p>
&lt;p>Государство. Сразу скажу, воевать с государством &lt;em>очень&lt;/em> сложно. В отношении отдельно взятого пользователя ресурсы государства можно принимать за неисчислимые. Кроме того, активное сокрытие данных может натолкнуть специальные службы на специальные мысли (винить их в этом бессмысленно - спецслужбы в этой ситуации ведут себя как собаки в экспериментах Павлова - есть раздражитель - будет реакция, если пользователь активно конспирируется - значит, он делает это не просто так). При этом нужно отделять государство как репрессивную машину в целом от ее отдельных представителей, которые от большого любопытства (или в корыстных интересах) начинают изучать жизнь пользователя. В принципе, государство имеет доступ к любому каналу связи, который относится к &amp;ldquo;изучаемому&amp;rdquo; пользователю - от кабеля в интернет до мобилки. Любой сервис, который официально работает в стране - должен предоставлять госорганам доступ к персональным данным, включая (но не ограничивая) переписку и список контактов. Если вы играете в Че Гевару - это нужно иметь ввиду. Разумеется, в теории все эти данные могут быть запрошены только на основании определенных документов (как минимум - должно быть возбуждено уголовное дело). Я не могу и не буду учить читателя криминальной активности (кто хочет - пусть сам и учится, на своих ошибках), но нужно понимать, что уголовное дело может быть заведено совершенно внезапно, и если в вашей жизни есть этот риск - к нему нужно быть готовым.&lt;/p>
&lt;p>Отдельной группкой сидит digital forensics team - это люди (чаще группы, чем одиночки), которые ищут конкретного человека и, как и реальные криминалисты, изучают цифровые следы этого человека в сети. По большей части DFT работает с публичными данными, анализируя особенности поведения. Цели работы таких команд могут быть самыми различными - от поиска проштрафившегося должника до политического убийства.&lt;/p>
&lt;h2 id="что-со-всем-этим-делать" >Что со всем этим делать?
&lt;span>
&lt;a href="#%d1%87%d1%82%d0%be-%d1%81%d0%be-%d0%b2%d1%81%d0%b5%d0%bc-%d1%8d%d1%82%d0%b8%d0%bc-%d0%b4%d0%b5%d0%bb%d0%b0%d1%82%d1%8c">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Итак, выше я обрисовал основные каналы утечки информации и их получателей, теперь попробуем придумать, что со всем этим делать и как бороться с гадами. Для начала очень важное замечание. Оно настолько важное, что я вынесу его отдельно:&lt;/p>
&lt;blockquote>
&lt;p>Слабость системы всегда равна слабости самого слабого звена&lt;/p>
&lt;/blockquote>
&lt;p>Что это значит для нас? Только то, что персональные данные должны быть одинаково хорошо защищены со всех сторон. Если вы поставили в квартиру крутую стальную дверь из танковой брони - вы не сделали дом неуязвимым - вам могут эту дверь вынести со всей коробкой (обычно ставят домкрат в лестничный пролет - промышленный домкрат выдает 50 тонн, и дверь вылетает, как пробка. Так вот, о чем это я?). Или вынесут стену. Или разберут потолок. Потому - защита не должна иметь явных белых пятен. Стратегия защиты в идеале должна выглядеть, как забор - одинаково высокая по всей длинне. Далее - нужно определится со степенью конспирации. В целом в работе с инструментами безопасности прослеживается простая закономерность - безопасность обратно пропорциональна удобству. Если вы хотите построить очень защищенную систему - это вполне реально, но это будет &lt;em>очень&lt;/em> неудобно (и дорого). Недоубный инструмент провоцирует на то, чтобы от него отказаться. Чем более инструмент неудобен - тем меньше он, статистически, у вас проживет. Большая часть шагов, которую я опишу ниже - это разумные предосторожности, и если за вами гоняется Ми-6 - вам они не помогут. Но от глупых неприятностей, надеюсь, уберегут.&lt;/p>
&lt;p>Рекомендация или правило номер два - в вопросах безопасности нельзя доверять никому и ни в чем. Что бы кто бы вам не обещал - ваши данные должны быть только вашими. Если вам прислали подозрительный файл - не открывайте (он может быть “заряжен” вирусом). Подозрительная ссылка - не ходите. Любой объект, который размещен в сети - принадлежит не тому, кто его разместил, а тому, кто владеет площадкой, где он лежит.&lt;/p>
&lt;p>Теперь по пунктам.&lt;/p>
&lt;h3 id="учетные-данные" >Учетные данные
&lt;span>
&lt;a href="#%d1%83%d1%87%d0%b5%d1%82%d0%bd%d1%8b%d0%b5-%d0%b4%d0%b0%d0%bd%d0%bd%d1%8b%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Их надо беречь. Самое уязвимое место - e-mail. Большая часть онлайн-сервисов сейчас использует при регистрации именно e-mail, получив к нему доступ, злоумышленник получит доступ разом ко всем сервисам, на которых вы с данного ящика регистрировались. В ящике не должно быть паролей (вообще, их нужно удалять сразу после получения письма) а так же - регистрационных писем и рассылок от владельцев сервиса. Разумеется, на ящике должен стоять сложный пароль (длинный, не словарное слово, не связан с вами ни в каком виде). К ящику нужно обязательно привязать номер телефона, причем номер должен быть зарегистрирован именно на вас (иначе вы не сможете получить симку, если потеряете ее, а без симки не сможете вернуть себе доступ). Если почтовый ящик позволяет - используйте двухфакторную авторизацию (пароль + смс), практически все крупные провайдеры умеют это. Вообще, специалисты рекомендуют иметь несколько ящиков. Для регистраций использовать ящик нечитаемого вида (&lt;a href="mailto:D6AkY2fQvy978f24@ya.ru">D6AkY2fQvy978f24@ya.ru&lt;/a>), который никогда не светится в переписке. Ящик, который используется для контактов с реальными людьми - не использовать для регистраций на критичных сервисах. Пароли от ящиков рекомендуется периодически менять (скажем - раз в год). Помните о том, что все письма в вашем почтовом ящике доступны как минимум сотрудникам почтового сервиса. Если у вас есть письмо, которое относится к категории &amp;ldquo;это не телефонный разговор&amp;rdquo; - оно должно быть зашифровано до отправки по почте. Любые ваши данные, размещенные на любом сервере в интернете, вам уже не принадлежат, они принадлежат серверу! Помните о том, что никакой сервис не будет у вас требовать пароль от вашей учетной записи - техническая поддержка всегда может работать без него. Также рекомендуется обращать внимание не только на внешний вид страницы входа, но и на адрес сервиса в адресной строке. В этом сильно помогает HTTPS - если ваш сервис его использует, рекомендую не лениться, а кликнуть на буквы https и прочитать информацию о сертификате, как минимум - кому он выдан, кем, и до какого момента действителен.&lt;/p>
&lt;p>&lt;img src="https://prudnitskiy.pro/media/uploads/ssl.png" alt="HTTPS">&lt;/p>
&lt;h3 id="поведение-в-сети" >Поведение в сети
&lt;span>
&lt;a href="#%d0%bf%d0%be%d0%b2%d0%b5%d0%b4%d0%b5%d0%bd%d0%b8%d0%b5-%d0%b2-%d1%81%d0%b5%d1%82%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Как я уже говорил выше, все, что вы размещаете в сети - рано или поздно станет доступно всем и останется в сети навсегда. Прежде, чем что-то размещать - спросите себя, уверенны ли вы в том, что хотите этого. По возможности, нужно размещать в сети как можно меньше информации, особенно - оперативно. Понятия &amp;ldquo;приватный фотоальбом&amp;rdquo; в сети нет, удалить данные невозможно (все фотографии вконтакте до сих пор доступны любому по прямой ссылке. Да, все фотографии за всю историю вконтакте). Чем тушить потом пожар информационного скандала - проще сейчас затушить спичку и не размещать в сети что-то такое, о чем вы можете потом пожалеть. Если вам действительно нужно выложить какую-то потенциально опасную для вас информацию - перед выкладкой ее нужно обязательно зашифровать, а ключ переправить получателю отдельно. В целом я очень рекомендую точно дозировать информацию, которой вы делитесь в сети и не публиковать больше, чем того требует элементарная сетевая вежливость. При этом я не рекомендую сворачивать активность в социальной сети до нуля - это может натолкнуть на подозрение, что пользователь шифруется и вызовет повышенное внимание у злоумышленника.&lt;/p>
&lt;h3 id="слежение-за-поведением-пользователя" >Слежение за поведением пользователя
&lt;span>
&lt;a href="#%d1%81%d0%bb%d0%b5%d0%b6%d0%b5%d0%bd%d0%b8%d0%b5-%d0%b7%d0%b0-%d0%bf%d0%be%d0%b2%d0%b5%d0%b4%d0%b5%d0%bd%d0%b8%d0%b5%d0%bc-%d0%bf%d0%be%d0%bb%d1%8c%d0%b7%d0%be%d0%b2%d0%b0%d1%82%d0%b5%d0%bb%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Поисковые (и вообще - таргетинговые) системы обожают слежку за пользователем. Несмотря на то, что законы прямо запрещают компаниям хранить приватные данные в не-обезличенном виде, компании постоянно ищут способ этот запрет обойти. Кроме того, лично у меня нет доверия к компаниям, которые следят за поведением пользователей, потому, что я, как пользователь, не могу проконтролировать эти данные. Традиционный способ слежения - использование javascript на страницах в интернет. Слежкой традиционно занимаются различные системы аналитики (Google Analytics, Yandex.Метрика, Bing Webmaster toolkit, NewRelic), а так же - счетчики (Alexa, LiveInternet, Топ Mail.ru). Для идентификции пользователя сервис выставляет cookie (обычно - несколько разных, прячет в разные места), а при каждом заходе на каждую страницу сайта - проверяет ее наличие. Простой способ борьбы - использовать расширение Ghostery (есть в редакциях под Mozilla Firefox и Google Chrome/Chromium). Так же частичную блокировку обеспечивает расширение AdBlock (а еще лучше - сочетать эти два способа борьбы). Способ более сложный (и надежный) - использование Incognito-режима в браузере. В этом случае все данные, которые использует браузер в работе будут стерты при закрытии браузера.&lt;/p>
&lt;p>&lt;img src="https://prudnitskiy.pro/media/uploads/forbes.png" alt="Forbes">&lt;/p>
&lt;p>Мой любимый пример - сайт российского издания Forbes. 11 следящих модулей (Ghostery - справа) и 26 рекламных модулей (которые тоже могут следить за пользователем).&lt;/p>
&lt;h3 id="общение-в-сети-почта-im" >Общение в сети. Почта, IM
&lt;span>
&lt;a href="#%d0%be%d0%b1%d1%89%d0%b5%d0%bd%d0%b8%d0%b5-%d0%b2-%d1%81%d0%b5%d1%82%d0%b8-%d0%bf%d0%be%d1%87%d1%82%d0%b0-im">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Простое правило всех безопасников - не доверять никому - действует и тут. Нужно помнить о том, что доступ к вашей переписке есть у сотрудника компании, которая предоставляет вам сервис. За злоупотребление данной привилегией сотрудников карают, но злоупотребления происходят с завидной периодичностью. Также этот доступ может (и будет) предоставлен компетентным органам. Опять повторю рекомендацию, которую я приводил выше - почтовый ящик - это очень важная часть цифровой личности. Обычно, имея доступ к почтовому ящику, нет никакой проблемы перехватить сервисы, которые к этому ящику привязаны, по этому строго рекомендуется иметь несколько почтовых ящиков (как минимум - два), и не использовать для регистрации в сервисах ящик, который служит для общения (и наоборот). Все, что может указать на связь ящика с сервисами (письма с паролями и ссылками на активацию, рассылки с новостями) рекомендуется удалять сразу после прочтения. Если у вас есть письма, содержащие важные или потенциально опасные сведения - эти письма должны хранится только в зашифрованном виде или не храните их вообще. Для шифрования можно использовать, например, GPG - есть редакции по Windows, Mac и Linux. К слову об удалении писем - не забывайте чистить корзину.&lt;/p>
&lt;p>Мессенджер менее опасен, чем почта, но у него есть существенное, для атакующего, преимущество - пользователь использует его значительно активнее. Общие рекомендации похожи на почтовые - не пишите то, о чем можете пожалеть. Если вам надо что-то такое написать - используйте, как минимум, end-to-end шифрование, большая часть современных клиентов (таких, как AdiumX для Mac, Kopete под Linux или MirandaIM под Windows) имеют соответствующие расширения и настройки. Если есть возможность - используйте открытые пиринговые системы обмена сообщениями, такие, как &lt;a href="https://tox.im">Tox&lt;/a> или BitMessage - собеседника в такой системе отследить почти невозможно. В плане безопасности наихудшим образом проявил себя Skype - никто не знает, как он устроен и чем в системе занимается, модулей шифрования в нем нет, открытых клиентов (к которому можно прикрутить модуль шифрования) - тоже нет. При этом skype принадлежит компании майкрософт, которая обязана сотрудничать с органами власти и предоставлять им пользовательские данные по запросу. Не забывайте о том, что мессендежры хранят историю и на пользовательской машине тоже. Историю, скажем, скайпа прочитать непросто, но при необходимости, можно.&lt;/p>
&lt;p>Помните о том, что любой ваш друг, коллега или родственник может лишится своего IM из-за взлома в любой момент. Не открывайте странные файлы, которые вам присылают (вирусы бывают не только в исполняемых файлах и не только на windows). Не ходите по неизвестным ссылкам. Если у вас есть подозрения, что человека взолмали - свяжитесь с ним по альтернативному каналу связи.&lt;/p>
&lt;h3 id="личный-компьютер-пользователя" >Личный компьютер пользователя
&lt;span>
&lt;a href="#%d0%bb%d0%b8%d1%87%d0%bd%d1%8b%d0%b9-%d0%ba%d0%be%d0%bc%d0%bf%d1%8c%d1%8e%d1%82%d0%b5%d1%80-%d0%bf%d0%be%d0%bb%d1%8c%d0%b7%d0%be%d0%b2%d0%b0%d1%82%d0%b5%d0%bb%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Заражение личной машины - самый сложный и опасный случай. Зараженная (или украденная) машина разом компрометирует все пароли, которые на ней есть и все данные, которые в момент заражения были доступны пользователю. Рекомендации традиционные, но я все же повторю их:&lt;/p>
&lt;ul>
&lt;li>Обновляйте систему. Делайте это своевременно.&lt;/li>
&lt;li>Обновлйте ПО, которое вы используете. Софт должен обновляться из доверенных источников (бывают фальшивые обновления).&lt;/li>
&lt;li>Если у вас windows - найдите и поставьте хороший антивирус. Его тоже обновляйте почаще.&lt;/li>
&lt;li>Обращайте внимание на поведение машины. Если машина внезапно “тупит” без явного повода, активно хрустит жестким диском или грузит сеть - это может быть признаком заражения. Резервная копия и загрузочный диск с антивирусом (бесплатные варианты есть у Dr.Web и Kaspersky antivirus) - ваши друзья на ближайшие несколько часов.&lt;/li>
&lt;li>Возьмите за традицию раз в определенное время (скажем, раз в год) проверять компьютер антивирусом, загрузив его с CD. Некоторые вирусы настолько качественно встраиваются в систему, что антивирус не может перехватить их выполнение и вылечить систему (или хотя бы обнаружить вирусную активность).&lt;/li>
&lt;li>Если у вас старая windows (XP, 2000, Vista) - не работайте из-под администратора. Для новых версий это уже не столь актуально - UAC перехватывает потенциально опасные действия.&lt;/li>
&lt;li>В любом случае у вас должен быть пароль. Длинный и сложный (PCI рекомендует не менее 8 символов, большие и маленькие буквы, цифры и спецсимволы)&lt;/li>
&lt;li>Шифруйте данные. Представьте, что ваш компьютер украли. Что увидит человек, имеющий полный доступ к диску? Есть ли там что-то, чего он увидеть не должен? Шифруйте. Для шифрования рекомендую использовать программу TrueCrypt, ее надежность и качество доказаны многократными проверками экспертов. Важно, не используйте версию 7.2, так как есть подозрение, что именно в версии 7.2 контроль над TrueCrypt был перехвачен злоумышленниками.&lt;/li>
&lt;li>При шифровании данных не используйте средства, предоставляемые самой операционной системой (BitLocker для Microsoft и FileVault для MacOS X). Эти системы имеют процедуру сброса пароля, а следовательно - они ненадежны. В по-настоящему надежной системе шифрования потеря ключа лишит вас доступа к данным без каких-либо шансов на восстановление доступа. Если система шифрования позволяет получить доступ к вашим данным без вашего ключа - она не может считаться надежной.&lt;/li>
&lt;li>Сменные носители тоже шифруйте. Флешки постоянно теряются, периодически доходит до маразма (например, один раз в канадском ломбарде всплыл ноутбук со сверхсекретным чертежами подводных лодок. Владельцы ломбарда получили немалый заряд позитива и несколько седых волос).&lt;/li>
&lt;li>Не стоит хранить на своей машине пароли. Если пароли не хранить не удается никак, то хотя бы шифруйте их - для этого есть специальные системы управления паролями, например KeyPass&lt;/li>
&lt;/ul>
&lt;h3 id="мобильные-устройства" >Мобильные устройства
&lt;span>
&lt;a href="#%d0%bc%d0%be%d0%b1%d0%b8%d0%bb%d1%8c%d0%bd%d1%8b%d0%b5-%d1%83%d1%81%d1%82%d1%80%d0%be%d0%b9%d1%81%d1%82%d0%b2%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Заражения мобильных бывают сравнительно редко, но приятного в этом мало. Если вы не воюете с государством или профессиональными хакерами, список рекомендаций будет очень небольшим:&lt;/p>
&lt;ul>
&lt;li>Устанавливайте приложения только из доверенных источников. Подавляющее большинство вирусов является именно полноценными приложениями.&lt;/li>
&lt;li>Если у вас Android - читайте, какие права запрашивает приложение для работы. Слишком высокие права должны вас насторожить.&lt;/li>
&lt;li>Отключайте WiFi и BlueTooth на устройстве, если вы его не используете. Заражение через сеть - редкость, но встречается.&lt;/li>
&lt;li>Обновляйте систему и ПО. Мобильный - тот же компьютер, только маленький. Софт для мобильного тоже подвержен ошибкам.&lt;/li>
&lt;li>Храните на мобильном минимум информации. Потому, что зашифровать данные на мобильном очень, очень сложно, а украсть мобильный физически проще, чем полноценный компьютер.&lt;/li>
&lt;li>Используйте программы удаленного управления устройством (Find my iPhone, Stolen/Hidden, HawkEye). Если телефон стащат - вы сможете хотя бы стереть с него критически важные данные.&lt;/li>
&lt;/ul>
&lt;h2 id="заключение" >Заключение
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Краткое руководство для практикующих параноиков получилось не таким уж и кратким, хотя я и жал его, как мог. Паранойя - дело сложное и затратное, как по времени, так и по количеству усилий. С другой стороны - интернет такая недобрая песочница, где пользователя всякий обидеть норовит. Минимальная грамотность в вопросах безопасности в этом плане подобна мечу из японской поговорки про самурая - даже, если воспользоваться им прийдется один раз в жизни, носить его при себе стоит постоянно. Надеюсь моя статья предоставит вам хоть немного полезной информации - это будет значить, что мой труд был не лишним.&lt;/p></description></item><item><title>Сравнение систем мониторинга</title><link>https://prudnitskiy.pro/post/2013-11-14-monitoring-comparsion/</link><pubDate>Thu, 14 Nov 2013 22:31:58 +0000</pubDate><guid>https://prudnitskiy.pro/post/2013-11-14-monitoring-comparsion/</guid><description>&lt;p>Мониторинг (отслеживание состояния сервисов), наряду с резеврным копированием является, наверное, одной из самых старых и популярных задач для системного администратора. Разумеется, существует великое множество различных инструментов для ее выполнения. В этом развесистом великолепии с трудом ориентируются даже бывалые специалисты. В данном тексте я собрал основные системы мониторинга с кратким описанием и сравнением плюсов, минусов и особенностей. Разумеется, статья не претендует на всеобъемлющее описание всех систем мониторинга планеты (их слишком много), но поможет хотя бы соориентироваться и понять, куда искать.&lt;/p>
&lt;h2 id="monit" >Monit
&lt;span>
&lt;a href="#monit">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Достаточно древняя разработка. Официальный слоган - That barking on daemons. Работает строго локально, самостоятельный демон, написан на C. Расширяемость нулевая - плагины не поддерживает. Основная задача - отслеживать работу демонов и перезапускать умершие, зависшие или вышедшие за квоту ресурсов. Обладает довольно своеобразным конфигом (не похож ни на что вообще). Не смотря на нулевую расширяемость в базе имеет большую часть необходимых проверок. Может проверять процесс по факту наличия, занимаемые ресурсы, подключаться к процессу (по сети или сокету), проверять ответ от сервера (на факт наличия, а так же на содержание), проверять соотвествие определенным протоколам (HTTP, FTP, POP/IMAP/SMTP - полный список смотреть в документации). Поддерживает работу с SSL, имеет встроенный веб-интерфейс. Проверка производится по расписанию, раз в определенное время. По результатам проверки может принимать определенные решения (прибить процесс, перезапустить, уведомить админа). Прост, надежен как автомат Калашникова. В активе компании-автора есть многосервисная платная система M/Monit - для управления группами сервров, но с ней я не сталкивался.&lt;/p>
&lt;h2 id="munin" >Munin
&lt;span>
&lt;a href="#munin">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Не смотря на то, что изначально этот проект создавался для рисования графиков, он может служить и мониторинговой системой (так, как имеет в базе систему уведомлений). Строго клиент-серверная система, на целевых узлах запускается процесс-клиент. Процесс-сервер подключается к клиентам по расписанию и собирает числовые данные (метрики), складирует их у себя и отрисовывает графики. Он же отвечает за уведомления - интеллект клиента у мунина близок к нулю. Легко расширяется: строго говоря, все метрики munin рисует, используя данные плагинов (без плагинов метрик не будет). Плагины легко пишутся - язык произвольный, так как мунин ожидает только числа (данные) метрик в определенном формате и код ответа. В силу своей архитектуры monit не способен производить действий на клиентских узлах (например - перезапускать зависший процесс). Язык написания самого демона - перл.&lt;/p>
&lt;h2 id="ganglia" >Ganglia
&lt;span>
&lt;a href="#ganglia">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Достаточно старый инструмент, созданный в CERN. Писали ученые и для ученых, а потому инструмент своеобразный. Основное назначение ганглии - сбор данных о производительности большого количества однотипных машин (вычислительные кластеры). Обладает производительностью, поражающей воображение (десятки тысяч наблюдаемых узлов на очень среднем сервере), но трешхолд довольно большой (данные собираются отложенно, так что если надо смотреть нагрузку в реальном времени - это не к нему. Клиент-серверная архитектура: клиент собирает данные, аккумулирует их у себя и раз в определенное время отсылает на сервер. В случае, если какая-то метрика перешагнула пороговое значение, ответ будет отправлен вне очереди. Сервер собирает данные со всех клиентов, аггрегирует их и сохраняет в базе. Веб-интерфейс живет отдельным компонентом, он связывается с сервером по внутреннему протоколу и отображает различные графики. В силу специфики ганглии интерфейс очень необычный, но прекрасно подходит для сравнительного анализа данных с групп серверов (например, построение графика зависимости нагрузки на CPU сервера 10 от сетевой нагрузки на сервера с 50 по 90 делается в два клика мышью). Ганглия расширяема, но написание плагина представляет из себя нетривиальную задачу - дело в том, что с точки зрения ганглии, плагин - это библиотека. Это накладывает требования на язык реализации плагина (только C или Python) и внутреннюю структуру кода (описано в документации). Сами демоны написаны на C, веб-интерфейс - на PHP. Обладает очень корявой системой уведомлений, чаще всего ганглию скрещивают с Исингой (см ниже)&lt;/p>
&lt;h2 id="nagios--icinga" >Nagios / Icinga
&lt;span>
&lt;a href="#nagios--icinga">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Довольно древний инстурмент, изначально назывался Nagios (автор - Этан Галстадт). В процессе разработки в стане разработчиков произошел раскол и появился форк (Icinga). Сейчас эти системы развиваются самостоятельно, но общего в них много больше, чем разницы. Nagios существует в бесплатной (core) и платной редакциях, Icinga - честный Open source. Изначально серверно-ориентированный демон на голом С, управление демоном ведется через C-подобный конфиг (внешне напоминает конфиг ISC BIND). Все проверки собираются в живую очередь и выполняются в строгой очередности. Это налагает определенные ограничения на масштабируемость - сервер удержит большое количество проверок без труда, но чем их больше, тем больше времени проходит между ними. По личному опыту, пара тысяч проверок (400 серверов х 5 проверок на сервер) делает систему мониторинга практически бессмысленной - между проверками проходит слишком много времени. В качестве опции существует приложение-клиент под названием NRPE, он позволяет проводить проверку локально, на клиенте (для тех случаев, когда проверить сервис удаленно невозможно), но это именно опция. Кроме того, проверки через клиента проводятся по инициативе сервера, так что на масштабируемость это никак не влияет. Nagios очень хорошо расширяется, плагины пишутся очень просто (и существует их великое множество). Nagios славится мощной и гибкой системой уведмолений - в базе она умеет писать письма и слать смс и сообщения на пейджер, но есть целый набор плагинов - от автоматического звонка голосом до светофора (не фигурально, а буквально - управляется эта радость через ModBus). Icinga имеет два веб-интерфейса на выбор - классический CGI и более современный на PHP. Субъективно CGI удобнее, хотя и менее гибок. Прародитель (nagios core) имеет только CGI-версию интерфейса. Важно отметить, что nagios не умеет и не желает собирать статистику ответов, соответственно ждать от нее красивых графиков в стиле Munin/Ganglia/Cacti бессмысленно. Существует мост для связи Icinga с Ganglia, это довольно популярный тандем, в котором Icinga отвечает, в первую очередь, за карту сети, обзор хостов и уведомления.&lt;/p>
&lt;h2 id="cacti" >Cacti
&lt;span>
&lt;a href="#cacti">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Изначально этот инструмент позиционируется для быстрой и простой сборки статистики по SNMP, но, с применением плагинов (notify + treshold) он обретает возможности системы монитоинга. Это PHP-приложение, настройки и конфигурации хранятся в базе MySQL (статистика хранится в RRD, что благотворно сказывается на производительности сервиса). Очень простая установка и первичная настройка (все делается через веб), в целом неплохо масштабируется (особенно, если применять костыли вида spine - многопоточного SNMP-опросника), большое количество базовых шаблонов для проверки различных типов устройств. Основной минус приложения - в его SNMP-центричности. Данный сервис хорошо подходит для сбора данных с активного оборудования, терпимо - для сбора типичной статистики работы сервиса (дисковое пространство, загрузка CPU etc) и отвратительно - для сбора сложных и нетипичных метрик. Кастомизация плохая.&lt;/p>
&lt;h2 id="opennms" >OpenNMS
&lt;span>
&lt;a href="#opennms">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Старший брат сервиса, рассмотренного выше. Это сложный, многокомпонентый &amp;ldquo;комбайн&amp;rdquo;, написанный на Java (собственный app-server, томкат не нужен), ориентированный на большие инфраструктуры с передачей статистики по SNMP. Большая сложность и гибкость сервиса превращают настройку в нетривиальное дело - для некрупных инфраструктур этот сервис явно избыточен. Так же, как и cacti, сервис придуман для работы с SNMP, а значит, основное применение сервиса - это мониторинг сетевых устройств. Сервис страдает практически полным отсутствием документации и очень плохо расширяем (по сути это монолитное java-приложение, внутренние настройки живут в виде неудобочитаемых XML-файлов, что превращает нетривиальную настройку в пытку).&lt;/p>
&lt;h2 id="graphite--collectd--whisper" >Graphite + CollectD + Whisper
&lt;span>
&lt;a href="#graphite--collectd--whisper">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Каждый компонент этого набора сам по себе не решает проблему мониторинга. Если все выше перечисленные продукты - это готовые решения уровня &amp;ldquo;сел и поехал&amp;rdquo;, то эта солянка больше напоминает мебель из IKEA (с той только разницей, что из этого набора с равной вероятностью можно собрать стол или подводную лодку). Фантастический неудобные файлы конфигурации, низкая стабильность кода (версии вида 0.1.192-alpha - нормальное дело) и тотальное отсутствие документации с лихвой компенсируется скоростью работы и масштабируемостью. Если вам надо собирать данные с серверной фермы класса github и видеть данные в практически реальном времени - вы нашли свой инструмент. Как и всякий молодой, сложный и специфичный инструмент - эта связка требует очень серьезной доработки до нужного состояния. Но. Эта штука работает быстро, действительно, &amp;lsquo;&amp;lsquo;невероятно&amp;rsquo;&amp;rsquo; быстро.&lt;/p>
&lt;h2 id="zabbix" >Zabbix
&lt;span>
&lt;a href="#zabbix">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Авторы этого инструмента при разработке брали примером серьезные системы мониторинга enterprice-класса. По сути - zabbix - это мониторинг enterprice-класса, но при этом он opensource. Обладает трехзвенной архитектурой (сервер-прокси-клиент, прокси опционален, но помогает снизить нагрузку), данные хранит в SQL, веб-интерфейс - полностью самостоятельное приложение на php. Сами демоны мониторинга написаны на C/C++. Все настройки так же хранятся в базе данных, а меняются через веб. Система обладает на редкость развесистым функционалом и покрывает любые, даже самые безумные &amp;ldquo;хотелки&amp;rdquo;. Множество различных проверок, графики &amp;ldquo;от чего угодно и куда угодно&amp;rdquo;, эскалации проблем и отслеживание SLA, app-level проверки, имитация хождения пользователя по сайту (с поддержкой javascript, cookies, GET/POST/PUT), карты и схемы, настраиваемые панели (dashboards) с любыми метриками на выбор. Система имеет свой API, распределенную модель прав доступа, умеет кластеризоваться для снижения нагрузки на узлы, умеет шаблоны проверок. В отличае от большинства перечисленных выше систем, zabbix может производить действия на клиентах (например - перезапустить определенный процесс), что дает множество интересных перспектив. Система прекрасно расширяется и очень гибко настраивается. Разумеется, не обходится и без дегтя, и главный бочонок сидит в SQL. Дело в том, что в SQL заббикс хранит абсолютно все - настройки, статистику, метрики, узлы. Активно работающий zabbix выедает IOPS с поражающей воображение скоростью, админы судорожно пьют корвалол и читают database performance optimization guides (что помогает, впрочем, мало) - или молятся на свой data storage. Несколько помогает снижение количество метрик и частоты их сбора, но это снижает пользу самой системы мониторинга (какой смысл в системе мониторинга, если она не мониторит?). Дополнительная пара ложек дегтя прячется в сложности zabbix. Черезвычайно гибкая по сути, система очень непроста в установке (даже с учетом того, что у нее прекрасно написана документация, в ней освещены практически все вопросы). Внедрение заббикса с нуля свободно может занять месяц труда администратора, а оптимизация под задачи бизнеса и вовсе процесс практически вечный. В целом - это хороший вариант для крупного бизнеса, которому нужны специфичные метрики (и который готов платить за столь масштабное внедрение). Затратив прорву времени, сил и денег (на оборудование), босс получает возможность одним взглядом окинуть всю инфраструктуру и сразу понять, где проблема.&lt;/p></description></item><item><title>Запуск ruby on rails на uwsgi на примере redmine</title><link>https://prudnitskiy.pro/post/2013-06-20-rails-on-uwsgi/</link><pubDate>Thu, 20 Jun 2013 19:49:52 +0000</pubDate><guid>https://prudnitskiy.pro/post/2013-06-20-rails-on-uwsgi/</guid><description>&lt;p>Для лично-рабочих нужд я активно использую task-tracking system под названием Redmine. Redmine практически всем хорош из открытых трекеров, но очень любит память. Традиционно он запускается через rails server (WEBRick) или rails-specific сервер thin. Во второй конфигурации у меня он жрал 300Мб оперативной памяти, а среднее время генерации страницы было близко к секунде, что совершенно неприемлимо. По этой причине я решил использовать uwsgi - совершенно прекрасный appserver, который я активно использую для своего творчества на python. Uwsgi работает очень быстро (действительно - очень!), достаточно экономно относится к памяти, обладает широчайшими возможностями конфигурирования - просто-таки мечта, а не сервер. До недавнего времени он умел работать только с python (под который интерфейс uWSGI, строго говоря, и создавался), но теперь умеет обрабатывать ruby и даже PHP. Минусом uwsgid является, во-первых, тот факт, что он находится на переднем крае разработок, а значит - может работать ой как своеобразно. Не менее своеобразно он настраивается, и документации по нему очень мало.&lt;/p>
&lt;h2 id="идея" >Идея
&lt;span>
&lt;a href="#%d0%b8%d0%b4%d0%b5%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Запускать будем redmine, но это типовое rails приложение, все остальные запускаются так же. В качестве веб-сервера - nginx, апп-сервер - uwsgid, база данных - postgresql (но будет уточнение для mysql), для управления uwsgid будем использовать supervisord&lt;/p>
&lt;h2 id="зависимости" >Зависимости
&lt;span>
&lt;a href="#%d0%b7%d0%b0%d0%b2%d0%b8%d1%81%d0%b8%d0%bc%d0%be%d1%81%d1%82%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Ставим системные компоненты:&lt;/p>
&lt;pre>&lt;code>apt-get update
apt-get install gcc cpp make nginx
#postgresql
apt-get install postgresql libpq-dev
#или mysql
apt-get install mysql libmysqlclient-dev
&lt;/code>&lt;/pre>
&lt;p>Лирическое отступление: я рекомендую использовать rvm вместо штатного руби. RVM живет вне пакетов, и обновлять его надо вручную, однако он позволяет получить самую свежую версию ruby, кроме того - он позволяет использовать несколько разных версий языка, а так же - несколько разных наборов библиотек (gem), не пересекая их друг с другом. Если у вас несколько приложений на ruby делят один сервер - это крайне удобный функционал.&lt;/p>
&lt;p>Ставим ruby:&lt;/p>
&lt;pre>&lt;code>#системная версия
apt-get install ruby1.8 ruby1.8-dev rubygems
#ИЛИ rvm
curl -L https://get.rvm.io | bash -s stable
rvm install 1.9.3-p429
&lt;/code>&lt;/pre>
&lt;p>Теперь доустанавливаем gem bundle. Он отвечает за установку необходимых для работы веб-приложения библиотек&lt;/p>
&lt;pre>&lt;code>gem install bundle
&lt;/code>&lt;/pre>
&lt;h2 id="установка-redmine" >Установка Redmine
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-redmine">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Создадим базу данных и пользователя для работы с ней:&lt;/p>
&lt;pre>&lt;code>#вариант для postgresql
sudo -u postgres psql
psql# create user redmineuser nocreatedb nocreateuser;
psql# alter role redmineuser with password 'MySecretP@ssw0rd';
psql# create database redminedb owner redmineuser;
#вариант для mysql
mysql -p
mysql&amp;gt; create database redminedb;
mysql&amp;gt; grant all on redminedb.* to redmineuser@localhost identified by 'MySecretP@ssw0rd';
mysql&amp;gt; flush privileges;
&lt;/code>&lt;/pre>
&lt;p>Теперь скачиваем и ставим сам redmine. Последнюю версию берем [http://rubyforge.org/frs/?group_id=1850] тут.&lt;/p>
&lt;pre>&lt;code>wget http://rubyforge.org/frs/download.php/76933/redmine-2.3.1.tar.gz
tar -xf redmine-2.3.1.tar.gz
mv redmine-2.3.1 redmine
&lt;/code>&lt;/pre>
&lt;p>Для корректной работы надо исправить файл config/database.yml в корне приложения. Вот пример для postgresql:&lt;/p>
&lt;pre>&lt;code>production:
adapter: postgresql
database: redminedb
host: localhost
username: redmineuser
password: MySecretP@ssw0rd
encoding: utf8
schema_search_path: public
&lt;/code>&lt;/pre>
&lt;p>А вот пример для mysql:&lt;/p>
&lt;pre>&lt;code>production:
adapter: mysql
database: redminedb
host: localhost
username: redmineuser
password: MySecretP@ssw0rd
encoding: utf8
&lt;/code>&lt;/pre>
&lt;p>Теперь самое сложное - установка GEM-ов. Gem - это библиотека в терминологии ruby. Их количество без преувеличения огромно, и делают они буквально все - appservers, драйвера к библиотекам, рисование графиков&amp;hellip; Любое нормальное руби-приложение использует множество гемов для работы. Для упрощения установки используется (сюрприз!) gem под названием bundle.
Заходим в папку redmine и выполняем:&lt;/p>
&lt;pre>&lt;code>#вариант для postgresql
bundle install --without development test sqlite mysql rmagick
#ИЛИ для mysql
bundle install --without development test sqlite pg rmagick
&lt;/code>&lt;/pre>
&lt;p>Запуск приложения (любого!) от root не рекомендуется, так как взлом этого приложения скомпрометирует систему полностью.
Сделаем непривелигированного юзера:&lt;/p>
&lt;pre>&lt;code>useradd --system -m -d /var/www/redmine -s /bin/bash redmine
&lt;/code>&lt;/pre>
&lt;p>Послеустановочные действия:&lt;/p>
&lt;pre>&lt;code>rake generate_secret_token
RAILS_ENV=production rake db:migrate
RAILS_ENV=production rake redmine:load_default_data
mkdir -p tmp tmp/pdf public/plugin_assets
chown -R redmine:redmine files log tmp public/plugin_assets
chmod -R 755 files log tmp public/plugin_assets
&lt;/code>&lt;/pre>
&lt;h2 id="установка-и-подключение-uwsgid" >Установка и подключение uwsgid
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d0%b8-%d0%bf%d0%be%d0%b4%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5-uwsgid">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Ставим uwsgid. Его придется ставить из gem, потому, что тот, что идет в комплекте с системой, слишком старый - и не умеет работать с rails&lt;/p>
&lt;pre>&lt;code>gem install uwsgi
&lt;/code>&lt;/pre>
&lt;p>Конфигурация uwsgi расскажет ему о том, как запустить rails. Пишем в файл uwsgi.ini&lt;/p>
&lt;pre>&lt;code>[uwsgi]
socket = /tmp/redmine.sock
chmod-socket = 770
master = true
lazy = true
processes = 2 #по количеству ядер в системе. У меня atom 525, два ядра
post-buffering = 4096
#следующие три строки - только для тех, кто использует RVM
rvm-path = /usr/local/rvm
#имя ruby, указывать обязательно, даже, если он указан по умолчанию
rvm = ruby-1.9.3-p429
#название gemset в формате язык@гемсет
gemset = ruby-1.9.3-p429@redmine
uid = redmine
gid = www-data
env = RAILS_ENV=production
chdir = /var/www/redmine
rack = /var/www/redmine/config.ru
http-modifier1 = 7
&lt;/code>&lt;/pre>
&lt;p>Сам по себе supervisor умеет порождать процессы-обработчики (это так называемый режим императора), но это совсем молодая фишка и работает она&amp;hellip; Ну, как любая совсем новая фишка. Лично я рекомендую использовать для управления supervisord. Его задача - запускать и останавливать другие процессы (в данном контексте - uwsgi). Он обладает очень простым (если не сказать - примитивным) конфигурационным файлом и очень прост в работе. Устанавливаем:&lt;/p>
&lt;pre>&lt;code>apt-get install supervisord
/etc/init.d/supervisor start
&lt;/code>&lt;/pre>
&lt;p>Теперь нам надо создать конфиг для нашего приложения. В папке &lt;code>/etc/supervisor/conf.d&lt;/code> создаем файл с произвольным именем и окончанием .conf. Содержимое:&lt;/p>
&lt;pre>&lt;code>[program:redmine]
directory=/var/www/redmine
command=uwsgi --ini /var/www/redmine/uwsgi.ini
autostart=true
&lt;/code>&lt;/pre>
&lt;p>Теперь его надо подключить. У supervisord есть собственная консоль, она называется supervisorctl. Заходим:&lt;/p>
&lt;pre>&lt;code>supervisorctl
#поиск новых конфигов
supervisor&amp;gt; reread
#нашелся
redmine: available
#добавляем
supervisor&amp;gt; add redmine
redmine: added process group
#проверим, работает?
supervisor&amp;gt; status
redmine BACKOFF can't find command 'uwsgi'
&lt;/code>&lt;/pre>
&lt;p>Не находится он потому, что supervisorctl не может найти rvm-версию uwsgi. Ок, укажем вручную:&lt;/p>
&lt;pre>&lt;code>find / -name uwsgi
[...]
/usr/local/rvm/gems/ruby-1.9.3-p429/bin/uwsgi
[...]
&lt;/code>&lt;/pre>
&lt;p>Вносим изменения в наш конфиг &lt;code>/etc/supervisor/conf.d/redmine.conf&lt;/code>. Теперь он выглядит так:&lt;/p>
&lt;pre>&lt;code>[program:redmine]
directory=/var/www/redmine
command=/usr/local/rvm/gems/ruby-1.9.3-p429/bin/uwsgi --ini /var/www/redmine/uwsgi.ini
autostart=true
&lt;/code>&lt;/pre>
&lt;p>Обновим конфиг без перезагрузки supervisord:&lt;/p>
&lt;pre>&lt;code>supervisorctl update redmine
supervisorctl status
[...]
redmine RUNNING pid 25365, uptime 0:00:18
[...]
&lt;/code>&lt;/pre>
&lt;p>Отлично, uwsgi работает, подключаем nginx. Debian-way предполагает, что конфигурации сайтов находятся в отдельных файлах каталога /etc/nginx/sites-enabled. Содержимое /etc/nginx/sites-enabled/redmine&lt;/p>
&lt;pre>&lt;code>server {
listen 80;
server_name redmine.office;
location @redmine {
uwsgi_modifier1 7;
include uwsgi_params;
uwsgi_pass unix:///tmp/redmine.sock;
}
location / {
root /var/www/redmine/public;
try_files $uri $uri/index.html $uri.html @redmine;
}
}
&lt;/code>&lt;/pre>
&lt;p>Кроме того, потребуется описание типовых параметров uwsgi, файл /etc/nginx/uwsgi_params&lt;/p>
&lt;pre>&lt;code>uwsgi_param QUERY_STRING $query_string;
uwsgi_param REQUEST_METHOD $request_method;
uwsgi_param CONTENT_TYPE $content_type;
uwsgi_param CONTENT_LENGTH $content_length;
uwsgi_param REQUEST_URI $request_uri;
uwsgi_param PATH_INFO $document_uri;
uwsgi_param DOCUMENT_ROOT $document_root;
uwsgi_param SERVER_PROTOCOL $server_protocol;
uwsgi_param UWSGI_SCHEME $scheme;
uwsgi_param REMOTE_ADDR $remote_addr;
uwsgi_param REMOTE_PORT $remote_port;
uwsgi_param SERVER_PORT $server_port;
uwsgi_param SERVER_NAME $server_name;
&lt;/code>&lt;/pre>
&lt;p>Теперь достаточно перезапустить nginx - и редмайн готов к использованию!&lt;/p></description></item><item><title>Облачный атлас: краткий путеводитель по вычислительным облакам для новичков</title><link>https://prudnitskiy.pro/post/2013-06-13-cloud-atlas/</link><pubDate>Thu, 13 Jun 2013 10:10:55 +0000</pubDate><guid>https://prudnitskiy.pro/post/2013-06-13-cloud-atlas/</guid><description>&lt;p>Неоднократно замечал, что многие мои коллеги (или просто знакомые) часто путают разные варианты модного сейчас набора концепций под собирательным названием &amp;ldquo;вычислительные облака&amp;rdquo;. Я решил набросать очень-очень краткий путеводитель по облакам, с примерами и анализом сильных и слабых сторон.&lt;/p>
&lt;h2 id="что-такое-облака" >Что такое облака?
&lt;span>
&lt;a href="#%d1%87%d1%82%d0%be-%d1%82%d0%b0%d0%ba%d0%be%d0%b5-%d0%be%d0%b1%d0%bb%d0%b0%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Несмотря на то, что стеку концепций (это не технологии, а именно набор концепций, идей!) под названием &amp;ldquo;вычислительные облака&amp;rdquo; уже, как минимум, 10 лет, единого мнения о &amp;ldquo;главном признаке&amp;rdquo; облаков нет до сих пор. В общем случае, облака - это вычислительные ресурсы по запросу (то есть - простота и скорость получения ресурсов) плюс высокая гранулярность учета этих ресурсов (оплата за час работы, а не за месяц). Не смотря на то, что звучит это просто и красиво, техническая сторона облаков очень сложна, как со стороны обеспечения, так и со стороны клиента. Большая часть современных операционных систем поддерживает горячее добавление ресурсов, но почти ни одна из них не поддерживает горячее &lt;em>удаление&lt;/em> ресурсов, и это лишь один маленький пример. Еще одной проблемой является, как ни странно, продолжение одного из основных бонусов облаков - точная тарификация ресурсов. Традиционный хостинг или аренда сервера тарифицируется &amp;ldquo;по среднему значению&amp;rdquo;, за счет чего активный пользователь услуг получает бонус за находчивость. При кажущейся дешевизне облаков, активная эксплуатация без точного понимания затрат на ресурсы грозит если не разорением, то, как минимум, неприятными открытиями при получении счета. Элементарный slow http ddos может сгенерировать пятизначный счет в долларах за трафик.&lt;/p>
&lt;h2 id="saas---software-as-a-service" >SaaS - Software as a Service
&lt;span>
&lt;a href="#saas---software-as-a-service">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Этот вариант облака появился самым первым, но при этом развивался до недавнего времени он хуже всего. Идея в том, что пользователь получает доступ к конкретному приложению (MS Word или 1C), которое работает где-то в заморском датацентре. Идею продвигал Microsoft, в надежде победить пиратство. В таком варианте продажи ПО (точнее - сдачи в аренду, ведь ПО, на самом деле, не продается) очень легко тарифицировать клиента и также легко отключать неугодных. Такая технология гарантирует отсуствие пиратства, ведь украсть приложение, к которому нет доступа - невозможно. Подвидом данного вида облаков является WAaaS - WebApp as a service. Данный вариант отлично подходит тем, кому нужна типавая инсталляция приложения (форум, crm). Эта услуга требует очень хорошего канала в интернет (минимум 512кб в секунду до датацентра для каждого пользователя услуги).&lt;/p>
&lt;h2 id="paas---platform-as-a-service" >PaaS - Platform as a Service
&lt;span>
&lt;a href="#paas---platform-as-a-service">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Это сравнительно свежая идея, из всех видов облаков она появилась последней. Идея в том, что код, написаный пользователем услуги, выполяется в провайдерском окружении. В отличае от SaaS, код ваш, однако инфраструктуру вам предоставляет провайдер. При этом совершенно не надо думать об отказоустойчивости или масштабируемости услуги - все это делает провайдер. Масштабируемость будет горячей (оплата за количество использованных циклов процессора, операций ввода-вывода) и совершенно незаметной. Это делает данный вариант облака идеальным для клиента с непредсказуемым профилем нагрузки (классический пример стартапа, у которого посещаемость может вырасти в 10.000 раз за день). Разумеется, без ложки дегтя в данной бочке меда не обошлось. Ложка называется App Binding. Дело в том, что абы какой код работать в подобной инфраструктуре не будет. Приложение придется адаптировать специально под конкретного провайдера. Причем адаптация может быть очень непростым делом и доставить разработчику много головной боли. Еще больше головной боли будет при миграции между провайдерами. Еще одной ложкой дегтя является устаревание основных версий библиотек и невозможность установить что-либо нетиповое. Если вам нужна экзотическая библиотека или (что еще хуже), ее экзотическая версия - у вас большие проблемы. Разумеется, провайдеры работают над решением этой проблемы, но сейчас она проявляется в полной мере.&lt;/p>
&lt;h2 id="iaas---infrastructure-as-a-service" >IaaS - Infrastructure as a Service
&lt;span>
&lt;a href="#iaas---infrastructure-as-a-service">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Самый широко известный и простой для понимания вариант вычислительных облаков. В общем вы получаете в аренду виртуальные сервера нужной вам конфигурации. Сервера имеют предустановленную ОС (на самом деле чаще всего они не ставятся, а копируются - для ускорения деплоя), а все остальное - уже ваша сфера ответственности. Единственное отличае от традиционных VDS/VPS - скорость получения услуги, новые сервера создаются буквально за минуты. Ну и, конечно, традицонная почасовая тарификация. Для более взыскательных клинетов IaaS позволяет построить виртуальный датацентр, создав, кроме серверов, еще и связующие их приватные сети. В общем случае IaaS не сильно сложнее традиционных VDS. Большинство провайдеров предлагает определенный набор средств для автоматизации развертывания. Обычно этот набор позволяет минимально сконфигурировать систему прямо в процессе развертывания (например, поставить дополнительные пакеты, привязать дополнительные файлсистемы и проч), однако слово &amp;ldquo;минимально&amp;rdquo;, в данной ситуации - ключевое. Сервер все равно придется настраивать самому. Благодаря такому подходу IaaS обеспечивает наибольшую гибкость в развертывании - ценой наибольших трудозатрат.&lt;/p>
&lt;h2 id="выводы" >Выводы
&lt;span>
&lt;a href="#%d0%b2%d1%8b%d0%b2%d0%be%d0%b4%d1%8b">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Облака появились как ответ на две основных проблемы ЦОД: во-первых, это постоянная неравномерность распределения нагрузки между физическими серверами (если у вас 20 серверов со средней нагрузкой в 10%, это означает, что за 18 серверов вы переплатили, и они, фигурально, греют воздух), а во-вторых - скорость развертывания новых машин. Бизнес очень любит мощности по запросу, желательно &amp;ldquo;вчера&amp;rdquo;. Классический пример - обсчет финансового отчета в конце года. Большой отчет требует прорву ресурсов, но нужны они только на время расчета. Интересным следствием из этого является тот факт, что в облаках конкретный сервер не имеет вообще никакой ценности - сама идеология облаков предполагает, что создается он только под конкретный запрос и живет только время его выполнения. Ценность в облаке имеет только информация (данные на серверах). Это налагает определенный отпечаток на работу в облаке - например, никто, кроме клиента, не заботится о целостности его, клиента, информации (исключение составляет только SaaS/WAaaS)&lt;/p></description></item><item><title>Дивный новый мир</title><link>https://prudnitskiy.pro/post/2013-05-21-brave-new-world/</link><pubDate>Tue, 21 May 2013 09:56:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2013-05-21-brave-new-world/</guid><description>&lt;p>Катастрофическое отсуствие времени в сочетании с любовью к Django и перфекционизмом привело к тому, что я решил отказаться от написания самостоятельного движка блога и перейти на Marcus от Ивана Сагалаева и Михаила Андреева. Движок, конечно, не 100% идеал (а есть ли вообще 100% идеал? Логика подсказывает, что такой невозможен), но близок к прекрасному. В ближайшее время вытащу сюда свои старые статьи и добавлю новых.&lt;/p>
&lt;p>Надеюсь гугл не выкинет меня из поисковой выдачи по некоторым ключевым словам за такой фокус :)&lt;/p></description></item><item><title>Использование Munin</title><link>https://prudnitskiy.pro/post/2011-11-21-munin-install/</link><pubDate>Mon, 21 Nov 2011 05:07:29 +0000</pubDate><guid>https://prudnitskiy.pro/post/2011-11-21-munin-install/</guid><description>&lt;p>В данной статье рассматривается такой инструмент мониторинга, как Munin. Этот инструмент существует под xNIX (Linux, xBSD, Solaris) и Windows и позволяет централизовано отслеживать и наглядно отображать состояние подшефных систем. Изначально используется для отрисовки графиков, но также его можно использовать как чистое средство для наблюдения. Большой плюс Munin - гибкость (все графики рисуются плагинами, активными на целевых системах, и никто не запрещает использовать только те плагины, которые нужны) и возможность с одного сервера собирать информацию о множестве других. Соответственно, нагрузка на наблюдаемом сервере минимальна. Интересно? Добро пожаловать под кат&lt;/p>
&lt;h2 id="что" >Что?
&lt;span>
&lt;a href="#%d1%87%d1%82%d0%be">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Munin - достаточно не новая система, развившаяся на популярном среди администраторов средстве отрисовки графиков RRDTool. Напомню, что идеология RRDTool состоит в хранении данных по &amp;ldquo;карусельному&amp;rdquo; типу - при заполнении базы фиксированного размера RRDTool начинает затирать данные с хвоста базы (то есть со старых) к голове (к новым), что гарантирует потерю минимального количества полезных данных, но при этом позволяет базе не распухать до безумных размеров (как у HP OpenView или Zabbix). Обычно в базе RRDTool есть несколько каруселей - например &amp;ldquo;мгновенные данные&amp;rdquo; (хранятся неделю), среднее за 5 минут (генерируется на основе мгновенных данных, хранятся месяц) и средние за час (генерируются на основе 5минутных, хранятся год. Такая база весит всего несколько мегабайт, и в размерах никогда не меняется (если данных в базе нет, в хвосте карусели просто стоят нули, слоты в базе под данные создаются сразу все). Минус RRDTool в его же плюсе. Нужно очень внимательно расчитывать емкость базы, потому что отредактировать созданную базу уже невозможно, и вытащить данные с целью перенести в другую базу (аналог DUMP в SQL базах) - тоже. Кроме того, RRDTool отвечает только за &lt;strong>хранение&lt;/strong> данных, а их ведь еще откуда-то надо брать&amp;hellip; Изначально админы использовали для этого самописные скрипты &amp;ldquo;на чем печень возжелает&amp;rdquo;, традиционно первые места занимали всесущий Bash и мозголомный Perl (в последнем даже присуствует расширение для работы с RRD, остальные языки вынуждены использовать &amp;ldquo;подпорки&amp;rdquo; в виде вызова rrdtool прямиком из командной строки). Скрипты у всех были разные, качество кода и оптимизация работы таких скриптов гуляла в широчайших пределах. Сам я, на самой заре своей админской карьеры, писал подобные скрипты, причем писал &amp;ldquo;в лоб&amp;rdquo;, простенький скрипт на пяток параметров мог выполнятся несколько секунд. Разумеется, в случае, когда возникает потребность (в инструменте удобного рисования графиков) - возникает и инструмент. Именно таким инструментом стал проект Munin.&lt;/p>
&lt;h3 id="обзор-и-архитектура" >Обзор и архитектура
&lt;span>
&lt;a href="#%d0%be%d0%b1%d0%b7%d0%be%d1%80-%d0%b8-%d0%b0%d1%80%d1%85%d0%b8%d1%82%d0%b5%d0%ba%d1%82%d1%83%d1%80%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Munin состоит из двух раздельных частей. Первая - это сервер (собственно, munin) - он опрашивает клиентов, хранит базу и рисует графики. Вторая - клиент (munin-node). Соединение с клиентом всегда инициирует сервер (он запускается по cron). При запуске сервер читает конфиг со списком адресов клиентов, обращается к каждому клиенту (порт - 4949/tcp), получает список возможных параметров, после чего - по списку - значения параметров. Полученые данные загружаются в RRD-файлы (если таковых нет - сервер их создаст). Рисованием готовых графиков ведает отдельный процесс, который хоть и входит в пакет munin, но живет совершенно самостоятельной жизнью.&lt;/p>
&lt;p>В отличае от сервера, клиент - это постоянно находящийся в памяти демон. Написан он, как и сервер, на чистом perl. К слову сказать, единственный способ авторизации - IP, с которого инициируется соединение. Шифрования там также никакого, так что светить демона не советую, firewall и внимательную настройку конфига никто не отменял. Интересный факт, но сам демон ничего не знает о системе, в которой находится. Данные, которые клиент отдает серверу, он получает от плагинов-программ, которые последовательно запускает. За счет этого оптимизируется нагрузка на сервер (всегда можно оставить только те плагины, которые нужны), и вместе с тем - уменьшается время простоя демона, который уже не должен мучительно выдумывать параметры, которых в данной конкретной системе отродясь не бывало.&lt;/p>
&lt;h2 id="как" >Как
&lt;span>
&lt;a href="#%d0%ba%d0%b0%d0%ba">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;h3 id="установка-и-диагностика" >Установка и диагностика
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d0%b8-%d0%b4%d0%b8%d0%b0%d0%b3%d0%bd%d0%be%d1%81%d1%82%d0%b8%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Как я уже упомниал выше, munin состоит из двух пакетов. Ставятся они тривиально, но нужно быть готовым к тому, что munin (сервер) потащит за собой немалую гору пакетов, отвечающих за RRD и графику (GD). Если мониторить надо один сервер - надо ставить оба пакета (пример для debian):&lt;/p>
&lt;pre>&lt;code>apt-get install munin munin-node
&lt;/code>&lt;/pre>
&lt;p>В отличае от monit, munin не может выполнять никаких действий в системе (кроме сбора статистики), как следствие - его можно запускать сразу после установки. В Debian GNU/Linux и CentOS демон запускается сам:&lt;/p>
&lt;pre>&lt;code>lab:~# ps ax | grep muni
16139 ? Ss 0:00 /usr/sbin/munin-node
&lt;/code>&lt;/pre>
&lt;p>Активация плагинов сделана также просто и незатейливо - в папке с настройками munin (в linux это /etc/munin, а во freebsd - /usr/local/etc/munin) есть папка plugins. Все плагины, присутствующие в папке на момент запуска munin-node считаются активными. Если присутствующий плагин по какой-то причине отказывается работать (например, плагин сбора данных о MySQL при остановленом сервисе mysqld) - node вернет 0 при попытке получения информации из плагина.
На самом деле, все доступные плагины лежат обычно в другом месте, а в эту папку сложены симлинки.
Вот пример:&lt;/p>
&lt;pre>&lt;code>lab:~# ls -al /etc/munin/plugins/
total 2
drwxr-xr-x 2 root root 1024 2009-06-21 15:31 .
drwxr-xr-x 5 root root 1024 2010-02-11 23:35 ..
lrwxrwxrwx 1 root root 29 2009-05-19 16:39 acpi -&amp;gt; /usr/share/munin/plugins/acpi
lrwxrwxrwx 1 root root 28 2009-03-22 22:51 cpu -&amp;gt; /usr/share/munin/plugins/cpu
lrwxrwxrwx 1 root root 27 2009-03-22 22:51 df -&amp;gt; /usr/share/munin/plugins/df
...
&lt;/code>&lt;/pre>
&lt;p>Изначально с munin поставляется немлое количество плагинов (обращаю внимание - активны не все!), кроме того, есть сайты, где также выложены плагины. Кроме того, существует руководство по написанию плагинов самостоятельно, но эта тема уже заметно выходит за рамки статьи.
Некоторые плагины поддерживают аргументы вызова. Вот яркий пример:
Реальные файл плагина&lt;/p>
&lt;pre>&lt;code>-rwxr-xr-x 1 root root 4775 2009-11-25 13:38 if_
-rwxr-xr-x 1 root root 3164 2009-11-25 13:38 if_err_
А вот что лежит в конфигурационной директории:
lab:~# ls -al /etc/munin/plugins/ | grep if
root root 32 2009-03-22 22:51 if_err_eth0 -&amp;gt; /usr/share/munin/plugins/if_err_
root root 32 2009-03-22 22:51 if_err_eth1 -&amp;gt; /usr/share/munin/plugins/if_err_
root root 28 2009-03-22 22:51 if_eth0 -&amp;gt; /usr/share/munin/plugins/if_
root root 28 2009-03-22 22:51 if_eth1 -&amp;gt; /usr/share/munin/plugins/if_
root root 28 2009-06-21 15:31 if_tun0 -&amp;gt; /usr/share/munin/plugins/if_
&lt;/code>&lt;/pre>
&lt;p>Без аргументов подобные плагины вызывать бесполезно - они не будут понимать, чего от них хотят.&lt;/p>
&lt;p>Некоторые плагины поддерживают дополнительные настройки. Например, для плагина, собирающего информацию о MySQL можно задать логин и пароль для входа на сервер. Подобные настройки munin хранит в файле {confdir}/plugin-conf.d/munin-node.&lt;/p>
&lt;p>Файл довольно подробно прокомментирован, но я, на всякий случай, приведу тут пару примеров:&lt;/p>
&lt;pre>&lt;code>#информация для плагина APT
[apt]
#запускать от имени root. В противном случае APT не запускается
user root
#информация для всех плагинов множества smart_,
#эти плагины вызываются по принципу smart_{DISK}
[smart_*]
#опять же, только root сможет прочитать параметры из smartctl
user root
#информация для плагина postgres_queries, база mngsearch
[postgres_queries_mngsearch]
#env.{имя} у каждого плагина могут быть своими.
#Подробно надо смотреть в source-коде плагина
#в данном примере мы задаем имя пользователя и пароль
#для получения данных о работе базы mngsearch
env.PGUSER mngsearch
env.PGPASSWORD Yn2ajPV4f6V5rzqj
&lt;/code>&lt;/pre>
&lt;p>Как можно убедится из примера выше, синтаксис файла очень несложный.&lt;/p>
&lt;h3 id="пошаговые-инструкции" >пошаговые инструкции
&lt;span>
&lt;a href="#%d0%bf%d0%be%d1%88%d0%b0%d0%b3%d0%be%d0%b2%d1%8b%d0%b5-%d0%b8%d0%bd%d1%81%d1%82%d1%80%d1%83%d0%ba%d1%86%d0%b8%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Сворачиваем растекание мыслью по древу. Теперь - четкие и понятные пошаговые инструкции.
Установка пакетов производится средствами ОС, собирать их из SRC не советую. Рассмотрим ситуацию, когда наблюдатель и наблюдаемый - физически одна машина.
Для начала настроим клиент:&lt;/p>
&lt;pre>&lt;code>vi /etc/munin/munin-node.conf
...
log_level 4
#&amp;quot;говорливость&amp;quot; munin в журнале. 10 - режим отладки, 1 - полная тишина
log_file /var/log/munin/munin-node.log
#путь к журналу. Должен уже существовать
pid_file /var/run/munin/munin-node.pid
#pid-file, менять без необходимости не советую
background 1
#режим демона. Для отладки ставим 0 - и нод будет вечно висеть на консоли
setseid 1
user root
group root
#имя владельца процесса.
#У него должны быть права на получение ID каждого имени пользователя,
#от имени которых запускается плагин проверки
#лучше пусть root и остается
setsid yes
#выставлять ID пользователя для каждого плагина. Трогать не советую
allow ^127\.0\.0\.1$
#с какого IP придет запрос сервера. В нашем случае - 127.0.0.1
#обращаю ваше внимание на то, что это регулярное выражение (RegExp).
host 127.0.0.1
#к какому IP привязывать демон. В данном примере - к 127.0.0.1
port 4949
#соовтвественно, порт.
&lt;/code>&lt;/pre>
&lt;p>Изменение конфига или списка плагинов требует перезапуска демона. При изменении списка плагинов нужно именно перезапускать демона, kill -HUP в данной ситуации не поможет.&lt;/p>
&lt;p>Проверяем работу демона:&lt;/p>
&lt;pre>&lt;code>lab:/etc/munin# telnet 127.0.0.1 4949
Trying 127.0.0.1...
Connected to 127.0.0.1.
Escape character is '^]'.
# munin node at lab.local.logan
list
open_inodes ip_127.0.0.1 postgres_queries_mngsearch irqstats
if_eth0 squid_cache sensors_temp df tor_connections swap
load cpu df_inode smart_hda forks iostat sensors_fan open_files
memory postgres_queries_netams exim_mailqueue vmstat sensors_volt
if_err_eth0 entropy processes acpi interrupts mysql_bytes if_tun0 if_err_eth1
if_eth1 tor_traffic exim_mailstats
fetch ip_127.0.0.1
in.value 83599135
out.value 83599135
.
quit
Connection closed by foreign host.
&lt;/code>&lt;/pre>
&lt;p>Командной list мы получили список активных плагинов, командой fetch - получили данные из одного плагина. Демон мониторинга ведет себя точно также, что позволяет с высокой степенью достоверности убедится в правильности работы клиента-нода.&lt;/p>
&lt;p>Теперь переходим к серверу. В отличае от клиента (нода) - сервер не существует как процесс, он запускается только в моменты получения данных и рисования графиков (и то не всегда, этот вопрос будет рассмотрен ниже)
В списке процессов выглядит это вот так:&lt;/p>
&lt;pre>&lt;code>lab:~# ps ax | grep muni
16139 ? Ss 0:00 /usr/sbin/munin-node
17842 ? S 0:00 /bin/sh /usr/bin/munin-cron
17843 ? S 0:00 /usr/bin/perl -w /usr/share/munin/munin-update
17846 ? S 0:00 /usr/share/munin/munin-update [r1sz.zooclub.ru]
17847 ? S 0:00 /usr/share/munin/munin-update [web1.zooclub.ru]
17848 ? S 0:00 /usr/share/munin/munin-update [monitor-01.infobox.ru]
17849 ? S 0:00 /usr/share/munin/munin-update [stat.kpp.ru]
17851 ? S 0:00 /usr/share/munin/munin-update [ro2-h.local]
17852 ? S 0:00 /usr/share/munin/munin-update [ro1-h.local]
17853 ? S 0:00 /usr/sbin/munin-node
&lt;/code>&lt;/pre>
&lt;p>Настройки демона находятся в файле {config}/munin.conf
Он также очень подробно откомментирван, и ниже я приведу минимальный работоспособный пример.&lt;/p>
&lt;pre>&lt;code>dbdir /home/db/monitor
#место, где хранятся RRD. Путь должен существовать, а rrd демон создаст сам
htmldir /home/www/mon
#куда выкладывать готовые графики
logdir /var/log/munin
#где лежат логи
rundir /var/run/munin
#Описания серверов
[lab.local]
address 127.0.0.1
use_node_name yes
#эта директива нужна, на страничке с графиками отображалось имя узла, а не его адрес.
[midori.local]
#другой сервер, в той же группе
address 10.9.8.7
use_node_name yes
[web2.zooclub.ru]
#сервер в другой группе
address 77.221.150.98
use_node_name yes
contact.logan.command mail -s &amp;quot;Munin notification&amp;quot; logan@mydomain.my
#слать сообщения об ошибках.
#Информацию об ошибке сервер принимает от клиента.
#Изменение статуса (ОК&amp;lt;-&amp;gt;ОШИБКА) будет сопровождатся письмом
#graph_strategy cgi
#можно использовать CGI для отрисовки графиков вместо отрисовки по крону.
#Это уменьшает нагрузку на сервер, если графики смотрят редко.
#Если графики смотрят часто (или много народу) - вы уложите сервер.
&lt;/code>&lt;/pre>
&lt;p>Указаных выше настроек вполне хватит для нормальной работы. Более подробно эти настройки указаны в документации, но ждать многого от munin не надо - это полезный, но очень простой и ограниченый инструмент.&lt;/p>
&lt;h3 id="обслуживание" >Обслуживание
&lt;span>
&lt;a href="#%d0%be%d0%b1%d1%81%d0%bb%d1%83%d0%b6%d0%b8%d0%b2%d0%b0%d0%bd%d0%b8%d0%b5">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h3>&lt;p>Munin имеет простейшее устройство, строго в рамках unix-way. Периодического обслуживания он не требует, а непереодическое - осуществляется очень просто. Разберем основные случаи:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Жрет процессор и/или рисует графики с разрывами. Важно - Разрывы в рамках одной ноды на графиках расположены по-разному. Основная причина - не успевает отрабатывать процесс рисования (munin-graph). Надо либо уменьшить количество параметров, которые munin получает с нод (удалив там неиспользуемые плагины), либо перенастроить munin на fcgi режим (графики будут отрисованы при обращении), либо переезжать на другую машину.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>График не рисуется совсем или не обновляется. Проблема в правах доступа на папку, куда munin-graph складывает графики. По умолчанию владелец папки должен быть munin, права на запись, чтение и вхождение в папку у него должны быть. Узнать, кто точно владеет папкой, поможет команда&lt;/p>
&lt;p>ps auxww | grep graph&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Как мигрировать munin server (вариант - сделать резервную копию). Чтобы перенести munin - достаточно перенести папку dbdir из конфигурации. Точно соблюдать версию при переносе не обязательно, munin очень давно не меняет структуру баз при обновлении версии. Папки с графиком переносить совершенно не обязательно, munin всегда рисует графики с нуля, основываясь на данных из базы.&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Обновление дистрибутива debian до 6 версии</title><link>https://prudnitskiy.pro/post/2011-08-18-debian-update-distro/</link><pubDate>Thu, 18 Aug 2011 05:28:30 +0000</pubDate><guid>https://prudnitskiy.pro/post/2011-08-18-debian-update-distro/</guid><description>&lt;p>В свете выхода нового стабильного релиза любимого мною дистрибутива Debian (Squeeze, 6.0) - краткая инструкция по обновлению дистрибутива до нового релиза.&lt;/p>
&lt;h2 id="предварительно" >Предварительно:
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%b5%d0%b4%d0%b2%d0%b0%d1%80%d0%b8%d1%82%d0%b5%d0%bb%d1%8c%d0%bd%d0%be">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;ul>
&lt;li>Не рекомендуется использовать слова-состояния дистрибутива в конфигурации apt (stable, unstable, testing) - рекомендуется использовать имена собственные дистрибутивов&lt;/li>
&lt;li>Не рекомендуется использовать российские зеркала, особенно - в первые дни после выхода дистрибутива. Питерцы могут использовать зеркало в Финляндии, москвичи - английское, Владивостокцы - напрямую американское, оно ближе. Российские зеркала в первые недели выхода релиза практически неработоспособны (Yandex, например, по сию пору имеет несколько поврежденных критически важных пакетов, а на chg.ru несколько пакетов и вовсе закрыты 403 ошибкой)&lt;/li>
&lt;li>Бекап никто не отменял, особенно это касается удаленных серверов.&lt;/li>
&lt;li>Если используются хитрые правила монтирования - рекомендуется временно их отключить. Как минимум, необходимо дать права на запись / и /boot и разрешить выполнение файлов в /var&lt;/li>
&lt;/ul>
&lt;h2 id="инструкция" >Инструкция:
&lt;span>
&lt;a href="#%d0%b8%d0%bd%d1%81%d1%82%d1%80%d1%83%d0%ba%d1%86%d0%b8%d1%8f">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Меняем настройки apt:&lt;/p>
&lt;pre>&lt;code>#deb ftp://ftp.fi.debian.org/debian/ etch main contrib non-free
#deb-src ftp://ftp.fi.debian.org/debian/ etch main contrib non-free
deb ftp://ftp.fi.debian.org/debian/ squeeze main contrib non-free
deb-src ftp://ftp.fi.debian.org/debian/ squeeze main contrib non-free
#deb http://security.debian.org/ etch/updates main
#deb-src http://security.debian.org/ etch/updates main
deb http://security.debian.org/ squeeze/updates main
deb-src http://security.debian.org/ squeeze/updates main
#deb http://volatile.debian.org/debian-volatile squeeze/volatile main
#deb-src http://volatile.debian.org/debian-volatile squeeze/volatile main
&lt;/code>&lt;/pre>
&lt;p>Выгружаем кеш пакетов:&lt;/p>
&lt;p>&lt;code>sudo apt-get update&lt;/code>&lt;/p>
&lt;p>Обновляем сам apt:&lt;/p>
&lt;pre>&lt;code>sudo aptitude install apt dpkg aptitude
&lt;/code>&lt;/pre>
&lt;p>Обновляем операционную систему&lt;/p>
&lt;pre>&lt;code>sudo aptitude full-upgrade
&lt;/code>&lt;/pre>
&lt;p>&lt;strong>Важно!&lt;/strong> При обновлении aptitude замещает часть файлов. О каждом случае замещения он подробно пишет. Это обязательно нужно читать, чтобы не получить неожиданный трудноуловимый сюрприз&lt;/p>
&lt;p>Перезагружаемся и обновляем свежеобновленную систему:&lt;/p>
&lt;pre>&lt;code>sudo apt-get update &amp;amp;&amp;amp; sudo apt-get upgrade
&lt;/code>&lt;/pre>
&lt;p>Снова перезагружаемся и проверяем, что все обновилось:&lt;/p>
&lt;pre>&lt;code>cat /etc/debian_version
6.0.1
apt-get update &amp;amp;&amp;amp; apt-get upgrade
&lt;/code>&lt;/pre></description></item><item><title>Monit - наблюдатель за системными процессами</title><link>https://prudnitskiy.pro/post/2011-06-23-monit-howto/</link><pubDate>Thu, 23 Jun 2011 08:16:22 +0000</pubDate><guid>https://prudnitskiy.pro/post/2011-06-23-monit-howto/</guid><description>&lt;p>Monit - самостоятельный демон, работающий от пользователя root. Демон работает на Linux, Free/Net/OpenBSD, SUN Solaris и некоторых других UNIX-системах. Это OpenSource проект, у которого есть &amp;ldquo;старший брат&amp;rdquo; - коммерческий проект MMonit. Последний обладает более широким функционалом в вопросе массового мониторинга, межсетевого взаимодействия и составления отчетов. Идея авторов проста - для одиночного сервера используем Monit, для большой сетевой фермы - MMonit.&lt;/p>
&lt;p>В зависимости от настроек, демон может проверять:&lt;/p>
&lt;ul>
&lt;li>Существование процесса по PID&lt;/li>
&lt;li>Работу определенного порта (TCP/UDP)&lt;/li>
&lt;li>Ответ определенного протокола по определенному порту (SMTP, SSH, HTTP&amp;hellip;)&lt;/li>
&lt;li>Ресурсы, занимаемые процессом (CPU time/RAM)&lt;/li>
&lt;li>MD5 checksum&lt;/li>
&lt;li>Объем и свободное пространство в файловой системе&lt;/li>
&lt;li>Количество активных (и суммарное) i-node-в&lt;/li>
&lt;li>Права доступа к файлу или каталогу&lt;/li>
&lt;/ul>
&lt;p>Никто не запрещает комбинировать различные методы проверки. Для одного объекта проверки (тесты) зависят друг от друга, то есть сначала проводится тест1, если он прошел без ошибок - тест2, затем - тест3 и т.д.&lt;/p>
&lt;p>В случае, если какой-то тест не пройден, monit может:&lt;/p>
&lt;ul>
&lt;li>Остановить, стартовать или перезапустить демона&lt;/li>
&lt;li>Подождать определенное время&lt;/li>
&lt;li>Уведомить админа (почтовым сообщением)&lt;/li>
&lt;li>Примонтировать, отмонтировать или перемонтировать файловую систему&lt;/li>
&lt;li>Запустить отдельный скрипт (заранее написаный админом), причем передать ему определенные параметры (имя процеса/текст ошибки и т.д.)&lt;/li>
&lt;/ul>
&lt;p>Действия также никто не запрещает комбинировать, например:
Если HTTPd занимает более 200 мегабайт - ждать минуту, если ничего не изменилось - перезапустить сервис, если это также не помогло - прождать пять минут. Если и это не помогло - остановить сервис и уведомить админа письмом.&lt;/p>
&lt;p>И еще. У Monit есть собственный http-сервер. Злоупотреблять им не стоит, так как работает он с рутовыми привелегиями, но иметь доступ к веб-консоли может быть крайне полезным. Вебсервер будет рассмотрен отдельно, в этой же статье.&lt;/p>
&lt;h2 id="установка-и-настройка" >Установка и настройка
&lt;span>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0-%d0%b8-%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b0">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Монит есть практически во всех широко распространенных дистрибутивах. В Debian, CentOS и Suse он так и называется. Во FreeBSD лежит в {PORTS}/sysmgmt/monit. Ставится он стандартным для операционной системы способом, и я не буду на нем остонавливатся.
Результатом установки будет собственно демон (monit) и файл конфигурации, который живет тут:&lt;/p>
&lt;pre>&lt;code># Linux, Solaris:
/etc/monit/monitrc
# FreeBSD/OpenBSD/NetBSD
/usr/local/etc/monit/monitrc
&lt;/code>&lt;/pre>
&lt;p>Конфиг очень подробно документирован, его рекомендуется почитать. Там есть подробные примеры и вообще много чего интересного. В принципе большую часть дефолтных настроек можно не трогать, ограничившись только необходимыми изменениями:&lt;/p>
&lt;pre>&lt;code># процесс работает как демон, цикл проверки - 120 секунд.
# длительность цикла можно менять, это основная еденица времени для monit.
# Раз в цикл срабатывают проверки и выполняются команды от админа,
# присланые через веб-интерфейс
set daemon 120
# сервера, через которые пойдет почтовое уведомление.
# Можно делать несколько, очередность срабатывания повторяет очередность внесения
set mailserver mail.zooclub.ru 10025,
localhost
# кто получит уведомление?
set alert sysadmin@zooclub.ru
&lt;/code>&lt;/pre>
&lt;p>Информацию о том, что monit должен проверять, можно хранить и в отдельном файле (файлах), которые подключаются в основной конфиг командой include:&lt;/p>
&lt;pre>&lt;code># один файл
include /etc/devel/monitcheck.monitconf
# все файлы с расширением из папки.
include /etc/stable/monit/*
&lt;/code>&lt;/pre>
&lt;p>Мне кажется, что удобнее хранить проверку каждого сервиса в отдельном файле - это облегчает отладку и упрощает администрирование.&lt;/p>
&lt;p>Мониторим состояние сервера в целом:&lt;/p>
&lt;pre>&lt;code>check system ws1.zooclub.ru
if loadavg (1min) &amp;gt; 4 then alert
if loadavg (5min) &amp;gt; 2 then alert
if memory usage &amp;gt; 75% then alert
if cpu usage (user) &amp;gt; 90% then alert
if cpu usage (system) &amp;gt; 40% then alert
if cpu usage (wait) &amp;gt; 20% then alert
&lt;/code>&lt;/pre>
&lt;p>Файловые системы:&lt;/p>
&lt;pre>&lt;code># /etc/stable/monit/filesystem.conf
# проверяем устройство по точке монтирования.
# Можно проверять диски напрямую (/dev/hda).
# C LVM и прочими логическими &amp;quot;дисками&amp;quot; этот фокус не прокатит,
# их проверять можно только по точке монтирования и никак иначе.
check device homefs with path /home
start program = &amp;quot;/bin/mount /home&amp;quot;
stop program = &amp;quot;/bin/umount /home&amp;quot;
if failed permission 755 then alert
if failed uid root then alert
# Если места остается меньше 20% минимум пять проверок за последние 15
# бить в набат и больше ничего не делать.
# При любой своей активности monit будет предупреждать админа письмом.
if space usage &amp;gt; 80% for 5 times within 15 cycles then alert
# Место кончилось, отмонтировать файлсистему
if space usage &amp;gt; 99% then stop
# аналогично про i-nodes.
if inode usage &amp;gt; 80% then alert
if inode usage &amp;gt; 99% then stop
group server
check device rootfs with path /
start program = &amp;quot;/bin/mount /&amp;quot;
# Потерять / во время работы сервера - безрадостная перспектива.
# По этому если дело плохо - просто перемонтируем его в read-only
stop program = &amp;quot;/bin/mount -o remount,ro /&amp;quot;
if failed permission 755 then unmonitor
if failed uid root then unmonitor
if space usage &amp;gt; 80% for 5 times within 15 cycles then alert
if space usage &amp;gt; 99% then stop
if inode usage &amp;gt; 80% then alert
if inode usage &amp;gt; 99% then stop
group server
check device bootfs with path /boot
start program = &amp;quot;/bin/mount /boot&amp;quot;
stop program = &amp;quot;/bin/mount -o remount,ro /boot&amp;quot;
# эта конструкция &amp;quot;отключит&amp;quot; тестирование файлсистемы, если права на папку - не 755
if failed permission 755 then unmonitor
if failed uid root then unmonitor
if space usage &amp;gt; 80% for 5 times within 15 cycles then alert
if space usage &amp;gt; 99% then stop
if inode usage &amp;gt; 80% then alert
if inode usage &amp;gt; 99% then stop
group server
&lt;/code>&lt;/pre>
&lt;p>Теперь проверим работу веб-сервера apache:&lt;/p>
&lt;pre>&lt;code># /etc/stable/monit/apache.conf
# проверка файла (размер, права доступа и тп):
check file apache_bin with path /usr/local/apache/bin/httpd
if failed checksum and
# sum - это стандартный md5-хэш.
# Его можно получить, натравив программу md5sum на нужный файл
expect the sum 8f7f419955cefa0b33a2ba316cba3659 then unmonitor
if failed permission 755 then unmonitor
if failed uid root then unmonitor
if failed gid root then unmonitor
# отдельное письмо на отдельный адрес и с отдельным содержимым.
alert security@zooclub.ru on {
checksum, permission, uid, gid, unmonitor
} with the mail-format { subject: Alarm! }
group server
# проверка процесса осуществляется по pid-файлу. Путь к pid-файлу всегда абсолютный
check process apache with pidfile /var/run/apache2.pid
start program = &amp;quot;/etc/init.d/apache2 start&amp;quot;
stop program = &amp;quot;/etc/init.d/apache2 stop&amp;quot;
if cpu &amp;gt; 60% for 2 cycles then alert
# если вебсервер сожрал 80% процессрного времени
# и не отдает его пять циклов проверки подряд - рестартуем его
if cpu &amp;gt; 80% for 5 cycles then restart
# аналогично по суммарной памяти, которую он поглотил.
if totalmem &amp;gt; 500.0 MB for 5 cycles then restart
if children &amp;gt; 250 then restart
# если load average сервера за 5 минут больше 10 8 циклов подряд - вырубаем.
if loadavg(5min) greater than 10 for 8 cycles then stop
# вот тут самое интересное - многоэтапная проверка:
# первый шаг - подключение на 80 порт, протокол http
if failed host 127.0.0.1 port 80 protocol http
# если получилось - запрашиваем файл /index.html
and request &amp;quot;/index.html&amp;quot;
with timeout 15 seconds
# а если что-то из цепочки не получилось - рестартуем демон
then restart
# проверка HTTP-SSL.
# Монит отдельно рассматривает SSL, и отдельно - защищаемый протокол.
# Для того, чтобы иметь возможность проводить такие проверки -
# нужно собрать monit с поддержкой SSL.
# Любители FreeBSD - будьте внимательны при сборке!
if failed port 443 type tcpssl protocol http
and request &amp;quot;/test.html&amp;quot;
with timeout 15 seconds
then restart
# если за последние пять циклов проверки было три рестарта или больше
# - пропускаем один цикл проверки.
if 3 restarts within 5 cycles then timeout
# проверку имеет смысл проводить только,
# если пройдена первая проверка (которая права доступа и проч).
# В противном случае все тесты безсмысленны.
depends on apache_bin
group server
&lt;/code>&lt;/pre>
&lt;p>OpenSSHD:&lt;/p>
&lt;pre>&lt;code>check process sshd with pidfile /var/run/sshd.pid
start program &amp;quot;/etc/init.d/ssh start&amp;quot;
stop program &amp;quot;/etc/init.d/ssh stop&amp;quot;
if failed port 22 protocol ssh then restart
if 5 restarts within 5 cycles then timeout
group server
&lt;/code>&lt;/pre>
&lt;p>OpenVPN. Проверяем только наличие процесса:&lt;/p>
&lt;pre>&lt;code>check process openvpn with pidfile /var/run/openvpn.link1.pid
group system
start program = &amp;quot;/etc/init.d/openvpn start&amp;quot;
stop program = &amp;quot;/etc/init.d/openvpn stop&amp;quot;
if 5 restarts within 5 cycles then timeout
&lt;/code>&lt;/pre>
&lt;p>PostgreSQL. Проверяем доступность через TCP-порт и сокет&lt;/p>
&lt;pre>&lt;code>check process postgres with pidfile /var/run/postgresql/main.pid
group database
start program = &amp;quot;/etc/init.d/postgresql start&amp;quot;
stop program = &amp;quot;/etc/init.d/postgresql stop&amp;quot;
if failed unixsocket /tmp/.s.PGSQL.5432 protocol pgsql then restart
if failed host 127.0.0.1 port 5432 protocol pgsql then restart
if 5 restarts within 5 cycles then timeout
group database
&lt;/code>&lt;/pre>
&lt;p>Исчерпывающий список протоколов и вариантов проверки можно почерпнуть в &lt;a href="http://mmonit.com/monit/documentation/monit.html">документации&lt;/a>. Правда, она на англ языке.&lt;/p>
&lt;h2 id="веб-интерфейс" >Веб-интерфейс
&lt;span>
&lt;a href="#%d0%b2%d0%b5%d0%b1-%d0%b8%d0%bd%d1%82%d0%b5%d1%80%d1%84%d0%b5%d0%b9%d1%81">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Как я уже писал во вступлении, у monit есть небольшая, но довольно полезная вебморда.
Пример настройки:&lt;/p>
&lt;pre>&lt;code>#включить веб-интерфейс на определенный порт
set httpd port 10001 and
#включить SSL
ssl enable
#где взять pem-файл. Нужен для ssl, подробно ниже
pemfile /etc/monit/monit.pem
#на каком адресе (интерфейсе) слушать.
#если адрес не указать - слушать будет на всех
use address 10.10.10.21
#разрешить доступ только с определенных адресов
#строго рекомендуется!
allow 10.10.10.22/32
allow 10.10.12.0/24
#разрешить доступ только знающим пароль.
#пароль, к сожалению, хранится в открытом виде
allow senegami:aoLouch0aingahce
allow logan:Jefae2Othaitae1S
&lt;/code>&lt;/pre>
&lt;p>Теперь о pem-файле. Веб-сервер monit довольно примитивный, и ему нужно иметь ssl сертификат, ключ от него и DH-файл в одном объекте. Собственно, он и называется pem-файлом. Готовится следующим образом. Сначала создадим шаблон для сертификата:&lt;/p>
&lt;pre>&lt;code>----- BEGIN:monit.cnf -----
RANDFILE = ./openssl.rnd
[ req ]
default_bits = 1024
encrypt_key = yes
distinguished_name = req_dn
x509_extensions = cert_type
[ req_dn ]
countryName = Country Name (2 letter code)
countryName_default = RU
stateOrProvinceName = State or Province Name (full name)
stateOrProvinceName_default = NorthWest
localityName= Locality Name (eg, city)
localityName_default= Saint Petersburg
organizationName= Organization Name (eg, company)
organizationName_default= AnyOne LLC
organizationalUnitName= Organizational Unit Name (eg, section)
organizationalUnitName_default= Net
commonName= Common Name (FQDN of your server)
commonName_default= ws1.zooclub.ru
emailAddress= Email Address
emailAddress_default= security@zooclub.ru
[ cert_type ]
nsCertType = server
----- END:monit.cnf -----
&lt;/code>&lt;/pre>
&lt;p>Разумеется, нужно поменять значения под необходимые конкретно вам&lt;/p>
&lt;p>Затем соберем из шаблона сертификат:&lt;/p>
&lt;pre>&lt;code>openssl req -new -x509 -days 720 -nodes \
-config ./monit.cnf -out /etc/monit/monit.pem \
-keyout /var/certs/monit.pem
#Генерируем число Диффи-Хеллмана и прячем его в тот же файл
openssl gendh 512 &amp;gt;&amp;gt; /etc/monit/monit.pem
#проверяем читаемость сертификата
openssl x509 -subject -dates -fingerprint -noout -in /etc/monit/monit.pem
#Поскольку в файле лежит серкретный ключ сертификата - уменьшим права доступа
chmod 400 /etc/monit/monit.pem
openssl gendh 512 &amp;gt;&amp;gt; /etc/monit/monit.pem
&lt;/code>&lt;/pre>
&lt;p>После чего перезапускаем монит и любуемся :)&lt;/p></description></item><item><title>Шифрование дисков через EFS в Linux</title><link>https://prudnitskiy.pro/post/2011-06-20-efs-disc-encryption/</link><pubDate>Mon, 20 Jun 2011 07:20:36 +0000</pubDate><guid>https://prudnitskiy.pro/post/2011-06-20-efs-disc-encryption/</guid><description>&lt;p>Linux в целом - достаточно защищенная система. При условии сложных паролей и своевременных обновлений (а также - нормального firewall-а) сломать его с целью получения данных достаточно трудно. Однако в случае физического доступа к машине достаточно просто загрузится с другого диска (например, с диска Slax) &amp;ndash; и с файловой системой можно делать все, что угодно. Дабы противостоять такой атаке &amp;ndash; придумана шифрованая файлсистема. В данной статье пошагово описано создание шифрованой файлсистемы (шифр - AES128) на &lt;em>отдельном разделе диска&lt;/em>, авторизация по паролю (keyword). Статья писалась под Xubuntu linux (Debian), хотя в принципе для других версий Linux принципиальных различий не будет.&lt;/p>
&lt;h2 id="как-это-работает" >как это работает?
&lt;span>
&lt;a href="#%d0%ba%d0%b0%d0%ba-%d1%8d%d1%82%d0%be-%d1%80%d0%b0%d0%b1%d0%be%d1%82%d0%b0%d0%b5%d1%82">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>В отличае от windows (XP/2003) Linux использует ту же файловую систему, что и обычно, но с &amp;ldquo;промежуточным звеном&amp;rdquo;.
Создание шифрованого раздела идет в два этапа - сначала нужно создать &amp;ldquo;промежуточное звено&amp;rdquo; (оно называется CryptoLoop), а затем сквозь эту петлю отформатировать диск. Дальнейшее обращение к диску идет через петлю, которая все по дороге зашифровывает (или наоборот - расшифровывает). Если не создать петлю (для каждого диска она своя, для подключения к петле нужно либо знать пароль - либо иметь сертификат) &amp;ndash; данные с диска прочитать не получится, они превратятся в высокоэнтропийную кашу. В данной статье пошагово описано создание шифрованой файлсистемы (шифр - AES128), авторизация по паролю (keyword). Статья писалась под Xubuntu linux (Debian), хотя в принципе для других версий Linux принципиальных различий не будет. &lt;em>ВАЖНО! При создании петли диск надо форматировать, все данные на нем будут потеряны. ОБЯЗАТЕЛЬНО запишите где-нибудь пароль от диска (или сделайте резервную копию сертификата, если используется он). Если вы забудете/посеете ключ - диск уже не расшифруете никогда, AES128 - очень надежный шифровальный стандарт. И данные с него будут потеряны безвозвратно&lt;/em>&lt;/p>
&lt;h2 id="начали" >Начали!
&lt;span>
&lt;a href="#%d0%bd%d0%b0%d1%87%d0%b0%d0%bb%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Для начала проверим, есть ли у нас необходимые модули:&lt;/p>
&lt;pre>&lt;code>/sbin/modinfo /lib/modules/`uname -r`/kernel/crypto/*
filename: /lib/modules/2.6.20-16-generic/kernel/crypto/aes.ko
license: Dual BSD/GPL description: Rijndael (AES) Cipher Algorithm
srcversion: 8CB82B3A254D5A950FD0D14 depends:
vermagic: 2.6.20-16-generic SMP mod_unload 586
filename: /lib/modules/2.6.20-16-generic/kernel/crypto/anubis.ko
description: Anubis Cryptographic Algorithm
license: GPL
srcversion: F88E14F122B9D232FFF5811
depends:
vermagic: 2.6.20-16-generic SMP mod_unload 586
filename: /lib/modules/2.6.20-16-generic/kernel/crypto/arc4.ko
author: Jon Oberheide
&lt;/code>&lt;/pre>
&lt;p>Отлично, модули есть. Если у вас их нет &amp;ndash; придется пересобирать ядро. Нужны как минимум aes, dm_mod и dm_crypt Теперь указываем, какие модули по умолчанию будут грузится. Делать это надо от рута:&lt;/p>
&lt;pre>&lt;code>echo aes &amp;gt;&amp;gt; /etc/modules
echo dm_mod &amp;gt;&amp;gt; /etc/modules
echo dm_crypt &amp;gt;&amp;gt; /etc/modules
&lt;/code>&lt;/pre>
&lt;p>Перезагружаемся и смотрим:&lt;/p>
&lt;pre>&lt;code>lsmod |grep aes
aes 28608 0
lsmod |grep dm_mod
dm_mod 59084 1 dm_crypt
lsmod |grep dm_crypt
dm_crypt 14856 0
&lt;/code>&lt;/pre>
&lt;p>Модули есть, начинаем создавать петлю. В данном примере я создам петлю на диск /dev/sda7. Вам, соответственно, нужно создавать петлю на свой раздел. Помните о том, что после первого же обращения на диск через петлю он становится &lt;i>нечитаемым&lt;/i> вне петли. И все, что на нем было - исчезнет.
Для начала - отмонтируем диск. Все действия ведем от рута:&lt;/p>
&lt;pre>&lt;code>umount -f /dev/sda7
&lt;/code>&lt;/pre>
&lt;p>Для создания устройства cryptoloop нам нужна специальная утилита под названием cryptsetup
устанавливаем:&lt;/p>
&lt;pre>&lt;code>apt-get install cryptsetup
&lt;/code>&lt;/pre>
&lt;p>Теперь создадим спецустройство CryptoLoop:&lt;/p>
&lt;pre>&lt;code>cryptsetup --verbose --verify-passphrase create cryptohd /dev/sda7
&lt;/code>&lt;/pre>
&lt;p>Подробно о том, что тут написано:&lt;/p>
&lt;ul>
&lt;li>&amp;ndash;verbose &amp;ndash; показать процесс создания по возможности подробно&lt;/li>
&lt;li>&amp;ndash;verify-passphrase &amp;ndash; использовать пароль (а не ключ или сертификат)&lt;/li>
&lt;li>create &amp;ndash; создать новое криптоустройство. подробнее будет рассказано ниже&lt;/li>
&lt;li>cryptohd &amp;ndash; название криптопетли. Оно может состоять из букв и цифр. Нужно для того, чтобы определить название именно шифрованое имя диска.В пределах одной системы должно быть уникальным.&lt;/li>
&lt;li>/dev/sda7 &amp;ndash; название устройства, на которое будет привязана криптопетля. Данные на нем станут шифроваными.&lt;/li>
&lt;/ul>
&lt;p>Выполняем команду и вводим пароль. Именно этот пароль шифрует данные, не потеряйте его!&lt;/p>
&lt;pre>&lt;code>cryptsetup --verbose --verify-passphrase create cryptohd /dev/sda7
Enter passphrase:
Repeat passphrase:
&lt;/code>&lt;/pre>
&lt;p>Замечу, что по хорошей традиции UNIX-мира, ввод пароля никак не отображается. Смотрим, как там наша петля:&lt;/p>
&lt;pre>&lt;code>cryptsetup status cryptohd
/dev/.static/dev/mapper/cryptohd is active:
cipher: aes-cbc-plain
keysize: 256 bits
device: /dev/sda7
offset: 0
sectors size: 2008062 sectors
mode: read/write
&lt;/code>&lt;/pre>
&lt;p>Отлично, петля есть Форматируем диск:&lt;/p>
&lt;pre>&lt;code>mkfs.reiserfs /dev/mapper/cryptohd
&lt;/code>&lt;/pre>
&lt;p>И монтируем диск:&lt;/p>
&lt;pre>&lt;code>mount /dev/mapper/cryptohd /cryptohd
&lt;/code>&lt;/pre>
&lt;p>Не забудьте создать папку, куда будете монтировать диск:&lt;/p>
&lt;pre>&lt;code>mkdir /cryptohd
&lt;/code>&lt;/pre>
&lt;p>смотрим, что получилось:&lt;/p>
&lt;pre>&lt;code>mount
/dev/mapper/cryptohd /cryptohd
&lt;/code>&lt;/pre>
&lt;p>Теперь можно обращаться к диску и работать с ним. Отвязывается он, в общем, несложно. Сначала его отмонтируем, а затем &amp;ndash; разрушим криптопетлю:&lt;/p>
&lt;pre>&lt;code>umount -f /dev/mapper/cryptohd
cryptsetup remove cryptohd
&lt;/code>&lt;/pre>
&lt;p>смотрим на информацию о петле:&lt;/p>
&lt;pre>&lt;code>cryptsetup status cryptohd
/dev/mapper/.static/cryptohd is inactive
&lt;/code>&lt;/pre>
&lt;p>все, диск уже нечитаем, до момента создания криптопетли он бесполезен:&lt;/p>
&lt;pre>&lt;code>mount /dev/sda7 mount: filesystem is invalid or not known
&lt;/code>&lt;/pre>
&lt;p>Чтобы его прочитать, создаем петлю:&lt;/p>
&lt;pre>&lt;code>cryptsetup create cryptohd /dev/sda7
Enter passphrase:
&lt;/code>&lt;/pre>
&lt;p>И монтируем диск:&lt;/p>
&lt;pre>&lt;code>mount /dev/mapper/cryptohd /cryptohd
&lt;/code>&lt;/pre>
&lt;p>теперь файловая система вновь доступна&lt;/p></description></item><item><title>Эмуляция Juniper M на PC</title><link>https://prudnitskiy.pro/post/2009-07-11-juniper-emu/</link><pubDate>Sat, 11 Jul 2009 18:04:41 +0000</pubDate><guid>https://prudnitskiy.pro/post/2009-07-11-juniper-emu/</guid><description>&lt;p>И снова доброго утречка. В данной статье я рассажу о своем опыте эмуляции Juniper M-серии в домашних условиях и о тех трудностях, которые ждут экспериментаторов. Замечу, что данная статья является творческой компиляцией из &lt;a href="http://juniper.cluepon.net/index.php/Olive">этого&lt;/a>, &lt;a href="http://www.smogey.net/tech/Juniper/Olive/index.htm">этого&lt;/a> и вот &lt;a href="">этого&lt;/a>, щедро сдобреного собственным опытом и несколько лишенным воды. Если этой статьи вам мало - добро пожаловать в первоисточники :)&lt;/p>
&lt;h2 id="преамбула-сестра-скальпель" >Преамбула: Сестра, скальпель!
&lt;span>
&lt;a href="#%d0%bf%d1%80%d0%b5%d0%b0%d0%bc%d0%b1%d1%83%d0%bb%d0%b0-%d1%81%d0%b5%d1%81%d1%82%d1%80%d0%b0-%d1%81%d0%ba%d0%b0%d0%bb%d1%8c%d0%bf%d0%b5%d0%bb%d1%8c">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Основным плюсом для нас будет то, что Juniper Networks использует в качестве базы для своих решений x86 архитектуру (в частности M5 имеет на борту 500-й селерон, а Contiva 3000 - вообще 233-й). Кроме того, Juniper базируется на FreeBSD. Знание этих двух фокусов позволит нам достаточно успешно и недорого сэмулировать реальный маршрутизер. В отличие от Dynamips потери производительности будут минимальны, а если установить JunOS на реальную машину - вообще незаметны. Правда, установить реальный JunOS не так-то просто&amp;hellip; Но если очень захотеть - можно. А эмулировать так вообще - сплошное удовольствие :)&lt;/p>
&lt;p>Итак. В качестве платформы эмуляции я использовал Debian/GNU linux, в статье рассматриваю именно его.
Предварительная подготовка:
Потребуется готовая система Debian (графика не обязательна). Памяти - 512 минимум, 256 уйдет на эмулятор. 2 гига места на харде. Наличие второй сетевой карты, которую скормим эмулятору - не обязательно, но рекомендуется. Наличие широкого канала в инет строго рекомендуется, будем качать.
Поехали:
для начала нам потребуется эмулятор qemu. Причем простой не подходит, нужно патчить. Вытаскиваем инструменты для эмулятора:&lt;/p>
&lt;pre>&lt;code>apt-get build-dep qemu
apt-get install libpcap libcap-dev
apt-get install svntools
&lt;/code>&lt;/pre>
&lt;p>Сразу говорю - ставится будет немалое количество пакетов, это полный набор всех необходимых файлов для сборки qemu из исходного кода + компиляторы и библиотеки. lpcap нужен для непосредственного подсоединения эмулятора к сети. Можно собрать без него, но тогда эмулятор можно будет цеплять только к соседям или через tap-интерфейс, это сложнее.&lt;/p>
&lt;p>Теперь тянем собственно qemu:&lt;/p>
&lt;pre>&lt;code>mkdir ~/src
cd ~/src
svn co svn://svn.savannah.nongnu.org/qemu/trunk -r 5193
&lt;/code>&lt;/pre>
&lt;p>Это достаточно старая версия, но нам она подойдет. Новую версию тащить &lt;i>не советую&lt;/i> - будут проблемы при сборке libpcap&lt;/p>
&lt;p>Патчим свежеприобретенный код:&lt;/p>
&lt;pre>&lt;code>cd qemu
wget http://www.internetworkpro.org/nemith/qemu-olive/qemu-cvs20080910-brb_01-olive.patch
patch -p1 &amp;lt; qemu-cvs20080910-brb_01-olive.patch
&lt;/code>&lt;/pre>
&lt;p>Поясню свои действия. Дело в том, что JunOS из &amp;ldquo;традиционных&amp;rdquo; сетевых интерфейсов знает только Intel, причем несколько вполне определенных плат. Если быть абсолютно точным, то это&lt;/p>
&lt;ul>
&lt;li>Intel EtherExpress Pro/100 and Pro/100B (82558 / 82558B chipset)&lt;/li>
&lt;li>Intel EtherExpress Pro/100+ Management Adapter (82559 chipset)&lt;/li>
&lt;li>Intel Pro/1000MT Desktop Gigabit Adapter&lt;/li>
&lt;li>Intel Pro/1000MT Dual Port Server Adapter (FW82546EB chipset)&lt;/li>
&lt;li>Intel ICH3 Onboard Controller (82801CAM)&lt;/li>
&lt;li>Compaq NC3120 (82258 chipset)&lt;/li>
&lt;li>Compaq NC3121 (82558B chipset)&lt;/li>
&lt;li>Matrox QS-NIC Quad FE NIC (8255x chipset)&lt;/li>
&lt;/ul>
&lt;p>Во FreeBSD это интерфейсы &lt;b>em&lt;/b> и &lt;b>fxp&lt;/b>. Остальные сетевушки просто не работают. Базовая поставка qemu предполагает эмуляцию сетевой карты Dec/Tulip (чип Lance 1010), которая в JunOS попросту не увидится. Патч исправляет эту историческую несправедливость, добавляя в qemu поддержку Intel 82559B карты.&lt;/p>
&lt;p>Теперь собственно соберем:&lt;/p>
&lt;pre>&lt;code>./configure --prefix=/var/qemu --enable-pemu-i82559 \
--enable-net-pcap \
--disable-kqemu \
make
make install
&lt;/code>&lt;/pre>
&lt;p>Как соберется - у нас будет готовый qemu, с помощью которого мы будем эмулировать наш Juniper.&lt;/p>
&lt;h2 id="первые-шаги-готовим-будку" >Первые шаги: Готовим будку.
&lt;span>
&lt;a href="#%d0%bf%d0%b5%d1%80%d0%b2%d1%8b%d0%b5-%d1%88%d0%b0%d0%b3%d0%b8-%d0%b3%d0%be%d1%82%d0%be%d0%b2%d0%b8%d0%bc-%d0%b1%d1%83%d0%b4%d0%ba%d1%83">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Для эмуляции JunOS нам понадобится сама JunOS, а также FreeBSD, из которой мы соберем JunOS. JunOS я предоставлять не буду, это дело подсудное. Но найти ее несложно. Во-первых она есть в e2k и torrent сетях. А во вторых ее можно найти на &lt;a href="http://sadikhov.com">Садыковском форуме&lt;/a>. Важно не ошибиться в версии и собственно пакете. Версии старше 7.5 - очень старые, подходят мало. Версии новее 9.0 слишком новые. Кроме того, из-за них эмулятор может уйти в летаргию или crash-нутся. Лично я использую версию 8.5. Далее. Пакет бывает Junos-domestic и Junos-extraсt. Последний является апгрейдом к существующей системе и нам не подойдет, работать он откажется. Кроме собственно базовой системы Junos можно также стянуть jweb - веб-интерфейс для управления аппаратиком. Стягивать не обязательно, командная строка есть и без него, но интерфейс может пригодится, так что пусть будет.&lt;/p>
&lt;p>Теперь собственно будка. Скачиваем FreeBSD 4.11 &lt;a href="ftp://ftp-archive.freebsd.org/pub/FreeBSD-Archive/old-releases/i386/ISO-IMAGES/4.11/4.11-RELEASE-i386-miniinst.iso">отсюда&lt;/a>:&lt;/p>
&lt;p>Не смотря на несерьезные размеры, скачиваться будет долго - сервер сильно нагружен, а он один&amp;hellip;
После того как образ скачается - начинаем работу:&lt;/p>
&lt;pre>&lt;code>cd /var/qemu
./bin/qemu-img j1.img 2G
&lt;/code>&lt;/pre>
&lt;p>j1.img - диск, с которого мы будем грузится.&lt;/p>
&lt;p>Для удобства запуска я написал простенький скрипт:&lt;/p>
&lt;pre>&lt;code>#!/bin/sh
/var/qemu/bin/qemu -L /var/qemu/share/qemu -m 256 -hda /var/qemu/j1.img \
-cdrom /var/qemu/4.11-RELEASE-i386-miniinst.iso -boot d \
-localtime \
-serial tcp::6001,server \
-vnc :1 \
-net nic,macaddr=00:aa:00:00:01:01,model=pemu_i82559 -net lcap,ifname=eth0 &amp;amp;
&lt;/code>&lt;/pre>
&lt;p>Кидаем его в /var/qemu и даем права на запуск, потом запускаем. Скрипт черканет пару строчек и свалится в фон. В случае, если установка пошла не так или эмулятор ушел в летаргию - достаточно с консоли просто убить процесс qemu:&lt;/p>
&lt;pre>&lt;code>killall -9 qemu
&lt;/code>&lt;/pre>
&lt;p>А для продолжения установки цепляемся к серверу с qemu по VNC, порт - 5901. Далее ставим FreeBSD, это процесс совсем не сложен и детально описан в руководстве на сайте. Крайне рекомендую прописать машине hostname и IP для сетевой карты (fxp0). Единственное уточнение - разметка. Выглядеть должно так:&lt;/p>
&lt;ul>
&lt;li>/ - 512M&lt;/li>
&lt;li>swap - 256M&lt;/li>
&lt;li>/config - 256M&lt;/li>
&lt;li>/var - все остальное (должно быть около гига).&lt;/li>
&lt;/ul>
&lt;p>Ставить надо &lt;em>только&lt;/em> base system, ничего больше не потребуется.&lt;/p>
&lt;p>После установки фри, когда она предложит загрузится снова жмем ^C (ctrl-c) или убиваем процесс qemu.
Открываем наш скрипт запуска и меняем -boot d на -boot c. То есть наш новый скрипт будет смотреться примерно так:&lt;/p>
&lt;pre>&lt;code>#!/bin/sh
/var/qemu/bin/qemu -L /var/qemu/share/qemu -m 256 -hda /var/qemu/j1.img \
-cdrom /var/qemu/4.11-RELEASE-i386-miniinst.iso -boot с \
-localtime \
-serial tcp::6001,server \
-vnc :1 \
-net nic,macaddr=00:aa:00:00:01:01,model=pemu_i82559 -net lcap,ifname=eth0 &amp;amp;
&lt;/code>&lt;/pre>
&lt;h2 id="а-теперь-зверюшки" >А теперь зверюшки!
&lt;span>
&lt;a href="#%d0%b0-%d1%82%d0%b5%d0%bf%d0%b5%d1%80%d1%8c-%d0%b7%d0%b2%d0%b5%d1%80%d1%8e%d1%88%d0%ba%d0%b8">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Вновь запускаем систему и любуемся свежеустановленной системой. Забираем через сеть наш JunOS&lt;/p>
&lt;pre>&lt;code>cd /var/tmp
scp logan@10.10.10.3:~/jinstalll-8.3R2.8-domestic-signed.tgz ./
&lt;/code>&lt;/pre>
&lt;p>и ставим:&lt;/p>
&lt;pre>&lt;code>pkg_add -f ./jinstalll-8.3R2.8-domestic-signed.tgz
&lt;/code>&lt;/pre>
&lt;p>Тут есть еще один скользкий момент. Если JunOS у вас 8.0 или новее - поставить вы ее не сможете, будет ошибка ELF type 0. Но это победимо. Чтобы это забороть нужно подменить ./pkgtool/bin/checkpic на /usr/bin/true из системы, в которую закатываем JunOS:&lt;/p>
&lt;pre>&lt;code>mkdir junos
cp jinstall-8.3R2.8-domestic-signed.tgz
cd junos
tar -xf jinstall-8.3R2.8-domestic-signed.tgz
mkdir jinstall
cp jinstall-8.3R2.8.tgz ./jinstall
cd jinstall
tar -xf jinstall-8.3R2.8.tgz
mkdir pkgtools
cp pkgtools.tgz ./pkgtools
cd ./pkgtools
tar -xf pkgtools.tgz
cp /usr/bin/true ./bin/checkpic
&lt;/code>&lt;/pre>
&lt;p>А теперь затрамбуем это все обратно!&lt;/p>
&lt;pre>&lt;code>tar czvf ../pkgtools.tgz *
cd ../
rm -rf pktools
tar czvf ../jinstall-8.3R2.8.tgz *
cd ..
rm -rf jinstall
&lt;/code>&lt;/pre>
&lt;p>Последний архив нам собирать не надо, для установки используется jinstall
При обратной запаковке пользуемся табами - файлы, в которые система пакуется должны называться так же, как и те, из которых мы распаковались, иначе система не поставится.&lt;/p>
&lt;p>Ставим:&lt;/p>
&lt;pre>&lt;code>pkg_add -f jinstall-8.3R2.8.tgz
&lt;/code>&lt;/pre>
&lt;p>После всех мытарств рутер перезагрузится. Отцепляемся от VNC (там все равно ничего интерестного не будет) и цепляемся telnet-ом на сервере на адрес 127.0.0.1:6001 и смотрим на свежезагруженый джунипер.
Наш эмулятор готов!&lt;/p></description></item><item><title>Авторизация в OpenSSH с использованием публичного ключа</title><link>https://prudnitskiy.pro/post/2005-01-14-openssh-key-auth/</link><pubDate>Fri, 14 Jan 2005 08:35:00 +0000</pubDate><guid>https://prudnitskiy.pro/post/2005-01-14-openssh-key-auth/</guid><description>&lt;p>OpenSSHd имеет очень немалое количество механизмов аутентификации, которые в принципе базируются на двух парадигмах - симметричного ключа (пароль) и несимметричного (сертификат). Разница в этих парадигмах довольно незамысловата: в случае использования симметричного ключа копию этого ключа надо хранить на сервере, чтобы при авторизации сравнить хранимое значение со значением, отправленным пользователем. В случае, если значения одинаковы - пароль считается верным и пользователя авторизуют, если значения разные - то нет. Минус пароля в том, что его можно перехватить, после чего пользоваться им без ограничений. Идея сертификата (несимметричного ключа) - более свежая. Она создавалась позже системы на базе пароля и учитывает вышеуказанную уязвимость. Работает эта система на базе двух связанных между собой ключей - открытого и закрытого. Используя открытый ключ, можно зашифровать сообщение, но расшифровать его - нельзя. Расшифровать сообщение можно только закрытым ключом. При этом имея закрытый ключ - можно создать открытый, однако имея открытый - нельзя восстановить закрытый. Кроме того, закрытым ключом можно не только зашифровать, но подписать сообщение - добавить к нему некоторое значение, которое однозначно идентифицирует сообщение. Подписаное сообщение нельзя изменить, при изменении подпись нарушается. При этом, имея открытый ключ можно совершенно однозначно идентифицировать, что подписано сообщение было совершенно определенным закрытым ключом. Но восстановить закрытый ключ или подписать открытым ключом сообщение - снова нельзя. Надеюсь, я не слишком сильно усложнил статью этим кратким экскурсом в практическую криптографию :) Итак, поехали, только практика и ничего кроме практики&lt;/p>
&lt;h2 id="сервер-и-клиент" >Сервер и клиент
&lt;span>
&lt;a href="#%d1%81%d0%b5%d1%80%d0%b2%d0%b5%d1%80-%d0%b8-%d0%ba%d0%bb%d0%b8%d0%b5%d0%bd%d1%82">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Для нормально авторизации по ключу нужно: создать пару закрытый-открытый ключ на клиенте скопировать открытый ключ на сервер Авторизация сработает только в том случае, если она разрешена на сервере, по умолчанию она разрешена. Для начала надо создать папку для ключей на клиенте и поставить там нормальные права:&lt;/p>
&lt;pre>&lt;code>client$ mkdir ~/.ssh
client$ chmod 700 ~/.ssh
&lt;/code>&lt;/pre>
&lt;p>Теперь создадим ключи:&lt;/p>
&lt;pre>&lt;code>client$ ssh-keygen -q -f ~/.ssh/id_rsa -t rsa
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
&lt;/code>&lt;/pre>
&lt;p>Passphrase - пароль, которым будет зашифровано содержимое ключа. Можно пароль не вводить, тогда для авторизации вообще не нужно будет ничего вводить, что удобно для роботов-скриптов. На всякий случай - поправим права доступа на ключи:&lt;/p>
&lt;pre>&lt;code>client$ chmod go-w ~/
client$ chmod 700 ~/.ssh
client$ chmod go-rwx ~/.ssh/*
&lt;/code>&lt;/pre>
&lt;p>Теперь отправим ключ на сервер:&lt;/p>
&lt;pre>&lt;code>client$ scp ~/.ssh/id_rsa.pub user@server.local.dom:~
&lt;/code>&lt;/pre>
&lt;p>и там его положим в правильное место:&lt;/p>
&lt;pre>&lt;code>server$ mkdir ~/.ssh
server$ chmod 700 ~/.ssh
server$ cat ~/id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys
server$ chmod 600 ~/.ssh/authorized_keys
server$ rm ~/id_rsa.pub
&lt;/code>&lt;/pre>
&lt;p>И проверим, что получилось:&lt;/p>
&lt;pre>&lt;code>client$ ssh -o PreferredAuthentications=publickey server.local.dom
Enter passphrase for key '~/.ssh/id_rsa':
server$
&lt;/code>&lt;/pre>
&lt;h2 id="если-что-то-пошло-не-так" >Если что-то пошло не так
&lt;span>
&lt;a href="#%d0%b5%d1%81%d0%bb%d0%b8-%d1%87%d1%82%d0%be-%d1%82%d0%be-%d0%bf%d0%be%d1%88%d0%bb%d0%be-%d0%bd%d0%b5-%d1%82%d0%b0%d0%ba">
&lt;svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg">&lt;path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"/>&lt;/svg>
&lt;/a>
&lt;/span>
&lt;/h2>&lt;p>Основное место, где отображаются ошибки SSH-сервера - /var/log/auth.log. Основная проблема - неправильные права доступа к ключу SSH (сервер не даст авторизации на ключ со слишком низким уровнем безопасности).&lt;/p></description></item></channel></rss>