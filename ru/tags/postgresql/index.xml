<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Postgresql on Инфраструктурный блог</title><link>/ru/tags/postgresql/</link><description>Инфраструктурный блог (Postgresql)</description><generator>Hugo -- gohugo.io</generator><language>ru-ru</language><lastBuildDate>Wed, 22 Aug 2018 12:00:00 +0000</lastBuildDate><atom:link href="/ru/tags/postgresql/index.xml" rel="self" type="application/rss+xml"/><item><title>Repmgr: управление репликацией postgresql</title><link>/ru/post/2018-08-22-repmgr/</link><pubDate>Wed, 22 Aug 2018 12:00:00 +0000</pubDate><guid>/ru/post/2018-08-22-repmgr/</guid><description>&lt;p>PostgreSQL - это мощная и очень развитая база данных, функциональная и дружелюбная. В комплект входит надежный и очень удобный механизм потоковой репликации (я писал о нем &lt;a href="https://prudnitskiy.pro/2018-01-05-pgsql-replica">здесь&lt;/a>). Не смотря на мощь и удобство – этот инструмент сложен в настройке и не всегда понятен, особенно, если серверов баз много. Все становится еще хуже, если у вас сложная схема репликации с каскадами (master &amp;gt; slave &amp;gt; slave of slave). Чтобы облегчить жизнь DBA в таких ситуациях – известные специалисты по консалтингу Postgres, компания 2ndQuadrant придумали repmgr – специальный инструмент для управления настройками репликации для PostgreSQL.&lt;/p>
&lt;p>Repmgr может:&lt;/p>
&lt;ul>
&lt;li>облегчить создание новых серверов&lt;/li>
&lt;li>облегчить переключение на другой сервер (promote)&lt;/li>
&lt;li>автоматизировать переключение на новый сервер при отказе старого (failover)&lt;/li>
&lt;li>вести аудит событий репликации в кластере (event flow)&lt;/li>
&lt;li>официально repmgr поддерживает мультимастер с помощью механизма bidirectional replication. Это жуткий грязный хак, и я очень не рекомендую его использовать&lt;/li>
&lt;/ul>
&lt;p>Repmgr требует (ограничения):&lt;/p>
&lt;ul>
&lt;li>postgresql 9 или 10 (так как только в 9 версии появилась потоковая репликаця)&lt;/li>
&lt;li>доступ с каждого узла кластера на каждый узел кластера по протоколам SSH (непривелигированый) и postgresql (5432)&lt;/li>
&lt;li>одинаковую версию Postgres (только major)&lt;/li>
&lt;li>одинаковую архитектуру сервера (вы не сможете реплицировать данные с ARM на AMD64)&lt;/li>
&lt;li>одинаковую версию repmgr на всех узлах кластера (одинаковость должна быть &lt;em>полной&lt;/em>)&lt;/li>
&lt;li>пользователя с правами SUPERUSER, от имени которого repmgr будет проводить операции. Пароль от этого пользователя хранится в файловой системе кластера в открытом виде.&lt;/li>
&lt;/ul>
&lt;h2 id="установка" >
&lt;div>
&lt;a href="#%d1%83%d1%81%d1%82%d0%b0%d0%bd%d0%be%d0%b2%d0%ba%d0%b0">
#
&lt;/a>
Установка
&lt;/div>
&lt;/h2>
&lt;p>Repmgr поставляется в виде пакета и входит в стандартный для всех пользователей postgresql репозиторий PGDG. В данной статье я продемонстрирую настройку для debian, но для centos он настраивается практически так же – меняются только пути доступа к файлам. Добавим репозиторий:&lt;/p>
&lt;pre>&lt;code>sh -c 'echo &amp;quot;deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main&amp;quot; &amp;gt; /etc/apt/sources.list.d/pgdg.list'
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | apt-key add -
apt-get update
&lt;/code>&lt;/pre>
&lt;p>Теперь можно установить необходимые для работы пакеты:&lt;/p>
&lt;pre>&lt;code>apt-get install postgresql-10 postgresql-10-repmgr -y
&lt;/code>&lt;/pre>
&lt;p>Для repmgr важно, чтобы все хосты видели друг друга по hostname. Я рекомендую иметь внутренний DNS для решения этой задачи, но если у вас по какой-то причине его нет – придется добавить имена и адреса серверов кластера в &lt;code>/etc/hosts&lt;/code>. Например:&lt;/p>
&lt;pre>&lt;code>192.168.0.17 pg1.lab.office pg1
192.168.0.18 pg2.lab.office pg2
192.168.0.19 pg3.lab.office pg3
&lt;/code>&lt;/pre>
&lt;p>Для того, что бы repmgr мог копировать базу с одного сервера на другой – пользователю repmgrd нужен доступ по ssh без ввода пароля. Для этого на каждом из серверов нужно сгенерировать ssh public key. Этот public key нужно положить на все остальные сервера кластера в файл &lt;code>~/.ssh/authorized_keys&lt;/code>. Это нужно сделать для пользователя, от которого будет запущен repmgr. Обычно это тот же пользователь, от имени которого запущен postgres. Создадим ключи на каждом сервере:&lt;/p>
&lt;pre>&lt;code>sudo -u postgres ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/var/lib/postgresql/.ssh/id_rsa):
Created directory '/var/lib/postgresql/.ssh'.
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /var/lib/postgresql/.ssh/id_rsa.
Your public key has been saved in /var/lib/postgresql/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:oqFJ3/Gr8oeBgQpAsKSlImbUOLroa/YaFbJ8AxlsBng postgresql@pg1
&lt;/code>&lt;/pre>
&lt;p>Публичный ключ из файла &lt;code>/var/lib/postgresql/.ssh/id_rsa.pub&lt;/code> надо добавить на все остальные сервера кластера, в файл &lt;code>~/.ssh/authorized_keys&lt;/code>. Заодно поправим права:&lt;/p>
&lt;pre>&lt;code>#на сервере pg1
echo &amp;quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCoavDuAETBMZBD0NwRvSEDYL1avCIkSLzxMG50L6b7nIeasrfv90AGjARxID9THkUXDNkdKhfRIu+WGFYxlgZ6zqPQCyZyQvKjcJr325pbo9it474LpLpeHuPrXdeMSzSilxvAKvYX/ml7L9KtOnYMDusFK1XdGeV25qcj2OSLWBY168riW5vvGWFYTCdU6q9eQ+JN2zCpoZzXKNqhh+dpItt1QiKRw84u7EtUW6U02tw1V5nmO+HGyG2A50S5/JNS7lbj/7IYAXwIgtlBrf3mzCPCIoHbjlSny/V6sp3S7QWNrxynpkI7o+oMvJq5frAEpn0syiUmtOz56Qnw67GP postgres@pg2&amp;quot; &amp;gt;&amp;gt; /var/lib/postgresql/.ssh/authorized_keys
echo &amp;quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDfl8Rg47u97kGUPf7OwF4jeGhcIxVtWEVDk1AKJt5o3Y65v5jzrjoI5F0YrboEzr+oPu5BV24M6dOI5u3ysRBX/osQI2fBlt+hotAIWXPiP8UUy9CgIdQH59h/MJcp3jPH0KYQTwF8WJDr1skUcUzKGswuofBaElm5TpME+Oz2vygXEl2vL9Pfo5kfdsk9ov58cUJNlDGtxTo/Rzw9XFRnkBimzwvem/gmdpYBFb45ulsbLVmdBcv+QTU7PQ+knqIyERboTecS8wBYoKnlCTA0LZscvyeHjKwILSl9ZFfir3CRdYtxNqx4Zk/hMphx4Bt7hn96KUXRiMf3ODpd2yp1 postgres@pg3&amp;quot; &amp;gt;&amp;gt; /var/lib/postgresql/.ssh/authorized_keys
chown postgres /var/lib/postgresql/.ssh/authorized_keys
chmod 600 /var/lib/postgresql/.ssh/authorized_keys
&lt;/code>&lt;/pre>
&lt;p>Убедимся, что доступ есть:&lt;/p>
&lt;pre>&lt;code>root@pg1:~# sudo -u postgres ssh pg2.lab.office -x 'w'
09:04:07 up 3 days, 23:48, 1 user, load average: 0.00, 0.00, 0.00
USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT
logan pts/0 192.168.0.70 14:28 1:19 0.22s 0.02s sshd: logan [priv]
&lt;/code>&lt;/pre>
&lt;p>Для остальных серверов делаем по аналогии.&lt;/p>
&lt;p>Для того, чтобы процесс repmgr мог сам перезапускать постгрес - ему нужны соответствующие права. Чтобы их дать - создадим файл &lt;code>/etc/sudoers.d/repmgr&lt;/code> и впишем туда:&lt;/p>
&lt;pre>&lt;code>Cmnd_Alias PGRE = /bin/systemctl status postgresql, \
/bin/systemctl start postgresql, \
/bin/systemctl stop postgresql, \
/bin/systemctl restart postgresql, \
/bin/systemctl reload postgresql
postgres ALL=(ALL) NOPASSWD: PGRE
&lt;/code>&lt;/pre>
&lt;p>Это позволит пользователю postgres перезапускать процесс сервера postgres.&lt;/p>
&lt;p>Теперь нам надо настроить сам postgresql. Обязательный минимум:&lt;/p>
&lt;ul>
&lt;li>доступность из сети (директива &lt;code>listen_addresses&lt;/code>)&lt;/li>
&lt;li>репликация (&lt;code>wal_level&lt;/code>, &lt;code>archive_mode&lt;/code>)&lt;/li>
&lt;li>лимит &lt;code>max_wal_senders&lt;/code> - как минимум на 1 больше количества серверов в кластере&lt;/li>
&lt;li>&lt;code>hot_standby&lt;/code> - для серверов в режиме slave.&lt;/li>
&lt;li>права на репликацию в hba&lt;/li>
&lt;/ul>
&lt;p>Если вы строите кластер на debian - настройки надо скопировать на все сервера кластера. Для centos это не обязательно, так как файл настроек лежит прямо в data directory и при клонировании repmgr вытащит файлы.&lt;/p>
&lt;p>Пример настроек - &lt;code>/etc/postgresql/10/main/postgresql.conf&lt;/code>:&lt;/p>
&lt;pre>&lt;code># тут приведены не все настройки, а только то, что я поменял
# часть настроек в файле закомментирована, а в части указаны другие значения.
# Пользуйтесь поиском.
listen_addresses = '*'
wal_level = replica
archive_mode = on
archive_command = 'cp %p /var/lib/pg-arch/%f'
max_wal_senders = 4
hot_standby = on
&lt;/code>&lt;/pre>
&lt;p>В данном примере мы не удаляем архивированные сегменты, а перемещаем их папку &lt;code>/var/lib/pg-arch/&lt;/code>. Это позволит восстановить &amp;ldquo;отставший&amp;rdquo; slave. Подробнее я писал &lt;a href="https://prudnitskiy.pro/2018-01-05-pgsql-replica">здесь&lt;/a>. Эту папку нужно создать (владелец - postgres, права доступа - 700). Папку нужно периодически чистить – postgres сам не очищает архивы. В упомянутой выше статье вы найдете детальное описание.&lt;/p>
&lt;p>Пример настроек hba. В данном примере пользователь БД называется &lt;code>repmgr&lt;/code>. Служебная база repmgr - &lt;code>repmgrdb&lt;/code>:&lt;/p>
&lt;pre>&lt;code># Не менять! сломаются локальные операции!
local all postgres peer
# TYPE DATABASE USER ADDRESS METHOD
local all all md5
host all all 127.0.0.1/32 md5
host all all ::1/128 md5
# replication settings
local replication all peer
host replication all 127.0.0.1/32 md5
host replication all ::1/128 md5
host repmgrdb repmgr 192.168.0.0/24 md5
host replication repmgr 192.168.0.0/24 md5
#remote access to server cluster. any DB, any user, any host, password required
host all all 0.0.0.0/0 md5
&lt;/code>&lt;/pre>
&lt;p>С настройкой postgres закончили, перезапускаем сервер и создаем служебную базу и пользователя. Пароль для пользователя лучше сделать посложнее:&lt;/p>
&lt;pre>&lt;code>service postgresql status
sudo -u postgres psql
psql (10.4 (Debian 10.4-2.pgdg90+1))
Type &amp;quot;help&amp;quot; for help.
postgres=# create user repmgr with superuser;
postgres=# alter role repmgr with password 'Ahn7yaechie6hoe0av8eF0ei';
postgres=# create database repmgrdb owner repmgr;
postgres=# \q
&lt;/code>&lt;/pre>
&lt;p>Чтобы repmgr мог обращаться к серверу БД и ему не требовалось вводить пароль – нужно создать файл &lt;code>/var/lib/postgresql/.pgpass&lt;/code>. Владельцем файла должен быть пользователь postgres, права - 0600 (иначе он игнорируется). Структура файла - &lt;code>IP:port:DB:user:password&lt;/code>. &lt;code>*&lt;/code> означает &amp;ldquo;любое&amp;rdquo;. К сожалению pgpass не в состоянии работать с CIDR, то есть задать адрес как &lt;code>192.168.0.*&lt;/code> можно, а &lt;code>192.168.0.0/24&lt;/code> – нельзя. Пример файла:&lt;/p>
&lt;pre>&lt;code>*:5432:repmgrdb:repmgr:Ahn7yaechie6hoe0av8eF0ei
*:5432:replication:repmgr:Ahn7yaechie6hoe0av8eF0ei
&lt;/code>&lt;/pre>
&lt;p>Вторая запись нужна для самого процесса репликации.&lt;/p>
&lt;p>Теперь настроим repmgr. Его настройки в debian лежат в файле &lt;code>/etc/repmgr.conf&lt;/code>. Пример с комментариями:&lt;/p>
&lt;pre>&lt;code># ID узла (сервера). В рамках кластера обязательно уникальный
node_id=1
# hostname. Остальные узлы должны иметь возможность найти этот именно по этому имени.
node_name='pg1.lab.office'
# строка подключения к БД
conninfo='host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2'
# директория с данными postgres.
data_directory='/var/lib/postgresql/10/main/'
# режим репликации. Пока что поддерживается только этот
replication_type=physical
# log file. Не забудьте создать папку для него.
log_file='/var/log/repmgr/repmgr.log'
# записывать статус каждые 5 минут (300 секунд)
log_status_interval=300
# где находятся bin-файлы postgres.
pg_bindir='/usr/lib/postgresql/10/bin/'
# не использовать password из conninfo (строки выше)
# мы храним пароль в .pgpass, это безопаснее. Потому - false
use_primary_conninfo_password=false
ssh_options='-q -o ConnectTimeout=10'
# режим failover
failover=manual
# очередность выборов мастера в случае отказа
# эта настройка и последующие применимы только если failover - auto
priority=100
reconnect_attempts=3
reconnect_interval=5
promote_command='/usr/bin/repmgr -f /etc/repmgr.conf standby promote --log-to-file'
follow_command='/usr/bin/repmgr standby follow -f /etc/repmgr.conf --log-to-file --upstream-node-id=%n'
# команды запуска, остановки и перезапуска сервиса. Должны соответствовать тому, что мы вписали в sudo.
service_start_command = 'sudo -n /bin/systemctl start postgresql'
service_stop_command = 'sudo -n /bin/systemctl stop postgresql'
service_restart_command = 'sudo -n /bin/systemctl restart postgresql'
service_reload_command = 'sudo -n /bin/systemctl reload postgresql'
&lt;/code>&lt;/pre>
&lt;p>Теперь можно зарегистрировать первый сервер в кластере:&lt;/p>
&lt;pre>&lt;code>sudo -u postgres repmgr -f /etc/repmgr.conf primary register
&lt;/code>&lt;/pre>
&lt;p>Проверим, что он там появился:&lt;/p>
&lt;pre>&lt;code>root@pg1:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | * running | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
&lt;/code>&lt;/pre>
&lt;p>Все ок. Теперь настроим остальные два сервера. Они настраиваются по аналогии с первым сервером. Только в конфиге repmgr.conf нужно поменять node_id, node_name и conninfo. На 2 и 3 серверах запускать postgres не нужно.&lt;/p>
&lt;p>Удалим существующий data-dir и склонируем базу с мастера:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# service postgresql stop
root@pg2:~# rm -rf /var/lib/postgresql/10/main/*
root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf -h pg1.lab.office -U repmgr -d repmgrdb standby clone
NOTICE: destination directory &amp;quot;/var/lib/postgresql/10/main/&amp;quot; provided
NOTICE: starting backup (using pg_basebackup)...
HINT: this may take some time; consider using the -c/--fast-checkpoint option
NOTICE: standby clone (using pg_basebackup) complete
NOTICE: you can now start your PostgreSQL server
HINT: for example: sudo -n /bin/systemctl start postgresql
HINT: after starting the server, you need to register this standby with &amp;quot;repmgr standby register&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Запускаем сервер, регистрируемся:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# service postgresql start
root@pg2:~# sudo -u postgres /usr/bin/repmgr standby register
NOTICE: standby node &amp;quot;pg2.lab.office&amp;quot; (id: 2) successfully registered
&lt;/code>&lt;/pre>
&lt;p>Проверяем, что изменилось:&lt;/p>
&lt;pre>&lt;code>root@pg1:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | * running | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
2 | pg2.lab.office | standby | running | pg1.lab.office | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
&lt;/code>&lt;/pre>
&lt;p>Третий сервер запускаем по аналогии со вторым.&lt;/p>
&lt;h2 id="failover" >
&lt;div>
&lt;a href="#failover">
#
&lt;/a>
Failover
&lt;/div>
&lt;/h2>
&lt;p>Итак, мастер сломался и надо переключится на slave:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+---------------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | ? unreachable | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
2 | pg2.lab.office | standby | running | pg1.lab.office | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
3 | pg3.lab.office | standby | running | pg1.lab.office | default | host=pg3.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
WARNING: following issues were detected
- when attempting to connect to node &amp;quot;pg1.lab.office&amp;quot; (ID: 1), following error encountered :
&amp;quot;could not connect to server: Connection refused
Is the server running on host &amp;quot;pg1.lab.office&amp;quot; (192.168.0.17) and accepting
TCP/IP connections on port 5432?&amp;quot;
- node &amp;quot;pg1.lab.office&amp;quot; (ID: 1) is registered as an active primary but is unreachable
&lt;/code>&lt;/pre>
&lt;p>Прежде чем продолжить – обязательно убедитесь, что старый мастер (pg1) отключен и не &amp;ldquo;оживет&amp;rdquo; в самый неподходящий момент. Repmgr не умеет работать с fencing-ом и вы можете потерять часть данных.&lt;/p>
&lt;p>Повышаем pg2 до мастера:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf standby promote
NOTICE: promoting standby to primary
DETAIL: promoting server &amp;quot;pg2.lab.office&amp;quot; (ID: 2) using &amp;quot;/usr/lib/postgresql/10/bin/pg_ctl -w -D '/var/lib/postgresql/10/main/' promote&amp;quot;
waiting for server to promote.... done
server promoted
NOTICE: STANDBY PROMOTE successful
DETAIL: server &amp;quot;pg2.lab.office&amp;quot; (ID: 2) was successfully promoted to primary
&lt;/code>&lt;/pre>
&lt;p>Проверяем статус:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | - failed | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
2 | pg2.lab.office | primary | * running | | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
3 | pg3.lab.office | standby | running | pg1.lab.office | default | host=pg3.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
&lt;/code>&lt;/pre>
&lt;p>pg3 по-прежнему ждет данных от pg1. Его нужно переключить на новый мастер:&lt;/p>
&lt;pre>&lt;code>root@pg3:~# sudo -u postgres /usr/bin/repmgr standby follow -f /etc/repmgr.conf --upstream-node-id=2
NOTICE: setting node 3's primary to node 2
NOTICE: restarting server using &amp;quot;sudo -n /bin/systemctl restart postgresql&amp;quot;
NOTICE: STANDBY FOLLOW successful
DETAIL: node 3 is now attached to node 2
&lt;/code>&lt;/pre>
&lt;p>Проверим состояние кластера:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
1 | pg1.lab.office | primary | - failed | | default | host=pg1.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
2 | pg2.lab.office | primary | * running | | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
3 | pg3.lab.office | standby | running | pg2.lab.office | default | host=pg3.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
WARNING: following issues were detected
- when attempting to connect to node &amp;quot;pg1.lab.office&amp;quot; (ID: 1), following error encountered :
&amp;quot;could not connect to server: Connection refused
Is the server running on host &amp;quot;pg1.lab.office&amp;quot; (192.168.0.17) and accepting
TCP/IP connections on port 5432?&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Теперь мы можем убрать старый сервер из конфигурации:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf primary unregister --node-id=1
&lt;/code>&lt;/pre>
&lt;p>Проверяем еще раз:&lt;/p>
&lt;pre>&lt;code>root@pg2:~# sudo -u postgres repmgr -f /etc/repmgr.conf cluster show
ID | Name | Role | Status | Upstream | Location | Connection string
----+----------------+---------+-----------+----------------+----------+-------------------------------------------------------------------
2 | pg2.lab.office | primary | * running | | default | host=pg2.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
3 | pg3.lab.office | standby | running | pg2.lab.office | default | host=pg3.lab.office user=repmgr dbname=repmgrdb connect_timeout=2
&lt;/code>&lt;/pre>
&lt;p>Теперь можно спокойно чинить pg1, без риска что он внезапно вернется в сеть и будет конфликт записи в slave.&lt;/p>
&lt;h2 id="возврат-мастера" >
&lt;div>
&lt;a href="#%d0%b2%d0%be%d0%b7%d0%b2%d1%80%d0%b0%d1%82-%d0%bc%d0%b0%d1%81%d1%82%d0%b5%d1%80%d0%b0">
#
&lt;/a>
Возврат мастера
&lt;/div>
&lt;/h2>
&lt;p>Самый простой способ вернуть старый сервер - удалить его datadir и зарегистрировать заново как slave:&lt;/p>
&lt;pre>&lt;code>root@pg1:~# rm -rf /var/lib/postgresql/10/main/*
root@pg1:~# sudo -u postgres repmgr -f /etc/repmgr.conf -h pg2.lab.office -U repmgr -d repmgrdb standby clone
NOTICE: destination directory &amp;quot;/var/lib/postgresql/10/main/&amp;quot; provided
NOTICE: starting backup (using pg_basebackup)...
HINT: this may take some time; consider using the -c/--fast-checkpoint option
NOTICE: standby clone (using pg_basebackup) complete
NOTICE: you can now start your PostgreSQL server
HINT: for example: sudo -n /bin/systemctl start postgresql
HINT: after starting the server, you need to register this standby with &amp;quot;repmgr standby register&amp;quot;
root@pg1:~# service postgresql start
root@pg1:~# sudo -u postgres /usr/bin/repmgr standby register
WARNING: --upstream-node-id not supplied, assuming upstream node is primary (node ID 2)
NOTICE: standby node &amp;quot;pg1.lab.office&amp;quot; (id: 1) successfully registered
&lt;/code>&lt;/pre>
&lt;h2 id="заключение" >
&lt;div>
&lt;a href="#%d0%b7%d0%b0%d0%ba%d0%bb%d1%8e%d1%87%d0%b5%d0%bd%d0%b8%d0%b5">
#
&lt;/a>
Заключение
&lt;/div>
&lt;/h2>
&lt;p>Repmgr - простой, понятный инструмент, который сильно облегчает операции в master-slave конфигурациях. Он не позволит полностью автоматизировать защиту от отказов (для этого нужны другие инструменты), но поможет в простых конфигурациях. Я очень рекомендую использовать его – самостоятельно или в сочетании с pgpool-II. В таком варианте pgpool отвечает за балансировку запросов, фенсинг и инициирует failover, когда это необходимо. Repmgr отвечает за сам низкоуровневый процесс failover (и это намного лучше, чем рекомендуемый pgpool набор жутковатых скриптов!).&lt;/p>
&lt;p>При этом я очень не рекомендую:&lt;/p>
&lt;ul>
&lt;li>использовать автоматический failover средствами repmgr. Строго говоря – он не работает. Для работы repmgr нужен работающий сервер postgresql, и если postgresql master упал – repmgr не в состоянии самостоятельно переключится (из-за упавшего мастера)&lt;/li>
&lt;li>использовать bidirectional multimaster. Эта функция заявлена в описании, но работает крайне плохо - сервера теряют связь друг с другом и часто трут конфликтующие данные. Проверено до версии &lt;strong>4.0.5&lt;/strong>&lt;/li>
&lt;/ul></description></item><item><title>Потоковая репликация в PostgreSQL – короткое введение</title><link>/ru/post/2018-01-05-pgsql-replica/</link><pubDate>Fri, 05 Jan 2018 21:00:00 +0000</pubDate><guid>/ru/post/2018-01-05-pgsql-replica/</guid><description>&lt;p>PostgreSQL – великолепная база данных, во многом – лучше MySQL. При этом у PostgreSQL довольно мало документации (кроме официальной) – MySQL раньше стал популярен и сейчас элементарно чаще встречается. Руководств по настройке репликации в MySQL - полный интернет, а для PostgreSQL на русском я пошаговых инструкций просто не видел. Это – именно такая инструкция.&lt;/p>
&lt;h2 id="мотивация" >
&lt;div>
&lt;a href="#%d0%bc%d0%be%d1%82%d0%b8%d0%b2%d0%b0%d1%86%d0%b8%d1%8f">
#
&lt;/a>
Мотивация
&lt;/div>
&lt;/h2>
&lt;p>Репликация – это очень просто. Репликация означает копирование состояние одного сервера на другой. То есть – любые изменения, примененные на основной сервер (master) будут скопированы на его &amp;ldquo;заместителя&amp;rdquo; (slave). Для чего это нужно:&lt;/p>
&lt;ul>
&lt;li>Для распределения нагрузки. Slave не может записывать данные, но с него можно эти данные читать. По личному опыту, более 80% нагрузки на базу данных – это именно чтение в том или ином виде. Slave (или несколько) позволяют разгрузить мастер. Установка нескольких дешевых серверов чаще всего обходится дешевле, чем обновления одного, но дорогого (горизонтальное масштабирование дешевле вертикального. В некоторых случаях мешает закон Амдаля, но у нас не тот случай).&lt;/li>
&lt;li>Для построения отказоустойчивых систем. В случае, если с мастером &lt;strong>что-то случилось&lt;/strong> – превратить slave в master можно буквально за секунды, это снижает время простоя. Восстановление из резервной копии займет много больше времени. Кроме того, состояние slave-а будет максимально приближено к состоянию master-а на момент отказа. Бэкапы обычно делаются по расписанию. То есть – все данные, записанные после создания резервной копии и до отказа мастера можно считать потерянными безвозвратно.&lt;/li>
&lt;/ul>
&lt;p>Как и у всякой технологии, у репликации есть ограничения:&lt;/p>
&lt;ul>
&lt;li>Репликация в PostgreSQL – исключительно однонаправленная (master -&amp;gt; slave). PostgreSQL не поддерживает мультимастер (есть внешние решения, но они выходят за рамки этой статьи)&lt;/li>
&lt;li>Репликация дополняет бэкап, но не заменяет его. Реплика спасет данные, если с мастер-сервером что-то случилось: отказ электричества, сервер сгорел, жесткие диски умерли, пожар в ЦОД, правоохранительные органы изъяли оборудование и т.д. Репликация никак не поможет при логической ошибке (код запорол данные) или ошибке оператора (&amp;ldquo;призрак человека с консолью&amp;rdquo;).&lt;/li>
&lt;li>Особенность именно PostgreSQL - репликация возможна только всего сервера целиком, нельзя выбрать базы, которые будут реплицироваться (или не будут).&lt;/li>
&lt;li>По умолчанию репликация - асинхронная. Это значит, что мастер пишет данные постоянно, а slave вытаскивает изменения и применяет их у себя по мере возможности. Вообще, в норме это не вызывает проблем. Но, если вдруг у slave возникли с этим проблемы (мастер несравнимо мощнее и slave не успевает применять изменения, или проблемы с сетью между мастером и slave) – master &amp;ldquo;убежит&amp;rdquo; вперед. Данные при этом потеряны не будут, и slave догонит мастер, как только сможет. Такую ситуацию несложно отслеживать (дальше покажу, как), просто нужно иметь это ввиду. Репликацию можно сделать синхронной, чтобы гарантировать абсолютную консистентность данных между серверами, но это удорожает транзакции – производительность записи упадет, а нагрузка – вырастет.&lt;/li>
&lt;li>Репликация использует отдачу WAL-сегментов с мастера на slave-ы. Эти сегменты надо на мастере где-то хранить, то есть нужно запланировать дополнительное место для них.&lt;/li>
&lt;li>Репликация возможна только между серверами с общей мажорной версией (то есть реплицироваться 9.5 -&amp;gt; 9.5 можно, а с 9.4 -&amp;gt; 10.0 – нельзя). На всякий случай напомню, что до версии 10.0 обновления 9.4 -&amp;gt; 9.5 считались мажорными, а не минорными. У разных версий разный формат хранения данных.&lt;/li>
&lt;li>потоковая репликация возможна только в PostgreSQL 9 и выше. Она не работает в 7 и 8 версиях.&lt;/li>
&lt;/ul>
&lt;h2 id="мутные-технические-подробности" >
&lt;div>
&lt;a href="#%d0%bc%d1%83%d1%82%d0%bd%d1%8b%d0%b5-%d1%82%d0%b5%d1%85%d0%bd%d0%b8%d1%87%d0%b5%d1%81%d0%ba%d0%b8%d0%b5-%d0%bf%d0%be%d0%b4%d1%80%d0%be%d0%b1%d0%bd%d0%be%d1%81%d1%82%d0%b8">
#
&lt;/a>
Мутные технические подробности
&lt;/div>
&lt;/h2>
&lt;p>Каждый postgresql-сервер пишет все изменения сначала в WAL (write-ahead log), и только затем – применяет изменения в реальное пространство базы данных. Это позволяет гарантировать целостность данных и отсутствие конфликтов изменений в табличном пространстве. В случае, если сервер по какой-то причине перезагрузился – он сначала проверяет текущий номер транзакции, примененный к табличному пространству (то есть - успешно завершенная запись). Затем сервер проверят WAL и дописывает разницу из WAL в tablespace. Номер транзакции всегда растет монотонно, что исключает конфликты очередности применения. Запись в WAL обходится дешевле, так как в WAL записываются только изменения, и они туда только последовательно пишутся (и эпизодически – последовательно читаются). Когда все транзакции из файла WAL считаются успешно примененными на сервер – WAL помечается как готовый (full) и удаляется. В случае репликации slave получает копию WAL с мастера (через специальный процесс wal streamer service - по одному на каждый slave). Для того, чтобы синхронизировать мастер со slave, нужно:&lt;/p>
&lt;ul>
&lt;li>скопировать текущее состояние мастера на slave.&lt;/li>
&lt;li>включить на мастере wal streaming (вещание wal-файлов)&lt;/li>
&lt;li>дождаться, пока slave не подключится к мастеру и не вытянет изменения и не применит их&lt;/li>
&lt;/ul>
&lt;h2 id="пошаговое-руководство" >
&lt;div>
&lt;a href="#%d0%bf%d0%be%d1%88%d0%b0%d0%b3%d0%be%d0%b2%d0%be%d0%b5-%d1%80%d1%83%d0%ba%d0%be%d0%b2%d0%be%d0%b4%d1%81%d1%82%d0%b2%d0%be">
#
&lt;/a>
Пошаговое руководство
&lt;/div>
&lt;/h2>
&lt;p>В примере будут участвовать два сервера:&lt;/p>
&lt;ul>
&lt;li>master.db.local (10.0.0.1)&lt;/li>
&lt;li>slave.db.local (10.0.0.2)&lt;/li>
&lt;/ul>
&lt;p>Для упрощения считаем, что мастер уже настроен, запущен и работает. Slave – это пустой сервер без данных вообще, там только установлена ОС и сам postgres. Версии PostgreSQL на обоих серверах имеют одинаковый номер версии в майоре (к примеру 9.6.0 на master и 9.6.4 на slave). В данном примере я использую Debian и PostgreSQL 9.6. Для других ОС и версий PostgreSQL настройки отличатся не будут, но могут отличаться пути, по которым лежат конфиги и файлы данных.&lt;/p>
&lt;h3 id="настройка-master" >
&lt;div>
&lt;a href="#%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%be%d0%b9%d0%ba%d0%b0-master">
##
&lt;/a>
Настройка master
&lt;/div>
&lt;/h3>
&lt;p>Для начала поправим postgresql.conf. В Debian он находится по адресу &lt;code>/etc/postgresql/VERSION/CLUSTER/postgresql.conf&lt;/code>. В нашем примере это &lt;code>/etc/postgresql/9.6/master/postgresql.conf&lt;/code>&lt;/p>
&lt;pre>&lt;code>#master должен быть доступен по сети для slave
#listen_addresses может принимать несколько значений (через запятую)
#можно поставить * - postgres будет доступен на всех сетевых интерфейсах
listen_addresses = '10.0.0.1'
#режим хранения WAL-сегментов. Для репликации – только hot_standby
wal_level = hot_standby
#максимальное количство wal_sender.
#это максимум slave-ов, который сможет подключится к этому серверу
max_wal_senders = 5
#сколько заполненных WAL-сегментов хранить на мастере перед удалением
#число можно подобрать только экспериментально (больше изменений – больше WAL надо хранить)
wal_keep_segments = 32
#папка для архива. Удаленный WAL-сегмент будет скопирован туда
#архивом можно пользоваться для восстановления slave, если slave не успел выкачать WAL с мастера, а мастер его уже удалил
#там должно быть много места – сам postgres не будет чистить свой архив
archive_mode = on
archive_command = 'cp %p /var/lib/pg-archive/%f'
&lt;/code>&lt;/pre>
&lt;p>Теперь нужно разрешить slave-у подключаться к мастеру для репликации. Для этого отредактируем pg_hba.conf (лежит там же, где postgresql.conf), и добавим туда специального пользователя:&lt;/p>
&lt;pre>&lt;code>#TYPE DB USER ADDRESS #METHOD
host replication replication 10.0.0.2/32 md5
&lt;/code>&lt;/pre>
&lt;p>Теперь надо создать папку для архива:&lt;/p>
&lt;pre>&lt;code>mkdir /var/lib/pg-archive/
chown postgres /var/lib/pg-archive/
chmod 700 /var/lib/pg-archive/
&lt;/code>&lt;/pre>
&lt;p>И перезапустить master:&lt;/p>
&lt;pre>&lt;code>service postgresql restart
&lt;/code>&lt;/pre>
&lt;p>Создадим пользователя для репликации. Для этого в консоли самого постгреса выполним команду:&lt;/p>
&lt;pre>&lt;code>CREATE ROLE replication WITH REPLICATION PASSWORD 'Hw572BbvG7g4cwq5' LOGIN;
&lt;/code>&lt;/pre>
&lt;p>Пароль нам потребуется для авторизации slave-а на мастере. Рекомендуется делать его посложнее.
Для того, чтобы slave мог читать данные с мастера – на мастере должно быть разрешено соединение с портом postgresql (по умолчанию - 5432), проверьте firewall!&lt;/p>
&lt;h3 id="копируем-данные" >
&lt;div>
&lt;a href="#%d0%ba%d0%be%d0%bf%d0%b8%d1%80%d1%83%d0%b5%d0%bc-%d0%b4%d0%b0%d0%bd%d0%bd%d1%8b%d0%b5">
##
&lt;/a>
Копируем данные
&lt;/div>
&lt;/h3>
&lt;p>Для начала остановим postgres на slave и удалим данные из datadir на salve:&lt;/p>
&lt;pre>&lt;code>slave&amp;gt; service postgresql stop
slave&amp;gt; rm -rf /var/lib/postgresql/9.6/main/*
&lt;/code>&lt;/pre>
&lt;p>Теперь скопируем основной каталог данных с мастера (текущее состояние)&lt;/p>
&lt;pre>&lt;code>master&amp;gt; psql -c &amp;quot;SELECT pg_start_backup('sync', true)&amp;quot;
master&amp;gt; rsync -rahzP /var/lib/postgresql/9.6/main/ 10.0.0.2:/var/lib/postgresql/9.6/main/ --exclude=postmaster.pid
master&amp;gt; psql -c &amp;quot;SELECT pg_stop_backup()&amp;quot;
&lt;/code>&lt;/pre>
&lt;h3 id="настраиваем-salve" >
&lt;div>
&lt;a href="#%d0%bd%d0%b0%d1%81%d1%82%d1%80%d0%b0%d0%b8%d0%b2%d0%b0%d0%b5%d0%bc-salve">
##
&lt;/a>
Настраиваем salve
&lt;/div>
&lt;/h3>
&lt;p>Если вы хотите читать данные из slave - нужно включить режим hot_standby. Это полезно, если slave используется для распределения нагрузки на чтение. Если slave нужен исключительно как горячая замена мастеру на случай аварии – этот параметр можно не трогать. В конфиге &lt;code>/etc/postgresql/9.6/master/postgresql.conf&lt;/code> добавим:&lt;/p>
&lt;pre>&lt;code>hot_standby = on
&lt;/code>&lt;/pre>
&lt;p>В папке с данными (в нашем примере это &lt;code>/var/lib/postgresql/9.6/main/&lt;/code>) создадим файл с настройками репликации. Он должен называться &lt;code>recovery.conf&lt;/code>&lt;/p>
&lt;pre>&lt;code>standby_mode = 'on'
primary_conninfo = 'host=10.0.0.1 port=5432 user=replication password=Hw572BbvG7g4cwq5'
trigger_file = '/var/lib/postgresql/9.6/promote_to_master'
restore_command = 'cp /var/lib/pg-archive/%f &amp;quot;%p&amp;quot;'
&lt;/code>&lt;/pre>
&lt;p>Создадим на slave папку для архива WAL (так же, как это было сделано на master)&lt;/p>
&lt;pre>&lt;code>mkdir /var/lib/pg-archive/
chown postgres /var/lib/pg-archive/
chmod 700 /var/lib/pg-archive/
&lt;/code>&lt;/pre>
&lt;p>Теперь синхронизируем архив мастера с архивом slave, чтобы гарантировать успешный запуск:&lt;/p>
&lt;pre>&lt;code>master&amp;gt; rsync -rahzP /var/lib/pg-archive/ 10.0.0.2:/var/lib/pg-archive/
&lt;/code>&lt;/pre>
&lt;p>Поднимаем slave:&lt;/p>
&lt;pre>&lt;code>slave&amp;gt; service postgresql start
&lt;/code>&lt;/pre>
&lt;p>В журнале постгреса можно увидеть что сервис стартовал и готов обслуживать соединения:&lt;/p>
&lt;pre>&lt;code>2018-01-11 02:11:31 MSK [26781-1] LOG: database system is ready to accept read only connections
2018-01-11 02:11:31 MSK [26788-1] LOG: started streaming WAL from primary at 10B/33000000 on timeline 1
&lt;/code>&lt;/pre>
&lt;p>Чтобы WAL-сегменты не сожрали весь диск мастера подчистую – их надо периодически чистить. Несложный скрипт в crontab поможет:&lt;/p>
&lt;pre>&lt;code>10 6 * * * /usr/bin/find /var/lib/pg-archive/ -type f -mtime +7 -exec rm {} \;
&lt;/code>&lt;/pre>
&lt;p>В этом примере мы чистим архив от сегментов старше 7 дней, задача выполняется в 6:10 утра по времени сервера.&lt;/p>
&lt;h3 id="диагностика-и-ремонт" >
&lt;div>
&lt;a href="#%d0%b4%d0%b8%d0%b0%d0%b3%d0%bd%d0%be%d1%81%d1%82%d0%b8%d0%ba%d0%b0-%d0%b8-%d1%80%d0%b5%d0%bc%d0%be%d0%bd%d1%82">
##
&lt;/a>
Диагностика и ремонт
&lt;/div>
&lt;/h3>
&lt;p>Как проверить, что репликация работает? Проще всего - выяснить текущее положение WAL на мастере и slave:&lt;/p>
&lt;pre>&lt;code>master$ psql -c &amp;quot;SELECT pg_current_xlog_location()&amp;quot;
pg_current_xlog_location
--------------------------
0/2000000
(1 row)
slave$ psql -c &amp;quot;select pg_last_xlog_receive_location()&amp;quot;
pg_last_xlog_receive_location
-------------------------------
0/2000000
(1 row)
&lt;/code>&lt;/pre>
&lt;p>В норме положение мастера и slave должны быть близки или одинаковы (они будут одинаковы, если между выполнением команды на master и на slave на мастере не было изменений). Если на мастере число растет, а на slave – нет – репликация сломалась.
Самый простой способ восстановить репликацию:&lt;/p>
&lt;pre>&lt;code>#остановим slave:
slave&amp;gt; service postgresql stop
#скопируем архив WAL-сегментов с мастера на salve
master&amp;gt; rsync -rahzP /var/lib/pg-archive/ 10.0.0.2:/var/lib/pg-archive/
#запустим slave обратно:
slave&amp;gt; service postgresql start
&lt;/code>&lt;/pre>
&lt;p>Это сработает, если синхронизация была потеряна недавно (в конкретно нашем примере – не более 7 дней назад) и WAL-ы из архива еще не удалены. Если синхронизацию сломали давно – придется синхронизироваться с нуля, как описано в разделах &amp;ldquo;копируем данные&amp;rdquo; и &amp;ldquo;настраиваем slave&amp;rdquo;. То есть – чистить datadir на slave, копировать состояние, копировать архивы и т.д.&lt;/p>
&lt;h3 id="промотирование-перевод-slave-в-master" >
&lt;div>
&lt;a href="#%d0%bf%d1%80%d0%be%d0%bc%d0%be%d1%82%d0%b8%d1%80%d0%be%d0%b2%d0%b0%d0%bd%d0%b8%d0%b5-%d0%bf%d0%b5%d1%80%d0%b5%d0%b2%d0%be%d0%b4-slave-%d0%b2-master">
##
&lt;/a>
Промотирование (перевод slave в master)
&lt;/div>
&lt;/h3>
&lt;p>Это нужно в тех случаях, когда slave подменяет мастер на случай аварии. Для того, чтобы промотировать slave – нужно создать файл с именем, описанным в секции &lt;code>trigger_file&lt;/code> конфига &lt;code>recovery.conf&lt;/code>. В нашем примере это &lt;code>/var/lib/postgresql/9.6/promote_to_master&lt;/code>&lt;/p>
&lt;pre>&lt;code>touch /var/lib/postgresql/9.6/promote_to_master
&lt;/code>&lt;/pre>
&lt;p>Содержание файла может быть любым.&lt;/p>
&lt;p>После этого:&lt;/p>
&lt;ul>
&lt;li>slave перестанет реплицироваться с master&lt;/li>
&lt;li>slave станет доступен для операций записи&lt;/li>
&lt;li>slave начнет собственный отсчет WAL. Это значит, что даже если master вернется – смигрировать с него данные на slav e автоматически уже &lt;strong>не получится&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="выводы" >
&lt;div>
&lt;a href="#%d0%b2%d1%8b%d0%b2%d0%be%d0%b4%d1%8b">
#
&lt;/a>
Выводы
&lt;/div>
&lt;/h2>
&lt;p>Репликация – мощная, удобная и надежная техника. Репликация в postgresql позволяет легко распределить нагрузку и повысить надежность инсталляции. Эта конструкция работает очень надежно и почти никогда не ломается (привет MySQL!). Разумеется, нужно помнить, что:&lt;/p>
&lt;ul>
&lt;li>любая техника требует мониторинга. Проверяйте состояние реплик!&lt;/li>
&lt;li>репликация не заменяет backup, а только дополняет его.&lt;/li>
&lt;/ul></description></item></channel></rss>